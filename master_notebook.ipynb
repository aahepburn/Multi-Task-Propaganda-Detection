{
    "cells": [
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "24b055ea",
                "execution_start": 1746982738674,
                "execution_millis": 7203,
                "execution_context_id": "29381a6b-b0af-4360-ae18-ae73a278d407",
                "cell_id": "ab1260066dce4271b3037f622527d193",
                "deepnote_cell_type": "code"
            },
            "source": "# RUN THESE IMPORTS FIRST\nimport os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DebertaV2Tokenizer, AutoModel, RobertaTokenizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, classification_report\nimport numpy as np\nimport shap\nfrom captum.attr import IntegratedGradients\nfrom transformers import AutoTokenizer, Trainer, TrainingArguments\nimport torch.nn.functional as F\nimport hf_xet\nimport optuna\nimport sys\nimport importlib # !pip install importlib\nsys.path.append('.')\n\n\n### Custom built modules ###\nimport importlib\n\nimport data_loader_STL\nimportlib.reload(data_loader_STL)\nfrom data_loader_STL import prepare_data_STL_fine, prepare_data_STL_hierarchical, prepare_data_STL_coarse\n\nimport single_task\nimportlib.reload(single_task)\nfrom single_task import TransformerClassifier, MultiLabelDataset, train_single_task_model, train_hierarchical_classifier\n\nimport multi_task\nimportlib.reload(multi_task)\nfrom multi_task import MultiTaskTransformer, train_mtl_flat, train_mtl_hierarchical, apply_hierarchical_constraints_mtl, hierarchical_loss_mtl, AdapterMultiTaskTransformer\n\nimport data_loader_MTL\nimportlib.reload(data_loader_MTL)\nfrom data_loader_MTL import prepare_data_MTL_fine_flat, prepare_data_MTL_hierarchical, prepare_data_MTL_coarse, MultiTaskDataset\n\nimport evaluation_utils as eval_util\nimportlib.reload(eval_util)\nfrom evaluation_utils import evaluate_flat, evaluate_hierarchy, evaluate_mtl_all_tasks, evaluate_per_class_flat, evaluate_per_domain_flat, predict_proba, evaluate_threshold_sweep, evaluate_mtl_hierarchical_task, evaluate_mtl_hierarchical_all_tasks, evaluate_flat_custom, compute_fine_vs_coarse_metrics, get_coarse_label_list\n",
            "block_group": "e0cb8b09157f411ba4e31f52c44d9a0d",
            "execution_count": 7,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "/root/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/6969ac5f-89a3-4c49-a98d-99a7d1f408c0",
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "ed80e4343e90452d9d4c49673adfe981",
                "deepnote_cell_type": "markdown"
            },
            "source": "# Master Notebook\n\nThrough this interface the user can experiment with all the models and experimental conditions used in the thesis.",
            "block_group": "933c99f2adcd4ebfbc0f16d5feca7b98"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "d1b1137e1bff477a9d7318171c644458",
                "deepnote_cell_type": "markdown"
            },
            "source": "## Hyperparameters",
            "block_group": "318a9802e7f541b58ca7e7a9a578fc10"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "be2ffd0c",
                "is_code_hidden": true,
                "execution_start": 1746887343724,
                "execution_millis": 9678,
                "is_output_hidden": true,
                "execution_context_id": "deb92800-6cc8-4a1a-b0a6-2b27f25ec5f4",
                "deepnote_app_is_code_hidden": true,
                "deepnote_app_is_output_hidden": true,
                "cell_id": "c50b5dce8d574e94b6d9af88126700c0",
                "deepnote_cell_type": "code"
            },
            "source": "import sys\nsys.path.append(\".\")  # Ensure current directory is in path\n\nfrom merged_optuna_script import objective_stl, objective_mtl, objective_mtl_adapter\nimport optuna\nimport pandas as pd\n\n# === Fast Experiment Sweep ===\nEXPERIMENTS = [\n    {\"setup\": \"stl\", \"task\": \"entity_framing\", \"encoder\": \"roberta-base\"},\n    {\"setup\": \"stl\", \"task\": \"narrative_classification\", \"encoder\": \"roberta-base\"},\n    {\"setup\": \"mtl\", \"task\": None, \"encoder\": \"roberta-base\"},\n    {\"setup\": \"stl\", \"task\": \"entity_framing\", \"encoder\": \"distilbert-base-uncased\"},\n    {\"setup\": \"stl\", \"task\": \"narrative_classification\", \"encoder\": \"distilbert-base-uncased\"},\n    {\"setup\": \"mtl\", \"task\": None, \"encoder\": \"distilbert-base-uncased\"},\n    {\"setup\": \"mtl_adapter\", \"task\": None, \"encoder\": \"roberta-base\"},\n    {\"setup\": \"mtl_adapter\", \"task\": None, \"encoder\": \"distilbert-base-uncased\"},\n]\n\nall_results = []\n\nfor config in EXPERIMENTS:\n    setup = config[\"setup\"]\n    task = config[\"task\"]\n    encoder = config[\"encoder\"]\n\n    print(f\"\\n Starting Optuna Study → Setup: {setup.upper()} | Task: {task or 'MTL'} | Encoder: {encoder}\")\n    \n    study = optuna.create_study(direction=\"maximize\")\n\n    if setup == \"stl\":\n        study.optimize(lambda trial: objective_stl(trial, task_type=task, model_name=encoder), n_trials=3)\n    elif setup == \"mtl\":\n        study.optimize(lambda trial: objective_mtl(trial, model_name=encoder), n_trials=3)\n    elif setup == \"mtl_adapter\":\n        study.optimize(lambda trial: objective_mtl_adapter(trial, model_name=encoder), n_trials=3)\n    else:\n        raise ValueError(f\"Unknown setup: {setup}\")\n\n    best_params = study.best_trial.params\n    best_score = study.best_trial.value\n\n    print(f\"\\n Best hyperparameters for {setup.upper()} | {task or 'MTL'} | {encoder}:\")\n    for k, v in best_params.items():\n        print(f\"  {k}: {v}\")\n    print(f\"  score: {best_score:.4f}\")\n\n    all_results.append({\n        \"setup\": setup,\n        \"task\": task or \"mtl\",\n        \"encoder\": encoder,\n        \"score\": best_score,\n        **best_params\n    })\n\n# === Save results ===\ndf = pd.DataFrame(all_results)\ndf.to_csv(\"optuna_quick_sweep_results_adapter.csv\", index=False)\nprint(\"\\n Saved results to optuna_quick_sweep_results.csv\")\n",
            "block_group": "263b1ebde4fc4c5e95d1d713f784bfe2",
            "execution_count": 2,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "[I 2025-05-10 10:29:04,051] A new study created in memory with name: no-name-efb61a5a-df9a-4bc7-a131-8da529d3017d\n\n Starting Optuna Study → Setup: MTL_ADAPTER | Task: MTL | Encoder: roberta-base\nException ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fca33dea170>>\nTraceback (most recent call last):\n  File \"/toolkit-cache/0.2.16/python3.10/kernel-libs/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n    def _clean_thread_parent_frames(\nKeyboardInterrupt: \nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\nStarting Epoch 1/2...\n[W 2025-05-10 10:29:12,061] Trial 0 failed with parameters: {'learning_rate': 2.5620923423875518e-05, 'batch_size': 8, 'epochs': 2, 'threshold': 0.2050096184706236} because of the following error: KeyboardInterrupt().\nTraceback (most recent call last):\n  File \"/root/venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n    value_or_values = func(trial)\n  File \"/tmp/ipykernel_280/1264774272.py\", line 36, in <lambda>\n    study.optimize(lambda trial: objective_mtl_adapter(trial, model_name=encoder), n_trials=3)\n  File \"/root/work/merged_optuna_script.py\", line 166, in objective_mtl_adapter\n    train_mtl_flat(\n  File \"/root/work/multi_task.py\", line 68, in train_mtl_flat\n    loss.backward()\n  File \"/root/venv/lib/python3.10/site-packages/torch/_tensor.py\", line 648, in backward\n    torch.autograd.backward(\n  File \"/root/venv/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 353, in backward\n    _engine_run_backward(\n  File \"/root/venv/lib/python3.10/site-packages/torch/autograd/graph.py\", line 824, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nKeyboardInterrupt\n[W 2025-05-10 10:29:12,277] Trial 0 failed with value None.\n",
                    "output_type": "stream"
                },
                {
                    "output_type": "error",
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective_mtl(trial, model_name\u001b[38;5;241m=\u001b[39mencoder), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m setup \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmtl_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_mtl_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown setup: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetup\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
                        "Cell \u001b[0;32mIn[2], line 36\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     34\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective_mtl(trial, model_name\u001b[38;5;241m=\u001b[39mencoder), n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m setup \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmtl_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 36\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective_mtl_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown setup: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msetup\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/work/merged_optuna_script.py:166\u001b[0m, in \u001b[0;36mobjective_mtl_adapter\u001b[0;34m(trial, model_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    164\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m--> 166\u001b[0m \u001b[43mtrain_mtl_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnarrative_classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_s2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity_framing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_s1\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnarrative_classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_s2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlb_s2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity_framing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_s1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlb_s1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmlbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnarrative_classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlb_s2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentity_framing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlb_s1\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_domain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_domain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m results \u001b[38;5;241m=\u001b[39m eval_util\u001b[38;5;241m.\u001b[39mevaluate_mtl_all_tasks(\n\u001b[1;32m    189\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    190\u001b[0m     task_loaders\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     load_from_disk\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    209\u001b[0m )\n\u001b[1;32m    211\u001b[0m f1s \u001b[38;5;241m=\u001b[39m [v[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()]\n",
                        "File \u001b[0;32m~/work/multi_task.py:68\u001b[0m, in \u001b[0;36mtrain_mtl_flat\u001b[0;34m(model, loaders, val_data, mlbs, optimizer, criterion, device, epochs, train_domain, test_domain)\u001b[0m\n\u001b[1;32m     65\u001b[0m     task_loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     66\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m task_loss\n\u001b[0;32m---> 68\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     70\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/venv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/17093a1d-646c-462e-b5f1-40ab2e2a05c2",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "31c2319a",
                "is_code_hidden": true,
                "execution_start": 1746918824209,
                "execution_millis": 173639,
                "execution_context_id": "c1121123-96fd-4595-bbe1-655047eb1bd9",
                "deepnote_app_is_code_hidden": true,
                "cell_id": "1112607fb25545b9b9d19854e4729c8f",
                "deepnote_cell_type": "code"
            },
            "source": "import os\nimport pandas as pd\nimport torch\nfrom transformers import AutoTokenizer\nfrom torch.utils.data import DataLoader\n\nfrom single_task import TransformerClassifier, train_single_task_model, MultiLabelDataset\nfrom multi_task import MultiTaskTransformer, AdapterMultiTaskTransformer, train_mtl_flat\nfrom data_loader_STL import prepare_data_STL_fine\nfrom data_loader_MTL import prepare_data_MTL_fine_flat\nfrom evaluation_utils import evaluate_flat_custom, compute_fine_vs_coarse_metrics, get_coarse_label_list\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nPARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 8,\n    \"epochs\": 3,\n    \"threshold\": 0.35,\n    \"max_len\": 512\n}\n\nSETUPS = [\n    #{\"setup\": \"stl\", \"task\": \"entity_framing\", \"encoder\": \"roberta-base\"},\n    #{\"setup\": \"stl\", \"task\": \"narrative_classification\", \"encoder\": \"roberta-base\"},\n    #{\"setup\": \"mtl\", \"task\": None, \"encoder\": \"roberta-base\"},\n    #{\"setup\": \"mtl_adapter\", \"task\": None, \"encoder\": \"roberta-base\"},\n    #{\"setup\": \"stl\", \"task\": \"entity_framing\", \"encoder\": \"distilbert-base-uncased\"},\n    #{\"setup\": \"stl\", \"task\": \"narrative_classification\", \"encoder\": \"distilbert-base-uncased\"},\n   {\"setup\": \"mtl\", \"task\": None, \"encoder\": \"distilbert-base-uncased\"},\n    #{\"setup\": \"mtl_adapter\", \"task\": None, \"encoder\": \"distilbert-base-uncased\"},\n]\n\nTRAIN_SPLITS = [[\"CC\"]]\nEVAL_SPLITS = [\"UA\", \"CC\"]\n\nSUMMARY_COLUMNS = [\n    \"setup\", \"encoder\", \"task\", \"train_domain\", \"eval_domain\",\n    \"overall_macro\", \"overall_micro\", \"overall_exact\",\n    \"macro_fine\", \"micro_fine\", \"macro_coarse\", \"micro_coarse\"\n]\n\nfor config in SETUPS:\n    setup = config[\"setup\"]\n    task = config[\"task\"]\n    encoder = config[\"encoder\"]\n    tokenizer = AutoTokenizer.from_pretrained(encoder)\n\n    setup_name = f\"{setup}_{task or 'mtl'}_{encoder.replace('/', '-')}\"\n    csv_path = f\"results_summary__{setup_name}.csv\"\n    all_rows = []\n\n    for train_domains in TRAIN_SPLITS:\n        train_str = \"+\".join(train_domains)\n\n        if setup == \"stl\":\n            df_train, df_val, df_test, y_train, y_val, y_test, mlb, text_col, label_col = prepare_data_STL_fine(\n                task, train_domains, [\"UA\", \"CC\"]\n            )\n            train_dataset = MultiLabelDataset(df_train[text_col].tolist(), y_train, tokenizer, PARAMS[\"max_len\"])\n            val_dataset = MultiLabelDataset(df_val[text_col].tolist(), y_val, tokenizer, PARAMS[\"max_len\"])\n            train_loader = DataLoader(train_dataset, batch_size=PARAMS[\"batch_size\"], shuffle=True)\n            val_loader = DataLoader(val_dataset, batch_size=PARAMS[\"batch_size\"])\n\n            model = TransformerClassifier(encoder, len(mlb.classes_)).to(device)\n            model = train_single_task_model(\n                model=model,\n                train_loader=train_loader,\n                val_loader=val_loader,\n                y_val=y_val,\n                MODEL_PATH=\"tmp.pt\",\n                LEARNING_RATE=PARAMS[\"learning_rate\"],\n                EPOCHS=PARAMS[\"epochs\"],\n                device=device\n            )\n\n            results_fine, results_coarse = {}, {}\n            coarse_list = get_coarse_label_list(task)\n\n            for domain in EVAL_SPLITS:\n                df_eval = df_test[df_test[\"Domain\"] == domain].copy()\n                known_labels = set(mlb.classes_)\n                df_eval[label_col] = df_eval[label_col].apply(lambda labels: [l for l in labels if l in known_labels])\n                y_eval = mlb.transform(df_eval[label_col])\n                test_loader = DataLoader(\n                    MultiLabelDataset(df_eval[text_col].tolist(), y_eval, tokenizer, PARAMS[\"max_len\"]),\n                    batch_size=PARAMS[\"batch_size\"]\n                )\n                eval_result = evaluate_flat_custom(model, test_loader, df_eval, mlb, device, threshold=PARAMS[\"threshold\"])\n                score_dict = compute_fine_vs_coarse_metrics(eval_result[\"y_true\"], eval_result[\"y_pred_bin\"], list(mlb.classes_), coarse_list)\n\n                all_rows.append({\n                    \"setup\": setup,\n                    \"encoder\": encoder,\n                    \"task\": task,\n                    \"train_domain\": train_str,\n                    \"eval_domain\": domain,\n                    \"overall_macro\": round((score_dict[\"macro_fine\"] + score_dict[\"macro_coarse\"]) / 2, 4),\n                    \"overall_micro\": round((score_dict[\"micro_fine\"] + score_dict[\"micro_coarse\"]) / 2, 4),\n                    \"overall_exact\": round(eval_result[\"exact\"], 4),\n                    \"macro_fine\": round(score_dict[\"macro_fine\"], 4),\n                    \"micro_fine\": round(score_dict[\"micro_fine\"], 4),\n                    \"macro_coarse\": round(score_dict[\"macro_coarse\"], 4),\n                    \"micro_coarse\": round(score_dict[\"micro_coarse\"], 4)\n                })\n\n        elif setup in [\"mtl\", \"mtl_adapter\"]:\n            (\n                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n                train_loader_s1, val_loader_s1, test_loader_s1,\n                train_loader_s2, val_loader_s2, test_loader_s2,\n                num_classes_dict\n            ) = prepare_data_MTL_fine_flat(\n                TASK=\"multi_task\",\n                model_name=encoder,\n                max_len=PARAMS[\"max_len\"],\n                batch_size=PARAMS[\"batch_size\"],\n                train_domains=train_domains,\n                test_domains=[\"UA\", \"CC\"],\n                train_languages=[\"ALL\"]\n            )\n\n            task_classes = {\n                \"entity_framing\": y_train_s1.shape[1],\n                \"narrative_classification\": y_train_s2.shape[1]\n            }\n            model = MultiTaskTransformer(encoder, task_classes).to(device) if setup == \"mtl\" else \\\n                AdapterMultiTaskTransformer(model_name=encoder, num_classes_dict=task_classes).to(device)\n\n            optimizer = torch.optim.AdamW(model.parameters(), lr=PARAMS[\"learning_rate\"])\n            criterion = torch.nn.BCEWithLogitsLoss()\n\n            train_mtl_flat(\n                model=model,\n                loaders={\"entity_framing\": train_loader_s1, \"narrative_classification\": train_loader_s2},\n                val_data={\n                    \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1),\n                    \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2)\n                },\n                mlbs={\"entity_framing\": mlb_s1, \"narrative_classification\": mlb_s2},\n                optimizer=optimizer,\n                criterion=criterion,\n                device=device,\n                epochs=PARAMS[\"epochs\"],\n                train_domain=train_domains,\n                test_domain=[\"UA\", \"CC\"]\n            )\n\n            for domain in EVAL_SPLITS:\n                for subtask, df_test, mlb, text_key, label_key in [\n                    (\"entity_framing\", df_test_s1, mlb_s1, \"Input_Text\", \"Label\"),\n                    (\"narrative_classification\", df_test_s2, mlb_s2, \"Translated_Text\", \"Label\")\n                ]:\n                    df_eval = df_test[df_test[\"Domain\"] == domain].copy()\n                    known_labels = set(mlb.classes_)\n                    df_eval[label_key] = df_eval[label_key].apply(\n                        lambda labels: [l for l in labels if l in known_labels] if isinstance(labels, list) else []\n                    )\n                    y_eval = mlb.transform(df_eval[label_key])\n\n                    test_loader = DataLoader(\n                        MultiLabelDataset(df_eval[text_key].tolist(), y_eval, tokenizer, PARAMS[\"max_len\"]),\n                        batch_size=PARAMS[\"batch_size\"]\n                    )\n\n                    model_path = f\"{subtask}_MTL_{'-'.join(train_domains)}_to_{'-'.join(EVAL_SPLITS)}.pt\"\n                    if os.path.exists(model_path):\n                        model.load_state_dict(torch.load(model_path))\n                        model.to(device)\n                        print(f\"✅ Loaded model for {subtask}\")\n                    else:\n                        print(f\"⚠️ Missing checkpoint: {model_path}\")\n\n\n                    eval_result = evaluate_flat_custom(\n                        model=model,\n                        loader=test_loader,\n                        df_source=df_eval,\n                        mlb=mlb,\n                        device=device,\n                        threshold=PARAMS[\"threshold\"],\n                        task=subtask\n                    )\n                    coarse_list = get_coarse_label_list(subtask)\n                    score_dict = compute_fine_vs_coarse_metrics(\n                        eval_result[\"y_true\"], eval_result[\"y_pred_bin\"], list(mlb.classes_), coarse_list\n                    )\n\n                    all_rows.append({\n                        \"setup\": setup,\n                        \"encoder\": encoder,\n                        \"task\": subtask,\n                        \"train_domain\": train_str,\n                        \"eval_domain\": domain,\n                        \"overall_macro\": round((score_dict[\"macro_fine\"] + score_dict[\"macro_coarse\"]) / 2, 4),\n                        \"overall_micro\": round((score_dict[\"micro_fine\"] + score_dict[\"micro_coarse\"]) / 2, 4),\n                        \"overall_exact\": round(eval_result[\"exact\"], 4),\n                        \"macro_fine\": round(score_dict[\"macro_fine\"], 4),\n                        \"micro_fine\": round(score_dict[\"micro_fine\"], 4),\n                        \"macro_coarse\": round(score_dict[\"macro_coarse\"], 4),\n                        \"micro_coarse\": round(score_dict[\"micro_coarse\"], 4),\n                    })\n\n\n    pd.DataFrame(all_rows, columns=SUMMARY_COLUMNS).to_csv(csv_path, index=False)\n    print(f\"✅ Saved: {csv_path}\")\n",
            "block_group": "7611105af9d74224b396c7489f31fa50",
            "execution_count": 40,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "9f01182e",
                "is_code_hidden": true,
                "execution_start": 1746921270867,
                "execution_millis": 11327,
                "execution_context_id": "c1121123-96fd-4595-bbe1-655047eb1bd9",
                "deepnote_app_is_code_hidden": true,
                "cell_id": "c1aaa69fe08344b2a18db7bcf990ab39",
                "deepnote_cell_type": "code"
            },
            "source": "\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nPARAMS = {\n    \"learning_rate\": 3e-5,\n    \"batch_size\": 8,\n    \"epochs\": 3,\n    \"threshold\": 0.35,\n    \"max_len\": 512\n}\n\nSETUPS = [\n    {\"setup\": \"mtl\", \"task\": None, \"encoder\": \"distilbert-base-uncased\"},\n]\n\nTRAIN_SPLITS = [[\"CC\"]]\nEVAL_SPLITS = [\"UA\", \"CC\"]\n\nSUMMARY_COLUMNS = [\n    \"setup\", \"encoder\", \"task\", \"train_domain\", \"eval_domain\",\n    \"overall_macro\", \"overall_micro\", \"overall_exact\",\n    \"macro_fine\", \"micro_fine\", \"macro_coarse\", \"micro_coarse\"\n]\n\nfor config in SETUPS:\n    setup = config[\"setup\"]\n    task = config[\"task\"]\n    encoder = config[\"encoder\"]\n    tokenizer = AutoTokenizer.from_pretrained(encoder)\n\n    setup_name = f\"{setup}_{task or 'mtl'}_{encoder.replace('/', '-')}\"\n    csv_path = f\"results_summary__{setup_name}.csv\"\n    all_rows = []\n\n    for train_domains in TRAIN_SPLITS:\n        train_str = \"+\".join(train_domains)\n\n        if setup == \"stl\":\n            df_train, df_val, df_test, y_train, y_val, y_test, mlb, text_col, label_col = prepare_data_STL_fine(\n                task, train_domains, EVAL_SPLITS\n            )\n            train_dataset = MultiLabelDataset(df_train[text_col].tolist(), y_train, tokenizer, PARAMS[\"max_len\"])\n            val_dataset = MultiLabelDataset(df_val[text_col].tolist(), y_val, tokenizer, PARAMS[\"max_len\"])\n            train_loader = DataLoader(train_dataset, batch_size=PARAMS[\"batch_size\"], shuffle=True)\n            val_loader = DataLoader(val_dataset, batch_size=PARAMS[\"batch_size\"])\n\n            model = TransformerClassifier(encoder, len(mlb.classes_)).to(device)\n            model = train_single_task_model(\n                model=model,\n                train_loader=train_loader,\n                val_loader=val_loader,\n                y_val=y_val,\n                MODEL_PATH=\"tmp.pt\",\n                LEARNING_RATE=PARAMS[\"learning_rate\"],\n                EPOCHS=PARAMS[\"epochs\"],\n                device=device\n            )\n\n            for domain in EVAL_SPLITS:\n                df_eval = df_test[df_test[\"Domain\"] == domain].copy()\n                known_labels = set(mlb.classes_)\n                df_eval[label_col] = df_eval[label_col].apply(lambda labels: [l for l in labels if l in known_labels])\n                y_eval = mlb.transform(df_eval[label_col])\n                test_loader = DataLoader(\n                    MultiLabelDataset(df_eval[text_col].tolist(), y_eval, tokenizer, PARAMS[\"max_len\"]),\n                    batch_size=PARAMS[\"batch_size\"]\n                )\n                eval_result = evaluate_flat_custom(model, test_loader, df_eval, mlb, device, threshold=PARAMS[\"threshold\"])\n                score_dict = compute_fine_vs_coarse_metrics(eval_result[\"y_true\"], eval_result[\"y_pred_bin\"], list(mlb.classes_), get_coarse_label_list(task))\n\n                all_rows.append({\n                    \"setup\": setup,\n                    \"encoder\": encoder,\n                    \"task\": task,\n                    \"train_domain\": train_str,\n                    \"eval_domain\": domain,\n                    \"overall_macro\": round((score_dict[\"macro_fine\"] + score_dict[\"macro_coarse\"]) / 2, 4),\n                    \"overall_micro\": round((score_dict[\"micro_fine\"] + score_dict[\"micro_coarse\"]) / 2, 4),\n                    \"overall_exact\": round(eval_result[\"exact\"], 4),\n                    \"macro_fine\": round(score_dict[\"macro_fine\"], 4),\n                    \"micro_fine\": round(score_dict[\"micro_fine\"], 4),\n                    \"macro_coarse\": round(score_dict[\"macro_coarse\"], 4),\n                    \"micro_coarse\": round(score_dict[\"micro_coarse\"], 4),\n                })\n\n        elif setup in [\"mtl\", \"mtl_adapter\"]:\n            (\n                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n                train_loader_s1, val_loader_s1, test_loader_s1,\n                train_loader_s2, val_loader_s2, test_loader_s2,\n                num_classes_dict\n            ) = prepare_data_MTL_fine_flat(\n                TASK=\"multi_task\",\n                model_name=encoder,\n                max_len=PARAMS[\"max_len\"],\n                batch_size=PARAMS[\"batch_size\"],\n                train_domains=train_domains,\n                test_domains=EVAL_SPLITS,\n                train_languages=[\"ALL\"]\n            )\n\n            task_classes = {\n                \"entity_framing\": y_train_s1.shape[1],\n                \"narrative_classification\": y_train_s2.shape[1]\n            }\n            model = MultiTaskTransformer(encoder, task_classes).to(device) if setup == \"mtl\" else \\\n                AdapterMultiTaskTransformer(model_name=encoder, num_classes_dict=task_classes).to(device)\n\n            for subtask in [\"entity_framing\", \"narrative_classification\"]:\n                model_path = f\"{subtask}_MTL_{'-'.join(train_domains)}_to_{'-'.join(EVAL_SPLITS)}.pt\"\n                if os.path.exists(model_path):\n                    model.load_state_dict(torch.load(model_path), strict=False)\n                    print(f\"✅ Loaded model for {subtask}\")\n                else:\n                    print(f\"⚠️ Missing checkpoint: {model_path}\")\n\n                df_test = df_test_s1 if subtask == \"entity_framing\" else df_test_s2\n                mlb = mlb_s1 if subtask == \"entity_framing\" else mlb_s2\n                text_key = \"Input_Text\" if subtask == \"entity_framing\" else \"Translated_Text\"\n                label_key = \"Label\"\n\n                for domain in EVAL_SPLITS:\n                    df_eval = df_test[df_test[\"Domain\"] == domain].copy()\n                    known_labels = set(mlb.classes_)\n                    df_eval[label_key] = df_eval[label_key].apply(lambda labels: [l for l in labels if l in known_labels] if isinstance(labels, list) else [])\n                    y_eval = mlb.transform(df_eval[label_key])\n\n                    test_loader = DataLoader(\n                        MultiTaskDataset(df_eval[text_key].tolist(), {subtask: y_eval}, tokenizer, PARAMS[\"max_len\"]),\n                        batch_size=PARAMS[\"batch_size\"]\n                    )\n\n                    eval_result = evaluate_flat_custom(\n                        model=model,\n                        loader=test_loader,\n                        df_source=df_eval,\n                        mlb=mlb,\n                        device=device,\n                        threshold=PARAMS[\"threshold\"],\n                        task=subtask\n                    )\n                    coarse_list = get_coarse_label_list(subtask)\n                    score_dict = compute_fine_vs_coarse_metrics(eval_result[\"y_true\"], eval_result[\"y_pred_bin\"], list(mlb.classes_), coarse_list)\n\n                    all_rows.append({\n                        \"setup\": setup,\n                        \"encoder\": encoder,\n                        \"task\": subtask,\n                        \"train_domain\": train_str,\n                        \"eval_domain\": domain,\n                        \"overall_macro\": round((score_dict[\"macro_fine\"] + score_dict[\"macro_coarse\"]) / 2, 4),\n                        \"overall_micro\": round((score_dict[\"micro_fine\"] + score_dict[\"micro_coarse\"]) / 2, 4),\n                        \"overall_exact\": round(eval_result[\"exact\"], 4),\n                        \"macro_fine\": round(score_dict[\"macro_fine\"], 4),\n                        \"micro_fine\": round(score_dict[\"micro_fine\"], 4),\n                        \"macro_coarse\": round(score_dict[\"macro_coarse\"], 4),\n                        \"micro_coarse\": round(score_dict[\"micro_coarse\"], 4),\n                    })\n\n    pd.DataFrame(all_rows, columns=SUMMARY_COLUMNS).to_csv(csv_path, index=False)\n    print(f\"✅ Saved: {csv_path}\")\n",
            "block_group": "4fc3d86176ed4b7aaa5164ee21ab2d86",
            "execution_count": 13,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "8ef97b96fbf142f4a3edbb657eeb9b03",
                "deepnote_cell_type": "markdown"
            },
            "source": "## Control Panel",
            "block_group": "4eebb8bf059549c2814bb1b392d9fdcc"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "edda9d25",
                "execution_start": 1746983529256,
                "execution_millis": 533,
                "execution_context_id": "29381a6b-b0af-4360-ae18-ae73a278d407",
                "cell_id": "c6c33bfb7b6440a98762b17b647c356f",
                "deepnote_cell_type": "code"
            },
            "source": "# Choose a task for the pipeline below: \"narrative_classification\" or \"entity_framing\" or \"multi_task\" or \"multi_task_adapter\"\nTASK = \"narrative_classification\"\n\n# select domains for training and testing: \"UA\"; \"CC\"; \"UA\", \"CC\";\nTRAIN_DOMAIN = [\"UA\"]\nTEST_DOMAIN = [\"UA\", \"CC\"] # The test data comes from a separate dataset.\n# The test data is always the same regardless of the domain we choose to train on. This is for consistency.\n\n# select languages for training and testing: \"ALL\";\"EN\";\"HI\";\"BG\";\"RU\";\"PT\"\nTRAIN_LANGUAGES = [\"ALL\"]\nTEST_LANGUAGES = [\"ALL\"]\n\n# Taxonomy Depth\nTAXONOMY_DEPTH = \"FINE\" # \"COARSE\" OR \"FINE\"\n\n# Classifier Complexity\nCLASSIFIER_COMPLEXITY = \"FLAT\" # \"FLAT\" OR \"HIERARCHICAL\"\n\n# change the training hyperparameters here\nMODEL_NAME = \"roberta-base\" # OR  \"distilbert-base-uncased\" \"roberta-base\"\nMAX_LEN = 512\nBATCH_SIZE = 8\nEPOCHS = 4\nLEARNING_RATE = 3e-5\nMODEL_PATH = f\"{TASK}_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\" # -- to save the model later\n\n#tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n#tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\n\n# debug mode -- reduced samples\nDEBUG_MODE = False",
            "block_group": "0b74c5d9b37b4460b5a91f83b34c80e1",
            "execution_count": 31,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "47fe07ac",
                "execution_start": 1746983531289,
                "execution_millis": 3,
                "execution_context_id": "29381a6b-b0af-4360-ae18-ae73a278d407",
                "cell_id": "62726c5321f94778994bc298793e96f9",
                "deepnote_cell_type": "code"
            },
            "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
            "block_group": "0484d130f5604e759dca217a1dc26887",
            "execution_count": 34,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "a5495661d9f442768d73571169ad1f5c",
                "deepnote_cell_type": "markdown"
            },
            "source": "## UTILS Assemble Dataset",
            "block_group": "b50fd602af6c47548e80ec00857d49b9"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "a9cc233",
                "execution_start": 1746983532335,
                "execution_millis": 7167,
                "execution_context_id": "29381a6b-b0af-4360-ae18-ae73a278d407",
                "cell_id": "e77f7dd60a1a430ebbd37089281db4ea",
                "deepnote_cell_type": "code"
            },
            "source": "if TASK != \"multi_task\" and TASK != \"multi_task_adapter\":\n    if TAXONOMY_DEPTH == 'FINE':\n        if CLASSIFIER_COMPLEXITY == 'FLAT':\n            df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL = prepare_data_STL_fine(\n                TASK,\n                TRAIN_DOMAIN,\n                TEST_DOMAIN,\n            )\n        elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n            df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL, child_to_parent, label_to_index = prepare_data_STL_hierarchical(\n                TASK,\n                TRAIN_DOMAIN,\n                TEST_DOMAIN,\n            )\n\n\n    elif TAXONOMY_DEPTH == 'COARSE':\n        df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL = prepare_data_STL_coarse(\n                TASK,\n                TRAIN_DOMAIN,\n                TEST_DOMAIN,\n            )\n\n    train_dataset = MultiLabelDataset(df_train[TEXT_COL].tolist(), y_train, tokenizer, MAX_LEN)\n    val_dataset = MultiLabelDataset(df_val[TEXT_COL].tolist(), y_val, tokenizer, MAX_LEN)\n    test_dataset = MultiLabelDataset(df_test[TEXT_COL].tolist(), y_test, tokenizer, MAX_LEN)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n    num_classes = len(mlb.classes_)\n\n\nelif TASK == \"multi_task\" or TASK == \"multi_task_adapter\":\n\n    if TAXONOMY_DEPTH == 'FINE':\n        \n        if CLASSIFIER_COMPLEXITY == 'FLAT':\n            (\n                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n                train_loader_s1, val_loader_s1, test_loader_s1,\n                train_loader_s2, val_loader_s2, test_loader_s2,\n                num_classes_dict\n            ) = prepare_data_MTL_fine_flat(\n                TASK,\n                train_domains=TRAIN_DOMAIN,\n                test_domains=TEST_DOMAIN,\n                train_languages=TRAIN_LANGUAGES,\n                model_name=MODEL_NAME,\n                max_len=MAX_LEN,\n                batch_size=BATCH_SIZE\n            )\n\n        elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n            (\n                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n                train_loader_s1, val_loader_s1, test_loader_s1,\n                train_loader_s2, val_loader_s2, test_loader_s2,\n                num_classes_dict,\n                child_to_parent_map,\n                label_to_index_map\n            ) = prepare_data_MTL_hierarchical(\n                TASK,\n                train_domains=TRAIN_DOMAIN,\n                test_domains=TEST_DOMAIN,\n                train_languages=TRAIN_LANGUAGES,\n                model_name=MODEL_NAME,\n                max_len=MAX_LEN,\n                batch_size=BATCH_SIZE\n            )\n\n    elif TAXONOMY_DEPTH == 'COARSE':\n        (\n            df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n            df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n            train_loader_s1, val_loader_s1, test_loader_s1,\n            train_loader_s2, val_loader_s2, test_loader_s2,\n            num_classes_dict\n        ) = prepare_data_MTL_coarse(\n            TASK,\n            train_domains=TRAIN_DOMAIN,\n            test_domains=TEST_DOMAIN,\n            train_languages=TRAIN_LANGUAGES,\n            model_name=MODEL_NAME,\n            max_len=MAX_LEN,\n            batch_size=BATCH_SIZE\n        )\n\n\n",
            "block_group": "a8230a1f49a14ddc99725da2a7b03ade",
            "execution_count": 37,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "b4c55c78c616487cb9c73338c9886ab6",
                "deepnote_cell_type": "markdown"
            },
            "source": "## Training Loop",
            "block_group": "0eff6925517b43cf9ccf58f9edc98880"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "c99a6286",
                "execution_start": 1746983539574,
                "execution_millis": 5013,
                "execution_context_id": "29381a6b-b0af-4360-ae18-ae73a278d407",
                "cell_id": "3c084ae072e14c75a89644ba77a26804",
                "deepnote_cell_type": "code"
            },
            "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif TASK != \"multi_task\" and TASK != \"multi_task_adapter\":\n    print(\"\\n>>> Running Single-Task (no adapter) Model <<<\")\n    model = TransformerClassifier(MODEL_NAME, num_classes).to(device)\n\n    if CLASSIFIER_COMPLEXITY == 'FLAT':\n        trained_model = train_single_task_model(\n            model=model,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            y_val=y_val,\n            MODEL_PATH=MODEL_PATH,\n            LEARNING_RATE=LEARNING_RATE,\n            EPOCHS=EPOCHS,\n            device=device,\n            predict_proba=eval_util.predict_proba,\n            evaluate_threshold_sweep=eval_util.evaluate_threshold_sweep\n        )\n        trained_model.load_state_dict(torch.load(MODEL_PATH))\n        trained_model.to(device)\n\n    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n        trained_model = train_hierarchical_classifier(\n            model=model,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            y_val=y_val,\n            MODEL_PATH=MODEL_PATH,\n            child_to_parent=child_to_parent,\n            label_to_index=label_to_index,\n            predict_proba=eval_util.predict_proba,\n            evaluate_threshold_sweep=eval_util.evaluate_threshold_sweep,\n            LEARNING_RATE=LEARNING_RATE,\n            EPOCHS=EPOCHS\n        )\n        trained_model.load_state_dict(torch.load(MODEL_PATH))\n        trained_model.to(device)\n\nelif TASK == \"multi_task\":\n    print(\"\\n>>> Running Multi-Task (no adapter) Model <<<\")\n    task_classes = {\n        \"narrative_classification\": y_train_s2.shape[1],\n        \"entity_framing\": y_train_s1.shape[1]\n    }\n    model = MultiTaskTransformer(MODEL_NAME, task_classes).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.BCEWithLogitsLoss()\n\n    if CLASSIFIER_COMPLEXITY == 'FLAT':\n        train_mtl_flat(\n            model=model,\n            loaders={\n                \"narrative_classification\": train_loader_s2,\n                \"entity_framing\": train_loader_s1\n            },\n            val_data={\n                \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n                \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n            },\n            mlbs={\n                \"narrative_classification\": mlb_s2,\n                \"entity_framing\": mlb_s1\n            },\n            optimizer=optimizer,\n            criterion=criterion,\n            device=device,\n            epochs=EPOCHS,\n            train_domain=TRAIN_DOMAIN,\n            test_domain=TEST_DOMAIN\n        )\n\n    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n        train_mtl_hierarchical(\n            model=model,\n            loaders={\n                \"narrative_classification\": train_loader_s2,\n                \"entity_framing\": train_loader_s1\n            },\n            val_data={\n                \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n                \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n            },\n            child_to_parent_map=child_to_parent_map,\n            label_to_index_map=label_to_index_map,\n            optimizer=optimizer,\n            criterion=criterion,\n            device=device,\n            epochs=EPOCHS,\n            train_domain=TRAIN_DOMAIN,\n            test_domain=TEST_DOMAIN\n        )\n\n\n    # Re-load best saved model per task\n    model.load_state_dict(torch.load(f\"entity_framing_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n    model.load_state_dict(torch.load(f\"narrative_classification_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n    trained_model = model\n\n\nelif TASK == \"multi_task_adapter\":\n    print(\"\\n>>> Running Multi-Task Adapter Model <<<\")\n    \n    task_classes = {\n        \"narrative_classification\": y_train_s2.shape[1],\n        \"entity_framing\": y_train_s1.shape[1]\n    }\n    \n    model = AdapterMultiTaskTransformer(\n        model_name=MODEL_NAME,\n        num_classes_dict=task_classes,\n        adapter_dim=128 \n    ).to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.BCEWithLogitsLoss()\n\n    if CLASSIFIER_COMPLEXITY == 'FLAT':\n        train_mtl_flat(\n            model=model,\n            loaders={\n                \"narrative_classification\": train_loader_s2,\n                \"entity_framing\": train_loader_s1\n            },\n            val_data={\n                \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n                \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n            },\n            mlbs={\n                \"narrative_classification\": mlb_s2,\n                \"entity_framing\": mlb_s1\n            },\n            optimizer=optimizer,\n            criterion=criterion,\n            device=device,\n            epochs=EPOCHS,\n            train_domain=TRAIN_DOMAIN,\n            test_domain=TEST_DOMAIN\n        )\n\n    # load best saved models\n    model.load_state_dict(torch.load(f\"entity_framing_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n    model.load_state_dict(torch.load(f\"narrative_classification_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n    trained_model = model\n",
            "block_group": "3fe48995adf346389329b91b32defed8",
            "execution_count": null,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n>>> Running Single-Task (no adapter) Model <<<\nEpoch 1:  38%|███▊      | 57/152 [00:40<01:07,  1.40it/s]",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/8cc5e88c-7fcd-49c0-a502-018e5a544ca4",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "e359bbdb",
                "is_code_hidden": true,
                "execution_start": 1746982827241,
                "execution_millis": 8201,
                "execution_context_id": "29381a6b-b0af-4360-ae18-ae73a278d407",
                "deepnote_app_is_code_hidden": true,
                "cell_id": "1cc9b2dbaf41460fa31ccd43fd3cd636",
                "deepnote_cell_type": "code"
            },
            "source": "\nmodel.load_state_dict(torch.load(f\"entity_framing_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\nmodel.load_state_dict(torch.load(f\"narrative_classification_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\ntrained_model = model",
            "block_group": "78253a50ea39405094958a2a3768336e",
            "execution_count": 25,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "ef2657310edf4047b2b0d26f3e295f68",
                "deepnote_cell_type": "markdown"
            },
            "source": "## Evaluation",
            "block_group": "905c5b60c2504577b756d16cfa778da5"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "4acc9a72",
                "execution_start": 1746982838723,
                "execution_millis": 16164,
                "execution_context_id": "29381a6b-b0af-4360-ae18-ae73a278d407",
                "cell_id": "e41fec67c22844bfaf5807a5c09279c4",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# EVALUATION (Single Task)\n# ==========================\nif TASK != \"multi_task\" and TASK != \"multi_task_adapter\":\n    print(f\"\\nEvaluating Single-Task Model ({TASK})\")\n\n    if CLASSIFIER_COMPLEXITY == 'FLAT':\n        results_domain = eval_util.evaluate_per_domain_flat(\n            trained_model,\n            val_loader, df_val.reset_index(drop=True),\n            test_loader, df_test.reset_index(drop=True),\n            mlb,\n            device=device\n        )\n\n        results_class = eval_util.evaluate_per_class_flat(\n            trained_model,\n            test_loader,\n            df_test.reset_index(drop=True),\n            mlb,\n            device=device,\n            label=\"TEST\"\n        )\n\n\n    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n        results_hierarchical = eval_util.evaluate_and_compare_hierarchical(\n            model=trained_model,\n            val_loader=val_loader,\n            val_df=df_val.reset_index(drop=True),\n            val_targets=y_val,\n            test_loader=test_loader,\n            test_df=df_test.reset_index(drop=True),\n            test_targets=y_test,\n            mlb=mlb,\n            device=device,\n            child_to_parent=child_to_parent,\n            label_to_index=label_to_index\n        )\n\n# ==========================\n# EVALUATION (Multi-Task)\n# ==========================\nelif TASK == \"multi_task\" or TASK == \"multi_task_adapter\":\n    print(f\"\\nEvaluating Multi-Task Model ({TASK})\")\n    if CLASSIFIER_COMPLEXITY == 'FLAT':\n        task_loaders = {\n            \"narrative_classification\": test_loader_s2,\n            \"entity_framing\": test_loader_s1,\n        }\n\n        task_dfs = {\n            \"narrative_classification\": df_test_s2,\n            \"entity_framing\": df_test_s1,\n        }\n\n        task_targets = {\n            \"narrative_classification\": y_test_s2,\n            \"entity_framing\": y_test_s1,\n        }\n\n        task_mlbs = {\n            \"narrative_classification\": mlb_s2,\n            \"entity_framing\": mlb_s1,\n        }\n\n        results_mtl = eval_util.evaluate_mtl_all_tasks(\n            model=trained_model,\n            task_loaders=task_loaders,\n            task_dfs=task_dfs,\n            task_targets=task_targets,\n            task_mlbs=task_mlbs,\n            domain_list=TRAIN_DOMAIN,\n            device=device,\n            load_from_disk=False\n        )\n\n\n    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n        eval_util.evaluate_mtl_hierarchical_all_tasks(\n            model=trained_model,\n            test_loaders={\n                \"narrative_classification\": test_loader_s2,\n                \"entity_framing\": test_loader_s1\n            },\n            df_tests={\n                \"narrative_classification\": df_test_s2,\n                \"entity_framing\": df_test_s1\n            },\n            y_tests={\n                \"narrative_classification\": y_test_s2,\n                \"entity_framing\": y_test_s1\n            },\n            mlbs={\n                \"narrative_classification\": mlb_s2,\n                \"entity_framing\": mlb_s1\n            },\n            child_to_parent_map=child_to_parent_map,\n            label_to_index_map=label_to_index_map,\n            device=device\n        )\n",
            "block_group": "1110bed05b404da6acf9f44db8f0d24b",
            "execution_count": 28,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\nEvaluating Multi-Task Model (multi_task)\n\n--- Task: NARRATIVE_CLASSIFICATION ---\nEvaluating TEST [narrative_classification]: 100%|██████████| 23/23 [00:04<00:00,  5.08it/s]\n\nTEST (narrative_classification) [Threshold=0.35]\nMacro F1: 0.173\nMicro F1: 0.411\nExact Match: 0.062\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\nDomain: CC\nMacro F1: 0.035\nMicro F1: 0.367\nExact Match: 0.043\n\nDomain: UA\nMacro F1: 0.140\nMicro F1: 0.429\nExact Match: 0.074\n\n--- Task: ENTITY_FRAMING ---\nEvaluating TEST [entity_framing]: 100%|██████████| 56/56 [00:11<00:00,  4.84it/s]\nTEST (entity_framing) [Threshold=0.35]\nMacro F1: 0.238\nMicro F1: 0.575\nExact Match: 0.342\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\nDomain: CC\nMacro F1: 0.168\nMicro F1: 0.793\nExact Match: 0.626\n\nDomain: UA\nMacro F1: 0.221\nMicro F1: 0.521\nExact Match: 0.269\n\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/4ace1069-e378-4008-9b2c-102801626ec0",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "b623e53d",
                "execution_start": 1746964128994,
                "execution_millis": 0,
                "execution_context_id": "ef2a0b44-a1f8-4de6-8747-4ea794fe814a",
                "cell_id": "b0404af8e7bc43ed88751d5064888b62",
                "deepnote_cell_type": "code"
            },
            "source": "",
            "block_group": "c2decbbdc26a4204a8c412807aaf9a7d",
            "execution_count": 85,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "cell_id": "73d79e6531914c8098f92c80df81b935",
                "deepnote_cell_type": "code"
            },
            "source": "",
            "block_group": "a4713a4cef77436c8e7f5a88d5db33d2",
            "execution_count": null,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=49d39932-ba1f-4621-a036-ab99ade88496' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
            "metadata": {
                "created_in_deepnote_cell": true,
                "deepnote_cell_type": "markdown"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "deepnote_notebook_id": "28c06ed7bf87409192461e9c1e8d8ba3"
    }
}