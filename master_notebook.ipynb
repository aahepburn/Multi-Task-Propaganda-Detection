{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Master Notebook"
      ],
      "metadata": {
        "id": "dm0YrOSxd4dA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkHFBELYsQio"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQL193B0sbiR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Thesis Repository\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcdqzp0csryX"
      },
      "outputs": [],
      "source": [
        "pip install scikit-multilearn hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ4ZrK2Cr3gF"
      },
      "outputs": [],
      "source": [
        "# RUN THESE IMPORTS FIRST\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DebertaV2Tokenizer, AutoModel, RobertaTokenizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import numpy as np\n",
        "import shap\n",
        "#from captum.attr import IntegratedGradients\n",
        "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
        "import torch.nn.functional as F\n",
        "import hf_xet\n",
        "import itertools\n",
        "#import optuna\n",
        "import sys\n",
        "import importlib # !pip install importlib\n",
        "sys.path.append('.')\n",
        "\n",
        "\n",
        "### Custom built modules ###\n",
        "import importlib\n",
        "\n",
        "import data_loader_STL\n",
        "importlib.reload(data_loader_STL)\n",
        "from data_loader_STL import prepare_data_STL_fine, prepare_data_STL_hierarchical, prepare_data_STL_coarse\n",
        "\n",
        "import single_task\n",
        "importlib.reload(single_task)\n",
        "from single_task import TransformerClassifier, MultiLabelDataset, train_single_task_model, train_hierarchical_classifier\n",
        "\n",
        "import multi_task\n",
        "importlib.reload(multi_task)\n",
        "from multi_task import MultiTaskTransformer, train_mtl_flat, train_mtl_hierarchical, apply_hierarchical_constraints_mtl, hierarchical_loss_mtl, AdapterMultiTaskTransformer\n",
        "\n",
        "import data_loader_MTL\n",
        "importlib.reload(data_loader_MTL)\n",
        "from data_loader_MTL import prepare_data_MTL_fine_flat, prepare_data_MTL_hierarchical, prepare_data_MTL_coarse, MultiTaskDataset, prepare_data_MTL_mixed\n",
        "\n",
        "import evaluation_utils as eval_util\n",
        "importlib.reload(eval_util)\n",
        "from evaluation_utils import evaluate_flat, evaluate_hierarchy, evaluate_mtl_all_tasks, evaluate_mtl_task, evaluate_per_class_flat, evaluate_per_domain_flat, predict_proba, evaluate_threshold_sweep, evaluate_mtl_hierarchical_task, evaluate_mtl_hierarchical_all_tasks, evaluate_flat_custom, compute_fine_vs_coarse_metrics, get_coarse_label_list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8wlcPozt2_L"
      },
      "source": [
        "# Ablation - mixed dataset function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXp1Sexzt0dL"
      },
      "outputs": [],
      "source": [
        "def prepare_data_MTL_mixed(\n",
        "    task,\n",
        "    train_domains,\n",
        "    test_domains,\n",
        "    train_languages,\n",
        "    model_name,\n",
        "    max_len,\n",
        "    batch_size,\n",
        "    granularity_s1=\"coarse\",\n",
        "    granularity_s2=\"fine\"\n",
        "):\n",
        "    # --- Task 1 ---\n",
        "    if granularity_s1 == \"fine\":\n",
        "        (\n",
        "            df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "            _, _, _, _, _, _, _,\n",
        "            train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "            _, _, _,\n",
        "            _\n",
        "        ) = prepare_data_MTL_fine_flat(\n",
        "            task,\n",
        "            train_domains=train_domains,\n",
        "            test_domains=test_domains,\n",
        "            train_languages=train_languages,\n",
        "            model_name=model_name,\n",
        "            max_len=max_len,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "    elif granularity_s1 == \"coarse\":\n",
        "        (\n",
        "            df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "            _, _, _, _, _, _, _,\n",
        "            train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "            _, _, _,\n",
        "            _\n",
        "        ) = prepare_data_MTL_coarse(\n",
        "            task,\n",
        "            train_domains=train_domains,\n",
        "            test_domains=test_domains,\n",
        "            train_languages=train_languages,\n",
        "            model_name=model_name,\n",
        "            max_len=max_len,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "\n",
        "    # --- Task 2 ---\n",
        "    if granularity_s2 == \"fine\":\n",
        "        (\n",
        "            _, _, _, _, _, _, _,\n",
        "            df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "            _, _, _,\n",
        "            train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "            _\n",
        "        ) = prepare_data_MTL_fine_flat(\n",
        "            task,\n",
        "            train_domains=train_domains,\n",
        "            test_domains=test_domains,\n",
        "            train_languages=train_languages,\n",
        "            model_name=model_name,\n",
        "            max_len=max_len,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "    elif granularity_s2 == \"coarse\":\n",
        "        (\n",
        "            _, _, _, _, _, _, _,\n",
        "            df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "            _, _, _,\n",
        "            train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "            _\n",
        "        ) = prepare_data_MTL_coarse(\n",
        "            task,\n",
        "            train_domains=train_domains,\n",
        "            test_domains=test_domains,\n",
        "            train_languages=train_languages,\n",
        "            model_name=model_name,\n",
        "            max_len=max_len,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "\n",
        "    num_classes_dict = {\n",
        "        \"task1\": len(mlb_s1.classes_),\n",
        "        \"task2\": len(mlb_s2.classes_)\n",
        "    }\n",
        "\n",
        "    return (\n",
        "        df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "        df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "        train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "        train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "        num_classes_dict\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJIHWWzpSRqz"
      },
      "source": [
        "# Ablation - Granularity - MTL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up45fgTAsbJj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import torch\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# === Configuration ===\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 3e-5\n",
        "TRAIN_LANGUAGES = [\"ALL\"]\n",
        "\n",
        "granularity_options = ['fine','coarse'] #  38, 39, 40, 54, 55, 71, 72, 73, 74, 75\n",
        "seeds = [71, 72, 73, 74, 75] # 42, 43, 44\n",
        "granularity_configs = [('coarse', 'coarse')]\n",
        "\n",
        "\n",
        "train_domains_all = [[\"UA\"], [\"CC\"], [\"UA\", \"CC\"]]\n",
        "test_domains = [\"UA\", \"CC\"]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "os.makedirs(\"ablation_results_final_seeds\", exist_ok=True)\n",
        "\n",
        "# training loop\n",
        "for gran_s1, gran_s2 in granularity_configs:\n",
        "    config_id = f\"ef-{gran_s1}_nc-{gran_s2}\"\n",
        "    results = []\n",
        "\n",
        "    for train_domain in train_domains_all:\n",
        "        for task_type in [\"multi_task\", \"multi_task_adapter\"]:\n",
        "            for seed in seeds:\n",
        "                torch.manual_seed(seed)\n",
        "\n",
        "                # set model path\n",
        "                model_path = f\"{task_type}_{'-'.join(train_domain)}_to_{'-'.join(test_domains)}_ef-{gran_s1}_nc-{gran_s2}_seed{seed}.pt\"\n",
        "\n",
        "                # --- Data Prep ---\n",
        "                (\n",
        "                    df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "                    df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "                    train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "                    train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "                    num_classes_dict\n",
        "                ) = prepare_data_MTL_mixed(\n",
        "                    task=task_type,\n",
        "                    train_domains=train_domain,\n",
        "                    test_domains=test_domains,\n",
        "                    train_languages=TRAIN_LANGUAGES,\n",
        "                    model_name=MODEL_NAME,\n",
        "                    max_len=MAX_LEN,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    granularity_s1=gran_s1,\n",
        "                    granularity_s2=gran_s2\n",
        "                )\n",
        "\n",
        "                task_classes = {\n",
        "                    \"narrative_classification\": y_train_s2.shape[1],\n",
        "                    \"entity_framing\": y_train_s1.shape[1]\n",
        "                }\n",
        "\n",
        "                # --- Model ---\n",
        "                if task_type == \"multi_task\":\n",
        "                    model = MultiTaskTransformer(MODEL_NAME, task_classes).to(device)\n",
        "                else:\n",
        "                    model = AdapterMultiTaskTransformer(\n",
        "                        model_name=MODEL_NAME,\n",
        "                        num_classes_dict=task_classes,\n",
        "                        adapter_dim=128\n",
        "                    ).to(device)\n",
        "\n",
        "                optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "                criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "                # --- Train ---\n",
        "                train_mtl_flat(\n",
        "                    model=model,\n",
        "                    loaders={\n",
        "                        \"narrative_classification\": train_loader_s2,\n",
        "                        \"entity_framing\": train_loader_s1\n",
        "                    },\n",
        "                    val_data={\n",
        "                        \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n",
        "                        \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n",
        "                    },\n",
        "                    mlbs={\n",
        "                        \"narrative_classification\": mlb_s2,\n",
        "                        \"entity_framing\": mlb_s1\n",
        "                    },\n",
        "                    optimizer=optimizer,\n",
        "                    criterion=criterion,\n",
        "                    device=device,\n",
        "                    epochs=EPOCHS,\n",
        "                    train_domain=train_domain,\n",
        "                    test_domain=test_domains\n",
        "                )\n",
        "\n",
        "                # torch.save(model.state_dict(), model_path)\n",
        "\n",
        "                #  Evaluate\n",
        "                eval_results = evaluate_mtl_all_tasks(\n",
        "                    model=model,\n",
        "                    task_loaders={\n",
        "                        \"narrative_classification\": test_loader_s2,\n",
        "                        \"entity_framing\": test_loader_s1\n",
        "                    },\n",
        "                    task_dfs={\n",
        "                        \"narrative_classification\": df_test_s2,\n",
        "                        \"entity_framing\": df_test_s1\n",
        "                    },\n",
        "                    task_targets={\n",
        "                        \"narrative_classification\": y_test_s2,\n",
        "                        \"entity_framing\": y_test_s1\n",
        "                    },\n",
        "                    task_mlbs={\n",
        "                        \"narrative_classification\": mlb_s2,\n",
        "                        \"entity_framing\": mlb_s1\n",
        "                    },\n",
        "                    domain_list=train_domain,\n",
        "                    device=device\n",
        "                )\n",
        "\n",
        "                ef = eval_results[\"entity_framing\"]\n",
        "                nc = eval_results[\"narrative_classification\"]\n",
        "\n",
        "                results.append({\n",
        "                    \"task_type\": task_type,\n",
        "                    \"seed\": seed,\n",
        "                    \"train_domain\": \"-\".join(train_domain),\n",
        "                    \"ef_granularity\": gran_s1,\n",
        "                    \"nc_granularity\": gran_s2,\n",
        "\n",
        "                    # EF metrics\n",
        "                    \"ef_micro_ua\": ef[\"UA\"][\"micro\"],\n",
        "                    \"ef_macro_ua\": ef[\"UA\"][\"macro\"],\n",
        "                    \"ef_exact_ua\": ef[\"UA\"][\"exact\"],\n",
        "                    \"ef_micro_cc\": ef[\"CC\"][\"micro\"],\n",
        "                    \"ef_macro_cc\": ef[\"CC\"][\"macro\"],\n",
        "                    \"ef_exact_cc\": ef[\"CC\"][\"exact\"],\n",
        "\n",
        "                    # NC metrics\n",
        "                    \"nc_micro_ua\": nc[\"UA\"][\"micro\"],\n",
        "                    \"nc_macro_ua\": nc[\"UA\"][\"macro\"],\n",
        "                    \"nc_exact_ua\": nc[\"UA\"][\"exact\"],\n",
        "                    \"nc_micro_cc\": nc[\"CC\"][\"micro\"],\n",
        "                    \"nc_macro_cc\": nc[\"CC\"][\"macro\"],\n",
        "                    \"nc_exact_cc\": nc[\"CC\"][\"exact\"]\n",
        "                })\n",
        "\n",
        "\n",
        "    df_out = pd.DataFrame(results)\n",
        "    out_path = f\"ablation_results/ablation_{config_id}.csv\"\n",
        "    df_out.to_csv(out_path, index=False)\n",
        "    print(f\" Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRZs9vaeSXHO"
      },
      "source": [
        "# Ablation - Domain/Task - MTL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NphV8HReSWxW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import itertools\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# === Configuration ===\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 3e-5\n",
        "TRAIN_LANGUAGES = [\"ALL\"]\n",
        "TEST_LANGUAGES = [\"ALL\"]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "os.makedirs(\"ablation_results_cross_domain_more_seeds\", exist_ok=True)\n",
        "\n",
        "# === Domain Configurations for Task Splits ===\n",
        "domain_configs = [\n",
        "    (\"UA\", \"CC\"),  # EF on UA, NC on CC\n",
        "    (\"CC\", \"UA\")   # EF on CC, NC on UA\n",
        "]\n",
        "seeds = [71, 72, 73, 74, 75] # 42, 43, 44, 31, 32\n",
        "\n",
        "for ef_domain, nc_domain in domain_configs:\n",
        "    config_id = f\"EF-{ef_domain}_NC-{nc_domain}\"\n",
        "    results = []\n",
        "\n",
        "    for task_type in [\"multi_task\", \"multi_task_adapter\"]:\n",
        "        for seed in seeds:\n",
        "            torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "            model_path = f\"{task_type}_EF-{ef_domain}_NC-{nc_domain}_seed{seed}.pt\"\n",
        "\n",
        "            #Prepare data.\n",
        "            (\n",
        "                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "                train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "                train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "                num_classes_dict\n",
        "            ) = prepare_data_MTL_mixed(\n",
        "                task=task_type,\n",
        "                train_domains=[ef_domain, nc_domain],\n",
        "                test_domains=[\"UA\", \"CC\"],\n",
        "                train_languages=TRAIN_LANGUAGES,\n",
        "                model_name=MODEL_NAME,\n",
        "                max_len=MAX_LEN,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                granularity_s1=\"fine\",\n",
        "                granularity_s2=\"fine\"\n",
        "            )\n",
        "\n",
        "            task_classes = {\n",
        "                \"entity_framing\": y_train_s1.shape[1],\n",
        "                \"narrative_classification\": y_train_s2.shape[1]\n",
        "            }\n",
        "\n",
        "            # --- Model\n",
        "            if task_type == \"multi_task\":\n",
        "                model = MultiTaskTransformer(MODEL_NAME, task_classes).to(device)\n",
        "            else:\n",
        "                model = AdapterMultiTaskTransformer(\n",
        "                    model_name=MODEL_NAME,\n",
        "                    num_classes_dict=task_classes,\n",
        "                    adapter_dim=128\n",
        "                ).to(device)\n",
        "\n",
        "            optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "            criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "            # --- Train\n",
        "            train_mtl_flat(\n",
        "                model=model,\n",
        "                loaders={\n",
        "                    \"narrative_classification\": train_loader_s2,\n",
        "                    \"entity_framing\": train_loader_s1\n",
        "                },\n",
        "                val_data={\n",
        "                    \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n",
        "                    \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n",
        "                },\n",
        "                mlbs={\n",
        "                    \"narrative_classification\": mlb_s2,\n",
        "                    \"entity_framing\": mlb_s1\n",
        "                },\n",
        "                optimizer=optimizer,\n",
        "                criterion=criterion,\n",
        "                device=device,\n",
        "                epochs=EPOCHS,\n",
        "                train_domain=[ef_domain, nc_domain],\n",
        "                test_domain=[\"UA\", \"CC\"]\n",
        "            )\n",
        "\n",
        "            # --- Evaluate\n",
        "            eval_results = evaluate_mtl_all_tasks(\n",
        "                model=model,\n",
        "                task_loaders={\n",
        "                    \"narrative_classification\": test_loader_s2,\n",
        "                    \"entity_framing\": test_loader_s1\n",
        "                },\n",
        "                task_dfs={\n",
        "                    \"narrative_classification\": df_test_s2,\n",
        "                    \"entity_framing\": df_test_s1\n",
        "                },\n",
        "                task_targets={\n",
        "                    \"narrative_classification\": y_test_s2,\n",
        "                    \"entity_framing\": y_test_s1\n",
        "                },\n",
        "                task_mlbs={\n",
        "                    \"narrative_classification\": mlb_s2,\n",
        "                    \"entity_framing\": mlb_s1\n",
        "                },\n",
        "                domain_list=[ef_domain, nc_domain],\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            ef = eval_results[\"entity_framing\"]\n",
        "            nc = eval_results[\"narrative_classification\"]\n",
        "\n",
        "            results.append({\n",
        "                \"task_type\": task_type,\n",
        "                \"seed\": seed,\n",
        "                \"ef_train_domain\": ef_domain,\n",
        "                \"nc_train_domain\": nc_domain,\n",
        "\n",
        "                \"ef_micro_ua\": ef[\"UA\"][\"micro\"],\n",
        "                \"ef_macro_ua\": ef[\"UA\"][\"macro\"],\n",
        "                \"ef_exact_ua\": ef[\"UA\"][\"exact\"],\n",
        "                \"ef_micro_cc\": ef[\"CC\"][\"micro\"],\n",
        "                \"ef_macro_cc\": ef[\"CC\"][\"macro\"],\n",
        "                \"ef_exact_cc\": ef[\"CC\"][\"exact\"],\n",
        "\n",
        "                \"nc_micro_ua\": nc[\"UA\"][\"micro\"],\n",
        "                \"nc_macro_ua\": nc[\"UA\"][\"macro\"],\n",
        "                \"nc_exact_ua\": nc[\"UA\"][\"exact\"],\n",
        "                \"nc_micro_cc\": nc[\"CC\"][\"micro\"],\n",
        "                \"nc_macro_cc\": nc[\"CC\"][\"macro\"],\n",
        "                \"nc_exact_cc\": nc[\"CC\"][\"exact\"]\n",
        "            })\n",
        "\n",
        "\n",
        "    df_out = pd.DataFrame(results)\n",
        "    out_path = f\"ablation_results_cross_domain_more_seeds/ablation_{config_id}.csv\"\n",
        "    df_out.to_csv(out_path, index=False)\n",
        "    print(f\" Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQEOGZaA8HEE"
      },
      "source": [
        "# STL - Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# === Config ===\n",
        "MODELS = [\"distilbert-base-uncased\"]\n",
        "TASKS = [\"entity_framing\"]\n",
        "TAXONOMY_DEPTHS = [\"fine\"]\n",
        "SEEDS = [71]\n",
        "TRAIN_DOMAINS = [[\"UA\"]]\n",
        "TEST_DOMAIN = [\"UA\", \"CC\"]\n",
        "TRAIN_LANGUAGES = [\"ALL\"]\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 3e-5\n",
        "THRESHOLD = 0.35\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(\"shap_plots_final\", exist_ok=True)\n",
        "results = []\n",
        "\n",
        "for model_name, task, taxonomy, train_domain, seed in itertools.product(MODELS, TASKS, TAXONOMY_DEPTHS, TRAIN_DOMAINS, SEEDS):\n",
        "    domain_str = \"-\".join(train_domain)\n",
        "    print(f\"\\n--- Running STL: {task} | {taxonomy} | {model_name} | Seed={seed} | Train on {domain_str} ---\")\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    #Data prep\n",
        "    if taxonomy == \"fine\":\n",
        "        df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL = prepare_data_STL_fine(\n",
        "            TASK=task,\n",
        "            train_domains=train_domain,\n",
        "            test_domains=TEST_DOMAIN,\n",
        "            train_languages=TRAIN_LANGUAGES\n",
        "        )\n",
        "    else:\n",
        "        df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL = prepare_data_STL_coarse(\n",
        "            TASK=task,\n",
        "            train_domains=train_domain,\n",
        "            test_domains=TEST_DOMAIN,\n",
        "            train_languages=TRAIN_LANGUAGES\n",
        "        )\n",
        "\n",
        "    #  Dataset Setup\n",
        "    train_dataset = MultiLabelDataset(df_train[TEXT_COL].tolist(), y_train, tokenizer, MAX_LEN)\n",
        "    val_dataset = MultiLabelDataset(df_val[TEXT_COL].tolist(), y_val, tokenizer, MAX_LEN)\n",
        "    test_dataset = MultiLabelDataset(df_test[TEXT_COL].tolist(), y_test, tokenizer, MAX_LEN)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Model Init\n",
        "    num_classes = y_train.shape[1]\n",
        "    model = TransformerClassifier(model_name, num_classes)\n",
        "\n",
        "    model_path = (\n",
        "        f\"model_{task}_{taxonomy}_trained_on_{domain_str}\"\n",
        "        f\"_{model_name.replace('/', '-')}_seed{seed}.pt\"\n",
        "    )\n",
        "\n",
        "    # === Train ===\n",
        "    model = train_single_task_model(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        y_val=y_val,\n",
        "        MODEL_PATH=model_path,\n",
        "        LEARNING_RATE=LEARNING_RATE,\n",
        "        EPOCHS=EPOCHS,\n",
        "        device=device,\n",
        "        predict_proba=predict_proba,\n",
        "        evaluate_threshold_sweep=evaluate_threshold_sweep\n",
        "    )\n",
        "\n",
        "    # evaluate\n",
        "    eval_result = evaluate_flat(\n",
        "        model=model,\n",
        "        loader=test_loader,\n",
        "        df_source=df_test,\n",
        "        mlb=mlb,\n",
        "        device=device,\n",
        "        label=\"TEST\",\n",
        "        threshold=THRESHOLD\n",
        "    )\n",
        "\n",
        "    #Extract Per-Domain Metrics\n",
        "    for domain in [\"UA\", \"CC\"]:\n",
        "        results.append({\n",
        "            \"model\": model_name,\n",
        "            \"task\": task,\n",
        "            \"taxonomy\": taxonomy,\n",
        "            \"train_domain\": domain_str,\n",
        "            \"seed\": seed,\n",
        "            \"eval_domain\": domain,\n",
        "            \"micro\": eval_result[\"per_domain\"][domain][\"micro\"],\n",
        "            \"macro\": eval_result[\"per_domain\"][domain][\"macro\"],\n",
        "            \"exact\": eval_result[\"per_domain\"][domain][\"exact\"]\n",
        "        })\n",
        "\n",
        "    # SHAP\n",
        "    texts_ef = df_test[\"Translated_Text\"].tolist()\n",
        "    shap_values_ef = explain_shap(model, tokenizer, texts_ef, max_explain=5)\n",
        "    save_shap_waterfall_plots(shap_values_ef, \"shap_plots\", task, seed, task, mlb)\n",
        "\n",
        "\n",
        "df_out = pd.DataFrame(results)\n",
        "df_out.to_csv(\"ablation_results_stl_augmented_new/stl_all_results_augmented_more_seeds.csv\", index=False)\n",
        "print(\"ablation_results_stl_augmented_new/stl_all_results_augmented_more_seeds.csv\")\n"
      ],
      "metadata": {
        "id": "M_5C2Gi7PWJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLrDn238dXH6"
      },
      "source": [
        "# MTL/MTL-PAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln_E4MHPdW2H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import itertools\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# === Config ===\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 3e-5\n",
        "TRAIN_LANGUAGES = [\"ALL\"]\n",
        "TEST_DOMAINS = [\"UA\", \"CC\"]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "os.makedirs(\"new_augmented_seeds\", exist_ok=True)\n",
        "\n",
        "# Domain configs\n",
        "train_domain_configs = [[\"UA\"]]\n",
        "seeds = [71] #71, 72, 73, 74, 75, 31, 32, 42, 43, 44\n",
        "\n",
        "for train_domains in train_domain_configs:\n",
        "    domain_str = \"-\".join(train_domains)\n",
        "    results = []\n",
        "\n",
        "    for task_type in [\"multi_task\"]:\n",
        "        for seed in seeds:\n",
        "            torch.manual_seed(seed)\n",
        "\n",
        "            print(f\"\\n--- {task_type.upper()} | Train on: {domain_str} | Seed={seed} ---\")\n",
        "\n",
        "            model_path = f\"{task_type}_distilbert_trained_on_{domain_str}_seed{seed}.pt\"\n",
        "\n",
        "            # === Prepare Data ===\n",
        "            (\n",
        "                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "                train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "                train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "                num_classes_dict\n",
        "            ) = prepare_data_MTL_mixed(\n",
        "                task=task_type,\n",
        "                train_domains=train_domains,\n",
        "                test_domains=TEST_DOMAINS,\n",
        "                train_languages=TRAIN_LANGUAGES,\n",
        "                model_name=MODEL_NAME,\n",
        "                max_len=MAX_LEN,\n",
        "                batch_size=BATCH_SIZE,\n",
        "                granularity_s1=\"fine\",\n",
        "                granularity_s2=\"fine\"\n",
        "            )\n",
        "\n",
        "            task_classes = {\n",
        "                \"entity_framing\": y_train_s1.shape[1],\n",
        "                \"narrative_classification\": y_train_s2.shape[1]\n",
        "            }\n",
        "\n",
        "            # Initialise Model\n",
        "            if task_type == \"multi_task\":\n",
        "                model = MultiTaskTransformer(MODEL_NAME, task_classes).to(device)\n",
        "            else:\n",
        "                model = AdapterMultiTaskTransformer(\n",
        "                    model_name=MODEL_NAME,\n",
        "                    num_classes_dict=task_classes,\n",
        "                    adapter_dim=128\n",
        "                ).to(device)\n",
        "\n",
        "            optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "            criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "            # Train\n",
        "            train_mtl_flat(\n",
        "                model=model,\n",
        "                loaders={\n",
        "                    \"narrative_classification\": train_loader_s2,\n",
        "                    \"entity_framing\": train_loader_s1\n",
        "                },\n",
        "                val_data={\n",
        "                    \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n",
        "                    \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n",
        "                },\n",
        "                mlbs={\n",
        "                    \"narrative_classification\": mlb_s2,\n",
        "                    \"entity_framing\": mlb_s1\n",
        "                },\n",
        "                optimizer=optimizer,\n",
        "                criterion=criterion,\n",
        "                device=device,\n",
        "                epochs=EPOCHS,\n",
        "                train_domain=train_domains,\n",
        "                test_domain=TEST_DOMAINS\n",
        "            )\n",
        "\n",
        "            # === Evaluate ===\n",
        "            eval_results = evaluate_mtl_all_tasks(\n",
        "                model=model,\n",
        "                task_loaders={\n",
        "                    \"narrative_classification\": test_loader_s2,\n",
        "                    \"entity_framing\": test_loader_s1\n",
        "                },\n",
        "                task_dfs={\n",
        "                    \"narrative_classification\": df_test_s2,\n",
        "                    \"entity_framing\": df_test_s1\n",
        "                },\n",
        "                task_targets={\n",
        "                    \"narrative_classification\": y_test_s2,\n",
        "                    \"entity_framing\": y_test_s1\n",
        "                },\n",
        "                task_mlbs={\n",
        "                    \"narrative_classification\": mlb_s2,\n",
        "                    \"entity_framing\": mlb_s1\n",
        "                },\n",
        "                domain_list=train_domains,\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            ef = eval_results[\"entity_framing\"]\n",
        "            nc = eval_results[\"narrative_classification\"]\n",
        "\n",
        "            results.append({\n",
        "                \"task_type\": task_type,\n",
        "                \"model\": \"distilbert-base-uncased\",\n",
        "                \"seed\": seed,\n",
        "                \"train_domain\": domain_str,\n",
        "\n",
        "                \"ef_micro_ua\": ef[\"UA\"][\"micro\"],\n",
        "                \"ef_macro_ua\": ef[\"UA\"][\"macro\"],\n",
        "                \"ef_exact_ua\": ef[\"UA\"][\"exact\"],\n",
        "                \"ef_micro_cc\": ef[\"CC\"][\"micro\"],\n",
        "                \"ef_macro_cc\": ef[\"CC\"][\"macro\"],\n",
        "                \"ef_exact_cc\": ef[\"CC\"][\"exact\"],\n",
        "\n",
        "                \"nc_micro_ua\": nc[\"UA\"][\"micro\"],\n",
        "                \"nc_macro_ua\": nc[\"UA\"][\"macro\"],\n",
        "                \"nc_exact_ua\": nc[\"UA\"][\"exact\"],\n",
        "                \"nc_micro_cc\": nc[\"CC\"][\"micro\"],\n",
        "                \"nc_macro_cc\": nc[\"CC\"][\"macro\"],\n",
        "                \"nc_exact_cc\": nc[\"CC\"][\"exact\"]\n",
        "            })\n",
        "            texts_ef = df_test_s1[\"Translated_Text\"].tolist()\n",
        "            texts_nc = df_test_s2[\"Translated_Text\"].tolist()\n",
        "\n",
        "            shap_values_ef = explain_shap(model, tokenizer, texts_ef, \"entity_framing\", max_explain=5)\n",
        "            shap_values_nc = explain_shap(model, tokenizer, texts_nc, \"narrative_classification\", max_explain=5)\n",
        "\n",
        "            save_shap_waterfall_plots(shap_values_nc, \"shap_plots\", \"narrative_classification\", seed, task_type, mlb_s2)\n",
        "            save_shap_waterfall_plots(shap_values_ef, \"shap_plots\", \"entity_framing\", seed, task_type, mlb_s1)\n",
        "\n",
        "\n",
        "\n",
        "    df_out = pd.DataFrame(results)\n",
        "    out_path = f\"new_augmented_seeds/baseline_mtl_more_seeds_augmented_70{domain_str}.csv\"\n",
        "    df_out.to_csv(out_path, index=False)\n",
        "    print(f\" Saved: {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP functions"
      ],
      "metadata": {
        "id": "YTH4WsLMdgIg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MTL SHAP functions"
      ],
      "metadata": {
        "id": "VxPhu81ZO0Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def truncate_texts(texts, tokenizer, max_len):\n",
        "    truncated = []\n",
        "    for text in texts:\n",
        "        tokens = tokenizer.encode(text, truncation=True, max_length=max_len)\n",
        "        truncated_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
        "        truncated.append(truncated_text)\n",
        "    return truncated\n",
        "\n",
        "# Build SHAP Explainer for MTL\n",
        "def get_shap_explainer(model, tokenizer, task_name, model_type=\"entity_framing\"):\n",
        "    def forward_func(inputs):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs, task=task_name)\n",
        "            if isinstance(outputs, (tuple, list)):\n",
        "                logits = outputs[0]\n",
        "            else:\n",
        "                logits = outputs\n",
        "            return torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "    class Wrapper:\n",
        "        def __call__(self, text):\n",
        "            if isinstance(text, str):\n",
        "                text = [text]\n",
        "            elif isinstance(text, np.ndarray):\n",
        "                text = text.tolist()\n",
        "            elif isinstance(text, list) and isinstance(text[0], np.ndarray):\n",
        "                text = [str(t) for t in text]\n",
        "\n",
        "            encoded = tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=MAX_LEN\n",
        "            ).to(device)\n",
        "            return forward_func(encoded)\n",
        "\n",
        "    return shap.Explainer(Wrapper(), tokenizer, algorithm=\"permutation\")\n",
        "\n",
        "# run analysis\n",
        "def explain_shap(model, tokenizer, texts, task_name, model_type=\"entity_framing\", max_explain=5, visualize=False):\n",
        "    texts = truncate_texts(texts[:max_explain], tokenizer, MAX_LEN)\n",
        "    explainer = get_shap_explainer(model, tokenizer, task_name, model_type)\n",
        "    shap_values = explainer(texts, max_evals=1500, silent=True)\n",
        "    if visualize:\n",
        "        shap.plots.text(shap_values)\n",
        "    return shap_values\n",
        "\n",
        "\n",
        "# save to PNG\n",
        "\n",
        "def save_shap_waterfall_plots(shap_values, output_dir, task_name, seed, model_type, mlb, top_k=3):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "    from shap import Explanation\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i, sv in enumerate(shap_values):\n",
        "        try:\n",
        "            mean_abs = np.abs(sv.values).mean(axis=0)\n",
        "            top_outputs = np.argsort(mean_abs)[-top_k:]\n",
        "\n",
        "            for j in top_outputs:\n",
        "                try:\n",
        "                    # Create SHAP Explanation for one label\n",
        "                    single_sv = Explanation(\n",
        "                        values=sv.values[:, j],\n",
        "                        base_values=sv.base_values[j] if hasattr(sv.base_values, '__len__') else sv.base_values,\n",
        "                        data=sv.data,\n",
        "                        feature_names=sv.feature_names\n",
        "                    )\n",
        "\n",
        "                    # Get label name from mlb\n",
        "                    label_name = mlb.classes_[j].replace(\" \", \"_\")  # safer for filenames\n",
        "\n",
        "                    # Generate plot and save\n",
        "                    ax = shap.plots.waterfall(single_sv, show=False)\n",
        "                    fig = ax.figure\n",
        "                    fname = os.path.join(\n",
        "                        output_dir, f\"{task_name}_{model_type}_seed{seed}_sample{i}_label_{label_name}.png\"\n",
        "                    )\n",
        "                    fig.savefig(fname, bbox_inches=\"tight\")\n",
        "                    plt.close(fig)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  [!] Skipped sample {i}, label {j} → {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[!] Error processing sample {i} → {e}\")\n"
      ],
      "metadata": {
        "id": "gnsbhfcvtBQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STL SHAP functions"
      ],
      "metadata": {
        "id": "QmGekXwEO36S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from shap import Explanation\n",
        "\n",
        "\n",
        "def truncate_texts(texts, tokenizer, max_len):\n",
        "    truncated = []\n",
        "    for text in texts:\n",
        "        tokens = tokenizer.encode(text, truncation=True, max_length=max_len)\n",
        "        truncated_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
        "        truncated.append(truncated_text)\n",
        "    return truncated\n",
        "\n",
        "# Build SHAP Explainer for STL\n",
        "def get_shap_explainer(model, tokenizer):\n",
        "    def forward_func(inputs):\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            if hasattr(outputs, 'logits'):\n",
        "                logits = outputs.logits\n",
        "            elif isinstance(outputs, (tuple, list)):\n",
        "                logits = outputs[0]\n",
        "            else:\n",
        "                logits = outputs\n",
        "            return torch.sigmoid(logits).cpu().numpy()\n",
        "\n",
        "    class Wrapper:\n",
        "        def __call__(self, text):\n",
        "            if isinstance(text, str):\n",
        "                text = [text]\n",
        "            elif isinstance(text, np.ndarray):\n",
        "                text = text.tolist()\n",
        "            elif isinstance(text, list) and isinstance(text[0], np.ndarray):\n",
        "                text = [str(t) for t in text]\n",
        "\n",
        "            encoded = tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=MAX_LEN\n",
        "            ).to(device)\n",
        "            return forward_func(encoded)\n",
        "\n",
        "    return shap.Explainer(Wrapper(), tokenizer, algorithm=\"permutation\")\n",
        "\n",
        "# run analysis\n",
        "def explain_shap(model, tokenizer, texts, max_explain=5, visualize=False):\n",
        "    texts = truncate_texts(texts[:max_explain], tokenizer, MAX_LEN)\n",
        "    explainer = get_shap_explainer(model, tokenizer)\n",
        "    shap_values = explainer(texts, max_evals=1500, silent=True)\n",
        "    if visualize:\n",
        "        shap.plots.text(shap_values)\n",
        "    return shap_values\n",
        "\n",
        "# save to PNG\n",
        "def save_shap_waterfall_plots(shap_values, output_dir, task_name, seed, model_type, mlb, top_k=3):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i, sv in enumerate(shap_values):\n",
        "        try:\n",
        "            mean_abs = np.abs(sv.values).mean(axis=0)\n",
        "            top_outputs = np.argsort(mean_abs)[-top_k:]\n",
        "\n",
        "            for j in top_outputs:\n",
        "                try:\n",
        "                    single_sv = Explanation(\n",
        "                        values=sv.values[:, j],\n",
        "                        base_values=sv.base_values[j] if hasattr(sv.base_values, '__len__') else sv.base_values,\n",
        "                        data=sv.data,\n",
        "                        feature_names=sv.feature_names\n",
        "                    )\n",
        "\n",
        "                    label_name = mlb.classes_[j].replace(\" \", \"_\")\n",
        "\n",
        "                    ax = shap.plots.waterfall(single_sv, show=False)\n",
        "                    fig = ax.figure\n",
        "                    fname = os.path.join(\n",
        "                        output_dir, f\"{task_name}_{model_type}_seed{seed}_sample{i}_label_{label_name}.png\"\n",
        "                    )\n",
        "                    fig.savefig(fname, bbox_inches=\"tight\")\n",
        "                    plt.close(fig)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  [!] Skipped sample {i}, label {j} → {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[!] Error processing sample {i} → {e}\")\n"
      ],
      "metadata": {
        "id": "cX8LiIz4O2tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8CVgp5Vr3gL"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TWDLafBZr3gL"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\".\")  # Ensure current directory is in path\n",
        "\n",
        "from merged_optuna_script import objective_stl, objective_mtl, objective_mtl_adapter\n",
        "import optuna\n",
        "import pandas as pd\n",
        "\n",
        "# === Fast Experiment Sweep ===\n",
        "EXPERIMENTS = [\n",
        "    {\"setup\": \"stl\", \"task\": \"entity_framing\", \"encoder\": \"roberta-base\"},\n",
        "    {\"setup\": \"stl\", \"task\": \"narrative_classification\", \"encoder\": \"roberta-base\"},\n",
        "    {\"setup\": \"mtl\", \"task\": None, \"encoder\": \"roberta-base\"},\n",
        "    {\"setup\": \"stl\", \"task\": \"entity_framing\", \"encoder\": \"distilbert-base-uncased\"},\n",
        "    {\"setup\": \"stl\", \"task\": \"narrative_classification\", \"encoder\": \"distilbert-base-uncased\"},\n",
        "    {\"setup\": \"mtl\", \"task\": None, \"encoder\": \"distilbert-base-uncased\"},\n",
        "    {\"setup\": \"mtl_adapter\", \"task\": None, \"encoder\": \"roberta-base\"},\n",
        "    {\"setup\": \"mtl_adapter\", \"task\": None, \"encoder\": \"distilbert-base-uncased\"},\n",
        "]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for config in EXPERIMENTS:\n",
        "    setup = config[\"setup\"]\n",
        "    task = config[\"task\"]\n",
        "    encoder = config[\"encoder\"]\n",
        "\n",
        "    print(f\"\\n Starting Optuna Study → Setup: {setup.upper()} | Task: {task or 'MTL'} | Encoder: {encoder}\")\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "    if setup == \"stl\":\n",
        "        study.optimize(lambda trial: objective_stl(trial, task_type=task, model_name=encoder), n_trials=3)\n",
        "    elif setup == \"mtl\":\n",
        "        study.optimize(lambda trial: objective_mtl(trial, model_name=encoder), n_trials=3)\n",
        "    elif setup == \"mtl_adapter\":\n",
        "        study.optimize(lambda trial: objective_mtl_adapter(trial, model_name=encoder), n_trials=3)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown setup: {setup}\")\n",
        "\n",
        "    best_params = study.best_trial.params\n",
        "    best_score = study.best_trial.value\n",
        "\n",
        "    print(f\"\\n Best hyperparameters for {setup.upper()} | {task or 'MTL'} | {encoder}:\")\n",
        "    for k, v in best_params.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print(f\"  score: {best_score:.4f}\")\n",
        "\n",
        "    all_results.append({\n",
        "        \"setup\": setup,\n",
        "        \"task\": task or \"mtl\",\n",
        "        \"encoder\": encoder,\n",
        "        \"score\": best_score,\n",
        "        **best_params\n",
        "    })\n",
        "\n",
        "# === Save results ===\n",
        "df = pd.DataFrame(all_results)\n",
        "df.to_csv(\"optuna_quick_sweep_results_adapter.csv\", index=False)\n",
        "print(\"\\n Saved results to optuna_quick_sweep_results.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old Experiments [obsolete]"
      ],
      "metadata": {
        "id": "YroYuog3dIbo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jCiegG7r3gN"
      },
      "source": [
        "## Control Panel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u30gpB1nr3gO"
      },
      "outputs": [],
      "source": [
        "# Choose a task for the pipeline below: \"narrative_classification\" or \"entity_framing\" or \"multi_task\" or \"multi_task_adapter\"\n",
        "TASK = \"entity_framing\" # or \"entity_framing\" or \"multi_task\" or \"multi_task_adapter\n",
        "\n",
        "# select domains for training and testing: \"UA\"; \"CC\"; \"UA\", \"CC\";\n",
        "TRAIN_DOMAIN = [\"UA\",\"CC\"]\n",
        "TEST_DOMAIN = [\"UA\", \"CC\"] # The test data comes from a separate dataset.\n",
        "# The test data is always the same regardless of the domain we choose to train on. This is for consistency.\n",
        "\n",
        "# select languages for training and testing: \"ALL\";\"EN\";\"HI\";\"BG\";\"RU\";\"PT\"\n",
        "TRAIN_LANGUAGES = [\"ALL\"]\n",
        "TEST_LANGUAGES = [\"ALL\"]\n",
        "\n",
        "# Taxonomy Depth\n",
        "TAXONOMY_DEPTH = \"COARSE\" # \"COARSE\" OR \"FINE\"\n",
        "\n",
        "# Classifier Complexity\n",
        "CLASSIFIER_COMPLEXITY = \"FLAT\" # \"FLAT\" OR \"HIERARCHICAL\"\n",
        "\n",
        "# change the training hyperparameters here\n",
        "MODEL_NAME = \"distilbert-base-uncased\" # OR  \"distilbert-base-uncased\" \"roberta-base\" \"\"FacebookAI/roberta-base\"\"\n",
        "MAX_LEN = 512\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 3e-5\n",
        "MODEL_PATH = f\"{TASK}_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\" # -- to save the model later\n",
        "\n",
        "#tokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n",
        "#tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "\n",
        "# debug mode -- reduced samples\n",
        "DEBUG_MODE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jT1qbd2r3gO"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ippVT4Air3gO"
      },
      "source": [
        "## UTILS Assemble Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUl9l80Yr3gO"
      },
      "outputs": [],
      "source": [
        "if TASK != \"multi_task\" and TASK != \"multi_task_adapter\":\n",
        "    if TAXONOMY_DEPTH == 'FINE':\n",
        "        if CLASSIFIER_COMPLEXITY == 'FLAT':\n",
        "            df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL = prepare_data_STL_fine(\n",
        "                TASK,\n",
        "                TRAIN_DOMAIN,\n",
        "                TEST_DOMAIN,\n",
        "            )\n",
        "        elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n",
        "            df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL, child_to_parent, label_to_index = prepare_data_STL_hierarchical(\n",
        "                TASK,\n",
        "                TRAIN_DOMAIN,\n",
        "                TEST_DOMAIN,\n",
        "            )\n",
        "\n",
        "\n",
        "    elif TAXONOMY_DEPTH == 'COARSE':\n",
        "        df_train, df_val, df_test, y_train, y_val, y_test, mlb, TEXT_COL, LABEL_COL = prepare_data_STL_coarse(\n",
        "                TASK,\n",
        "                TRAIN_DOMAIN,\n",
        "                TEST_DOMAIN,\n",
        "            )\n",
        "\n",
        "    train_dataset = MultiLabelDataset(df_train[TEXT_COL].tolist(), y_train, tokenizer, MAX_LEN)\n",
        "    val_dataset = MultiLabelDataset(df_val[TEXT_COL].tolist(), y_val, tokenizer, MAX_LEN)\n",
        "    test_dataset = MultiLabelDataset(df_test[TEXT_COL].tolist(), y_test, tokenizer, MAX_LEN)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "    num_classes = len(mlb.classes_)\n",
        "\n",
        "\n",
        "elif TASK == \"multi_task\" or TASK == \"multi_task_adapter\":\n",
        "\n",
        "    if TAXONOMY_DEPTH == 'FINE':\n",
        "\n",
        "        if CLASSIFIER_COMPLEXITY == 'FLAT':\n",
        "            (\n",
        "                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "                train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "                train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "                num_classes_dict\n",
        "            ) = prepare_data_MTL_fine_flat(\n",
        "                TASK,\n",
        "                train_domains=TRAIN_DOMAIN,\n",
        "                test_domains=TEST_DOMAIN,\n",
        "                train_languages=TRAIN_LANGUAGES,\n",
        "                model_name=MODEL_NAME,\n",
        "                max_len=MAX_LEN,\n",
        "                batch_size=BATCH_SIZE\n",
        "            )\n",
        "\n",
        "        elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n",
        "            (\n",
        "                df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "                df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "                train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "                train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "                num_classes_dict,\n",
        "                child_to_parent_map,\n",
        "                label_to_index_map\n",
        "            ) = prepare_data_MTL_hierarchical(\n",
        "                TASK,\n",
        "                train_domains=TRAIN_DOMAIN,\n",
        "                test_domains=TEST_DOMAIN,\n",
        "                train_languages=TRAIN_LANGUAGES,\n",
        "                model_name=MODEL_NAME,\n",
        "                max_len=MAX_LEN,\n",
        "                batch_size=BATCH_SIZE\n",
        "            )\n",
        "\n",
        "    elif TAXONOMY_DEPTH == 'COARSE':\n",
        "        (\n",
        "            df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "            df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "            train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "            train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "            num_classes_dict\n",
        "        ) = prepare_data_MTL_coarse(\n",
        "            TASK,\n",
        "            train_domains=TRAIN_DOMAIN,\n",
        "            test_domains=TEST_DOMAIN,\n",
        "            train_languages=TRAIN_LANGUAGES,\n",
        "            model_name=MODEL_NAME,\n",
        "            max_len=MAX_LEN,\n",
        "            batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ivW39mKr3gP"
      },
      "outputs": [],
      "source": [
        "# Fine-Fine\n",
        "prepare_data_MTL_mixed(..., \"fine\", \"fine\")\n",
        "\n",
        "# Fine-Coarse\n",
        "prepare_data_MTL_mixed(..., \"fine\", \"coarse\")\n",
        "\n",
        "# Coarse-Fine\n",
        "prepare_data_MTL_mixed(..., \"coarse\", \"fine\")\n",
        "\n",
        "# Coarse-Coarse\n",
        "prepare_data_MTL_mixed(..., \"coarse\", \"coarse\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l26Y0sEEtBk6"
      },
      "outputs": [],
      "source": [
        "(\n",
        "    df_train_s1, df_val_s1, df_test_s1, y_train_s1, y_val_s1, y_test_s1, mlb_s1,\n",
        "    df_train_s2, df_val_s2, df_test_s2, y_train_s2, y_val_s2, y_test_s2, mlb_s2,\n",
        "    train_loader_s1, val_loader_s1, test_loader_s1,\n",
        "    train_loader_s2, val_loader_s2, test_loader_s2,\n",
        "    num_classes_dict\n",
        ") = prepare_data_MTL_mixed(\n",
        "    TASK,\n",
        "    train_domains=TRAIN_DOMAIN,\n",
        "    test_domains=TEST_DOMAIN,\n",
        "    train_languages=TRAIN_LANGUAGES,\n",
        "    model_name=MODEL_NAME,\n",
        "    max_len=MAX_LEN,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    granularity_s1=\"coarse\",\n",
        "    granularity_s2=\"fine\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW4sjS0er3gP"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFAfrlWQr3gP"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if TASK != \"multi_task\" and TASK != \"multi_task_adapter\":\n",
        "    print(\"\\n>>> Running Single-Task (no adapter) Model <<<\")\n",
        "    model = TransformerClassifier(MODEL_NAME, num_classes).to(device)\n",
        "\n",
        "    if CLASSIFIER_COMPLEXITY == 'FLAT':\n",
        "        trained_model = train_single_task_model(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            y_val=y_val,\n",
        "            MODEL_PATH=MODEL_PATH,\n",
        "            LEARNING_RATE=LEARNING_RATE,\n",
        "            EPOCHS=EPOCHS,\n",
        "            device=device,\n",
        "            predict_proba=eval_util.predict_proba,\n",
        "            evaluate_threshold_sweep=eval_util.evaluate_threshold_sweep\n",
        "        )\n",
        "        trained_model.load_state_dict(torch.load(MODEL_PATH))\n",
        "        trained_model.to(device)\n",
        "\n",
        "    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n",
        "        trained_model = train_hierarchical_classifier(\n",
        "            model=model,\n",
        "            train_loader=train_loader,\n",
        "            val_loader=val_loader,\n",
        "            y_val=y_val,\n",
        "            MODEL_PATH=MODEL_PATH,\n",
        "            child_to_parent=child_to_parent,\n",
        "            label_to_index=label_to_index,\n",
        "            predict_proba=eval_util.predict_proba,\n",
        "            evaluate_threshold_sweep=eval_util.evaluate_threshold_sweep,\n",
        "            LEARNING_RATE=LEARNING_RATE,\n",
        "            EPOCHS=EPOCHS\n",
        "        )\n",
        "        trained_model.load_state_dict(torch.load(MODEL_PATH))\n",
        "        trained_model.to(device)\n",
        "\n",
        "elif TASK == \"multi_task\":\n",
        "    print(\"\\n>>> Running Multi-Task (no adapter) Model <<<\")\n",
        "    task_classes = {\n",
        "        \"narrative_classification\": y_train_s2.shape[1],\n",
        "        \"entity_framing\": y_train_s1.shape[1]\n",
        "    }\n",
        "    model = MultiTaskTransformer(MODEL_NAME, task_classes).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    if CLASSIFIER_COMPLEXITY == 'FLAT':\n",
        "        train_mtl_flat(\n",
        "            model=model,\n",
        "            loaders={\n",
        "                \"narrative_classification\": train_loader_s2,\n",
        "                \"entity_framing\": train_loader_s1\n",
        "            },\n",
        "            val_data={\n",
        "                \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n",
        "                \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n",
        "            },\n",
        "            mlbs={\n",
        "                \"narrative_classification\": mlb_s2,\n",
        "                \"entity_framing\": mlb_s1\n",
        "            },\n",
        "            optimizer=optimizer,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epochs=EPOCHS,\n",
        "            train_domain=TRAIN_DOMAIN,\n",
        "            test_domain=TEST_DOMAIN\n",
        "        )\n",
        "\n",
        "    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n",
        "        train_mtl_hierarchical(\n",
        "            model=model,\n",
        "            loaders={\n",
        "                \"narrative_classification\": train_loader_s2,\n",
        "                \"entity_framing\": train_loader_s1\n",
        "            },\n",
        "            val_data={\n",
        "                \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n",
        "                \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n",
        "            },\n",
        "            child_to_parent_map=child_to_parent_map,\n",
        "            label_to_index_map=label_to_index_map,\n",
        "            optimizer=optimizer,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epochs=EPOCHS,\n",
        "            train_domain=TRAIN_DOMAIN,\n",
        "            test_domain=TEST_DOMAIN\n",
        "        )\n",
        "\n",
        "\n",
        "    # Re-load best saved model per task\n",
        "    model.load_state_dict(torch.load(f\"entity_framing_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n",
        "    model.load_state_dict(torch.load(f\"narrative_classification_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n",
        "    trained_model = model\n",
        "\n",
        "\n",
        "elif TASK == \"multi_task_adapter\":\n",
        "    print(\"\\n>>> Running Multi-Task Adapter Model <<<\")\n",
        "\n",
        "    task_classes = {\n",
        "        \"narrative_classification\": y_train_s2.shape[1],\n",
        "        \"entity_framing\": y_train_s1.shape[1]\n",
        "    }\n",
        "\n",
        "    model = AdapterMultiTaskTransformer(\n",
        "        model_name=MODEL_NAME,\n",
        "        num_classes_dict=task_classes,\n",
        "        adapter_dim=128\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    if CLASSIFIER_COMPLEXITY == 'FLAT':\n",
        "        train_mtl_flat(\n",
        "            model=model,\n",
        "            loaders={\n",
        "                \"narrative_classification\": train_loader_s2,\n",
        "                \"entity_framing\": train_loader_s1\n",
        "            },\n",
        "            val_data={\n",
        "                \"narrative_classification\": (val_loader_s2, df_val_s2, y_val_s2, mlb_s2),\n",
        "                \"entity_framing\": (val_loader_s1, df_val_s1, y_val_s1, mlb_s1)\n",
        "            },\n",
        "            mlbs={\n",
        "                \"narrative_classification\": mlb_s2,\n",
        "                \"entity_framing\": mlb_s1\n",
        "            },\n",
        "            optimizer=optimizer,\n",
        "            criterion=criterion,\n",
        "            device=device,\n",
        "            epochs=EPOCHS,\n",
        "            train_domain=TRAIN_DOMAIN,\n",
        "            test_domain=TEST_DOMAIN\n",
        "        )\n",
        "\n",
        "    # load best saved models\n",
        "    model.load_state_dict(torch.load(f\"entity_framing_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n",
        "    model.load_state_dict(torch.load(f\"narrative_classification_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"), strict=False)\n",
        "    trained_model = model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62l8IF1Lr3gP"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XgxBR-ar3gP"
      },
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# EVALUATION (Single Task)\n",
        "# ==========================\n",
        "if TASK != \"multi_task\" and TASK != \"multi_task_adapter\":\n",
        "    print(f\"\\nEvaluating Single-Task Model ({TASK})\")\n",
        "\n",
        "    if CLASSIFIER_COMPLEXITY == 'FLAT':\n",
        "        results_domain = eval_util.evaluate_per_domain_flat(\n",
        "            trained_model,\n",
        "            val_loader, df_val.reset_index(drop=True),\n",
        "            test_loader, df_test.reset_index(drop=True),\n",
        "            mlb,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        results_class = eval_util.evaluate_per_class_flat(\n",
        "            trained_model,\n",
        "            test_loader,\n",
        "            df_test.reset_index(drop=True),\n",
        "            mlb,\n",
        "            device=device,\n",
        "            label=\"TEST\"\n",
        "        )\n",
        "\n",
        "\n",
        "    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n",
        "        results_hierarchical = eval_util.evaluate_and_compare_hierarchical(\n",
        "            model=trained_model,\n",
        "            val_loader=val_loader,\n",
        "            val_df=df_val.reset_index(drop=True),\n",
        "            val_targets=y_val,\n",
        "            test_loader=test_loader,\n",
        "            test_df=df_test.reset_index(drop=True),\n",
        "            test_targets=y_test,\n",
        "            mlb=mlb,\n",
        "            device=device,\n",
        "            child_to_parent=child_to_parent,\n",
        "            label_to_index=label_to_index\n",
        "        )\n",
        "\n",
        "# ==========================\n",
        "# EVALUATION (Multi-Task)\n",
        "# ==========================\n",
        "elif TASK == \"multi_task\" or TASK == \"multi_task_adapter\":\n",
        "    print(f\"\\nEvaluating Multi-Task Model ({TASK})\")\n",
        "    if CLASSIFIER_COMPLEXITY == 'FLAT':\n",
        "        task_loaders = {\n",
        "            \"narrative_classification\": test_loader_s2,\n",
        "            \"entity_framing\": test_loader_s1,\n",
        "        }\n",
        "\n",
        "        task_dfs = {\n",
        "            \"narrative_classification\": df_test_s2,\n",
        "            \"entity_framing\": df_test_s1,\n",
        "        }\n",
        "\n",
        "        task_targets = {\n",
        "            \"narrative_classification\": y_test_s2,\n",
        "            \"entity_framing\": y_test_s1,\n",
        "        }\n",
        "\n",
        "        task_mlbs = {\n",
        "            \"narrative_classification\": mlb_s2,\n",
        "            \"entity_framing\": mlb_s1,\n",
        "        }\n",
        "\n",
        "        results_mtl = eval_util.evaluate_mtl_all_tasks(\n",
        "            model=trained_model,\n",
        "            task_loaders=task_loaders,\n",
        "            task_dfs=task_dfs,\n",
        "            task_targets=task_targets,\n",
        "            task_mlbs=task_mlbs,\n",
        "            domain_list=TRAIN_DOMAIN,\n",
        "            device=device,\n",
        "            load_from_disk=False\n",
        "        )\n",
        "\n",
        "\n",
        "    elif CLASSIFIER_COMPLEXITY == 'HIERARCHICAL':\n",
        "        eval_util.evaluate_mtl_hierarchical_all_tasks(\n",
        "            model=trained_model,\n",
        "            test_loaders={\n",
        "                \"narrative_classification\": test_loader_s2,\n",
        "                \"entity_framing\": test_loader_s1\n",
        "            },\n",
        "            df_tests={\n",
        "                \"narrative_classification\": df_test_s2,\n",
        "                \"entity_framing\": df_test_s1\n",
        "            },\n",
        "            y_tests={\n",
        "                \"narrative_classification\": y_test_s2,\n",
        "                \"entity_framing\": y_test_s1\n",
        "            },\n",
        "            mlbs={\n",
        "                \"narrative_classification\": mlb_s2,\n",
        "                \"entity_framing\": mlb_s1\n",
        "            },\n",
        "            child_to_parent_map=child_to_parent_map,\n",
        "            label_to_index_map=label_to_index_map,\n",
        "            device=device\n",
        "        )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "collapsed_sections": [
        "YTH4WsLMdgIg"
      ]
    },
    "deepnote_notebook_id": "28c06ed7bf87409192461e9c1e8d8ba3",
    "deepnote_persisted_session": {
      "createdAt": "2025-05-13T16:22:54.164Z"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}