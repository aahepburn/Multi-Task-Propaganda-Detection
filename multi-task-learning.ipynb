{
    "cells": [
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "21448b04",
                "execution_start": 1743807478404,
                "execution_millis": 2,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "2e27c76adebb44dca7534dbe80ff3216",
                "deepnote_cell_type": "code"
            },
            "source": "import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom collections import Counter\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom scipy.spatial.distance import jensenshannon, cosine\nfrom scipy.stats import chi2_contingency\nfrom scipy.spatial.distance import cdist\nfrom scipy.linalg import norm\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom wordcloud import WordCloud\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport transformers\nfrom transformers import DebertaV2Tokenizer, RobertaTokenizer\nfrom transformers import AutoModel\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\nimport gc\nfrom tqdm import tqdm\nimport sentencepiece\n",
            "block_group": "2e27c76adebb44dca7534dbe80ff3216",
            "execution_count": 111,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "71fb63f20b2644b7a3f7092a2d611d8b",
                "deepnote_cell_type": "markdown"
            },
            "source": "# Multi-Task Learning\n\nBelow is the current pipeline for multi-task learning. The code chunk bellow allows to switch between the two tasks: \"narrative_classification\" and \"entity_framing\".\n\nWe can also specify the training and test domains.",
            "block_group": "793d69369aed4e9ba5f139b34d5245c8"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "4df34080",
                "execution_start": 1743810132526,
                "execution_millis": 1,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "c9f97fcf846946d49badca52bebd117e",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# CONTROL PANEL\n# ==========================\n\n# choose a task for the pipeline below: \"narrative_classification\" or \"entity_framing\"\nTASK = \"multi_task\"\n\n# select domains for training and testing: \"UA\"; \"CC\"; or both\nTRAIN_DOMAIN = [\"CC\"]\nTEST_DOMAIN = [\"UA\", \"CC\"]\n# The test data comes from a separate dataset. \n# The test data is always the same regardless of the domain we choose to train on. This is for consistency.\n\n\"\"\"\nNote that all articles are now in English, but if we wanted to control for e.g. certain cultural variations of a specific language,\nwe could exclude articles that were originally written in that language.\n\nNot to use the functionality, 'ALL' should be selected.\n\n\"\"\"\n\n# select languages for training and testing: \"ALL\";\"EN\";\"HI\";\"BG\";\"RU\";\"PT\"\nTRAIN_LANGUAGES = [\"ALL\"]\nTEST_LANGUAGES = [\"ALL\"]\n\n# debug mode\nDEBUG_MODE = False\n\n# change the training hyperparameters here\nMODEL_NAME = \"roberta-base\" # OR \"deberta-v3-base\"\nMAX_LEN = 512\nBATCH_SIZE = 8\nEPOCHS = 3\nLEARNING_RATE = 2e-5\n\n# Use consistent naming\nMODEL_PATH = f\"{TASK}_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"  # -- to save the model later\n",
            "block_group": "87f611535b7d4627adc613951905fa82",
            "execution_count": 159,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "ecbeefd0",
                "execution_start": 1743810134701,
                "execution_millis": 610,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "6b3e3d2fced046f7bfc35bb84a13fcfc",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# LOAD DATA\n# ==========================\n\narticles = pd.read_csv(\"train-all-articles.csv\")\ns1 = pd.read_csv(\"train-S1-labels.csv\")\ns2 = pd.read_csv(\"train-S2-labels.csv\")\n\ntest_s1_articles = pd.read_csv(\"test-S1-articles.csv\")\ntest_s1_labels = pd.read_csv(\"test-S1-labels.csv\")\ntest_s2_articles = pd.read_csv(\"test-S2-articles.csv\")\ntest_s2_labels = pd.read_csv(\"test-S2-labels.csv\")\n\ntest_s1_labels.rename(columns={\"Translated_Entity\": \"Entity\"}, inplace=True)\ntest_s2_labels.columns = [\"Filename\", \"Narrative\", \"Subnarrative\"]\n",
            "block_group": "853b995a40c0450db05dc9e0bccba48b",
            "execution_count": 161,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "e7e274a4",
                "execution_start": 1743810136884,
                "execution_millis": 2,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "437e173e4f984161b4512036b190fb88",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# FILTER + SPLIT TRAIN/VAL\n# ==========================\n\n# filter domains/languages for shared train/val\nfiltered_articles = articles[articles[\"Domain\"].isin(TRAIN_DOMAIN)]\nif \"ALL\" not in TRAIN_LANGUAGES:\n    filtered_articles = filtered_articles[filtered_articles[\"Language\"].isin(TRAIN_LANGUAGES)]\n\n# 80/20 train/val split\nfiltered_articles = filtered_articles.sample(frac=1, random_state=42).reset_index(drop=True)\nsplit_idx = int(0.8 * len(filtered_articles))\ntrain_articles = filtered_articles.iloc[:split_idx].copy()\nval_articles = filtered_articles.iloc[split_idx:].copy()\n\n# debug subsamling\nif DEBUG_MODE:\n    train_articles = train_articles.sample(100)\n    val_articles = val_articles.sample(100)\n    test_s1_articles = test_s1_articles.sample(100)\n    test_s2_articles = test_s2_articles.sample(100)\n",
            "block_group": "d57d1c45a5cd4f51b8c357208c4da033",
            "execution_count": 163,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "ce9cd6ae",
                "execution_start": 1743810138561,
                "execution_millis": 35,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "2e1600c80afb497580be712bb0a94e52",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# MERGE WITH LABELS\n# ==========================\n\n# ENTITY FRAMING\ndf_train_s1 = pd.merge(s1, train_articles, on=\"Filename\")\ndf_val_s1   = pd.merge(s1, val_articles, on=\"Filename\")\ndf_test_s1  = pd.merge(test_s1_labels, test_s1_articles, on=\"Filename\")\n\nfor df in [df_train_s1, df_val_s1, df_test_s1]:\n    df.dropna(subset=[\"Translated_Text\", \"Entity\", \"Label\", \"Start\", \"End\"], inplace=True)\n    df[\"Start\"] = df[\"Start\"].astype(int)\n    df[\"End\"] = df[\"End\"].astype(int)\n\n    def insert_entity_marker(text, start, end):\n        try:\n            return text[:start] + \"[ENTITY]\" + text[start:end] + \"[/ENTITY]\" + text[end:]\n        except:\n            return text\n\n    df[\"Input_Text\"] = df.apply(lambda row: insert_entity_marker(row[\"Translated_Text\"], row[\"Start\"], row[\"End\"]), axis=1)\n    df[\"Entity_Labels\"] = df[\"Label\"].apply(lambda x: [s.strip() for s in str(x).split(\",\") if s.strip().lower() != \"nan\"])\n\n# NARRATIVE CLASSIFICATION\ndf_train_s2 = pd.merge(train_articles, s2, on=\"Filename\")\ndf_val_s2   = pd.merge(val_articles, s2, on=\"Filename\")\ndf_test_s2  = pd.merge(test_s2_articles, test_s2_labels, on=\"Filename\")\n\nfor df in [df_train_s2, df_val_s2, df_test_s2]:\n    df.dropna(subset=[\"Translated_Text\", \"Narrative\"], inplace=True)\n    df[\"Narrative_Labels\"] = df[\"Narrative\"].apply(lambda x: [s.strip() for s in str(x).split(\";\") if s.strip().lower() != \"nan\"])\n",
            "block_group": "c1e79d5bfbe54ef4af6d6c6a12365dec",
            "execution_count": 165,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "5520fd16",
                "execution_start": 1743810140236,
                "execution_millis": 4,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "f9f50cb7c97b46c6b4873f01ab6c6c0d",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# MULTI-TASK LABEL BINARISATION\n# ==========================\n\n# Narrative Classification\nmlb_s2 = MultiLabelBinarizer()\nmlb_s2.fit(pd.concat([df_train_s2[\"Narrative_Labels\"], df_val_s2[\"Narrative_Labels\"], df_test_s2[\"Narrative_Labels\"]]))\ny_train_s2 = mlb_s2.transform(df_train_s2[\"Narrative_Labels\"])\ny_val_s2   = mlb_s2.transform(df_val_s2[\"Narrative_Labels\"])\ny_test_s2  = mlb_s2.transform(df_test_s2[\"Narrative_Labels\"])\nnum_classes_s2 = len(mlb_s2.classes_)\n\n\n# Entity Framing\nmlb_s1 = MultiLabelBinarizer()\nmlb_s1.fit(pd.concat([df_train_s1[\"Entity_Labels\"], df_val_s1[\"Entity_Labels\"], df_test_s1[\"Entity_Labels\"]]))\ny_train_s1 = mlb_s1.transform(df_train_s1[\"Entity_Labels\"])\ny_val_s1   = mlb_s1.transform(df_val_s1[\"Entity_Labels\"])\ny_test_s1  = mlb_s1.transform(df_test_s1[\"Entity_Labels\"])\nnum_classes_s1 = len(mlb_s1.classes_)\n\ntask_classes = {\n    \"narrative_classification\": y_train_s2.shape[1],\n    \"entity_framing\": y_train_s1.shape[1]\n}\n",
            "block_group": "0cdb44042bd246519fca20e8e971debe",
            "execution_count": 167,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "ed2a2359",
                "execution_start": 1743810141886,
                "execution_millis": 153,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "962ff4ecb13a435181f1f8f882d13d75",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# TOKENISATION and DATASET CLASS\n# ==========================\n\ntokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n#tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n\nclass MultiTaskDataset(Dataset):\n    def __init__(self, texts, task_labels_dict, tokenizer, max_len):\n        self.texts = texts\n        self.task_labels_dict = task_labels_dict  # dict of task_name: label matrix\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoding = self.tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            return_tensors=\"pt\"\n        )\n\n        item = {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n        }\n\n        for task_name, label_matrix in self.task_labels_dict.items():\n            item[f\"{task_name}_labels\"] = torch.tensor(label_matrix[idx], dtype=torch.float)\n\n        return item\n\n\n# Dataset + DataLoader for Entity Framing\ndataset_train_s1 = MultiTaskDataset(df_train_s1[\"Input_Text\"].tolist(), {\"entity_framing\": y_train_s1}, tokenizer, MAX_LEN)\ndataset_val_s1   = MultiTaskDataset(df_val_s1[\"Input_Text\"].tolist(),   {\"entity_framing\": y_val_s1},   tokenizer, MAX_LEN)\ndataset_test_s1  = MultiTaskDataset(df_test_s1[\"Input_Text\"].tolist(),  {\"entity_framing\": y_test_s1},  tokenizer, MAX_LEN)\n\n# Dataset + DataLoader for Narrative Classification\ndataset_train_s2 = MultiTaskDataset(df_train_s2[\"Translated_Text\"].tolist(), {\"narrative_classification\": y_train_s2}, tokenizer, MAX_LEN)\ndataset_val_s2   = MultiTaskDataset(df_val_s2[\"Translated_Text\"].tolist(),   {\"narrative_classification\": y_val_s2},   tokenizer, MAX_LEN)\ndataset_test_s2  = MultiTaskDataset(df_test_s2[\"Translated_Text\"].tolist(),  {\"narrative_classification\": y_test_s2},  tokenizer, MAX_LEN)\n\n# ==========================\n# DATALOADERS FOR MTL\n# ==========================\n\n# Narrative Classification\ntrain_loader_nc = DataLoader(dataset_train_s2, batch_size=BATCH_SIZE, shuffle=True)\nval_loader_nc   = DataLoader(dataset_val_s2, batch_size=BATCH_SIZE)\ntest_loader_nc  = DataLoader(dataset_test_s2, batch_size=BATCH_SIZE)\n\n# Entity Framing\ntrain_loader_ef = DataLoader(dataset_train_s1, batch_size=BATCH_SIZE, shuffle=True)\nval_loader_ef   = DataLoader(dataset_val_s1, batch_size=BATCH_SIZE)\ntest_loader_ef  = DataLoader(dataset_test_s1, batch_size=BATCH_SIZE)\n",
            "block_group": "476fc545edce46b981c546e7e2968be3",
            "execution_count": 169,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "ed07c6b1",
                "execution_start": 1743810143086,
                "execution_millis": 1,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "6234a32a52b247678622c3e83e49c6e1",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# MODEL CLASS MTL\n# ==========================\n\nclass MultiTaskTransformer(nn.Module):\n    def __init__(self, model_name, num_classes_dict):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n\n        hidden_size = self.encoder.config.hidden_size\n\n        # task-specific classifier heads\n        self.task_heads = nn.ModuleDict({\n            \"narrative_classification\": nn.Linear(hidden_size, num_classes_dict[\"narrative_classification\"]),\n            \"entity_framing\": nn.Linear(hidden_size, num_classes_dict[\"entity_framing\"]),\n        })\n\n    def forward(self, input_ids, attention_mask, task):\n        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n        pooled_output = self.dropout(pooled_output)\n\n        return self.task_heads[task](pooled_output)\n",
            "block_group": "5b26250b234444e585bb7bcc786fbcc2",
            "execution_count": 171,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "1b0324c1",
                "execution_start": 1743810144526,
                "execution_millis": 1,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "ffdbad49355343a4b5d1a7b2a6270605",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# TRAINING LOOP UTILS (MTL)\n# ==========================\n\ndef train_mtl(model, loaders, val_data, mlbs, optimizer, criterion, device, epochs):\n    best_macro_f1 = {task: 0.0 for task in loaders.keys()}\n\n    # Convert loaders to iterables that cycle\n    from itertools import cycle\n\n    # Find the length of the longest dataloader\n    max_len = max(len(loader) for loader in loaders.values())\n    \n    task_names = list(loaders.keys())\n\n    for epoch in range(epochs):\n        print(f\"\\n Starting Epoch {epoch+1}/{epochs}...\") \n        model.train()\n        total_loss = 0.0\n\n        # initialise iterators (cycle to match max length)\n        iters = {task: cycle(loaders[task]) for task in task_names}\n\n        for _ in range(max_len):\n            optimizer.zero_grad()\n            loss = 0.0\n\n            for task in task_names:\n                batch = next(iters[task])\n                input_ids = batch[\"input_ids\"].to(device)\n                attention_mask = batch[\"attention_mask\"].to(device)\n                labels = batch[f\"{task}_labels\"].to(device)\n\n                outputs = model(input_ids, attention_mask, task=task)\n                task_loss = criterion(outputs, labels)\n                loss += task_loss\n\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_loss = total_loss / max_len\n        print(f\"\\nEpoch {epoch+1} - Average MTL Loss: {avg_loss:.4f}\")\n\n        # =====================\n        # VALIDATION PER TASK\n        # =====================\n        model.eval()\n        for task in val_data:\n            val_loader, df_val, y_val, mlb = val_data[task]\n\n            print(f\"\\n Validating task: {task}\")\n            threshold = 0.25  # fixed threshold\n            y_pred = []\n\n            with torch.no_grad():\n                for batch in val_loader:\n                    input_ids = batch[\"input_ids\"].to(device)\n                    attention_mask = batch[\"attention_mask\"].to(device)\n                    outputs = model(input_ids, attention_mask, task=task)\n                    probs = torch.sigmoid(outputs).cpu().numpy()\n                    y_pred.extend(probs)\n\n            y_pred = np.array(y_pred)\n            y_pred_bin = (y_pred > threshold).astype(int)\n\n            macro = f1_score(y_val, y_pred_bin, average=\"macro\", zero_division=0)\n            print(f\"[{task}] Macro F1: {macro:.4f}\")\n\n            if macro > best_macro_f1[task]:\n                best_macro_f1[task] = macro\n                save_path = f\"{task}_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"\n                torch.save(model.state_dict(), save_path)\n                print(f\" Best model for task '{task}' saved to {save_path}\")\n\n\ndef predict_proba(model, loader, task, device):\n    model.eval()\n    preds = []\n\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n\n            outputs = model(input_ids, attention_mask, task=task)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            preds.extend(probs)\n\n    return np.array(preds)\n\n",
            "block_group": "39959fb4c64f4c60afc75ff08de3a651",
            "execution_count": 173,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "b891d573",
                "execution_start": 1743810150558,
                "execution_millis": 184835,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "8ce5820af88a407fb285c7579ef47121",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# RUN MTL TRAINING\n# ==========================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Initialize model with correct class counts per task\ntask_classes = {\n    \"narrative_classification\": y_train_s2.shape[1],\n    \"entity_framing\": y_train_s1.shape[1]\n}\n\nmodel = MultiTaskTransformer(MODEL_NAME, task_classes).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.BCEWithLogitsLoss()\n\n# Run training loop\ntrain_mtl(\n    model=model,\n    loaders={\n        \"narrative_classification\": train_loader_nc,\n        \"entity_framing\": train_loader_ef\n    },\n    val_data={\n        \"narrative_classification\": (val_loader_nc, df_val_s2, y_val_s2, mlb_s2),\n        \"entity_framing\": (val_loader_ef, df_val_s1, y_val_s1, mlb_s1)\n    },\n    mlbs={\n        \"narrative_classification\": mlb_s2,\n        \"entity_framing\": mlb_s1\n    },\n    optimizer=optimizer,\n    criterion=criterion,\n    device=device,\n    epochs=EPOCHS\n)\n",
            "block_group": "cf8bb3367f684bb6b1f3211cd7c8d5b9",
            "execution_count": 179,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n Starting Epoch 1/3...\n\nEpoch 1 - Average MTL Loss: 0.6962\n\n Validating task: narrative_classification\n[narrative_classification] Macro F1: 0.0499\n Best model for task 'narrative_classification' saved to narrative_classification_MTL_CC_to_UA-CC.pt\n\n Validating task: entity_framing\n[entity_framing] Macro F1: 0.0559\n Best model for task 'entity_framing' saved to entity_framing_MTL_CC_to_UA-CC.pt\n\n Starting Epoch 2/3...\n\nEpoch 2 - Average MTL Loss: 0.4104\n\n Validating task: narrative_classification\n[narrative_classification] Macro F1: 0.1685\n Best model for task 'narrative_classification' saved to narrative_classification_MTL_CC_to_UA-CC.pt\n\n Validating task: entity_framing\n[entity_framing] Macro F1: 0.1257\n Best model for task 'entity_framing' saved to entity_framing_MTL_CC_to_UA-CC.pt\n\n Starting Epoch 3/3...\n\nEpoch 3 - Average MTL Loss: 0.3321\n\n Validating task: narrative_classification\n[narrative_classification] Macro F1: 0.2205\n Best model for task 'narrative_classification' saved to narrative_classification_MTL_CC_to_UA-CC.pt\n\n Validating task: entity_framing\n[entity_framing] Macro F1: 0.1755\n Best model for task 'entity_framing' saved to entity_framing_MTL_CC_to_UA-CC.pt\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/505ed495-ffd3-4591-8b6a-0c98d4b036d9",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "cell_id": "e7ab060673a04430bfdbb74d82db698a",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# FIXED THRESHOLD EVALUATION\n# ==========================\n\ndef evaluate_mtl(model, loader, df_source, y_true, mlb, task, label=\"TEST\", threshold=0.25):\n    model.eval()\n    y_pred, domains = [], []\n\n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(loader, desc=f\"Evaluating {label} [{task}]\")):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n\n            outputs = model(input_ids, attention_mask, task=task)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n            y_pred.extend(probs)\n\n            # track domain for each sample\n            start = i * loader.batch_size\n            end = start + len(probs)\n            domains.extend(df_source[\"Domain\"].iloc[start:end].tolist())\n\n    y_pred = np.array(y_pred)\n    y_true = np.array(y_true)\n    domains = np.array(domains)\n\n    y_pred_bin = (y_pred > threshold).astype(int)\n\n    # For narrative classification: filter unseen labels\n    if task == \"narrative_classification\":\n        mask = (y_true.sum(axis=0) + y_pred_bin.sum(axis=0)) > 0\n        y_true = y_true[:, mask]\n        y_pred_bin = y_pred_bin[:, mask]\n        filtered_labels = np.array(mlb.classes_)[mask]\n    else:\n        filtered_labels = mlb.classes_\n\n    macro = f1_score(y_true, y_pred_bin, average=\"macro\", zero_division=0)\n    micro = f1_score(y_true, y_pred_bin, average=\"micro\", zero_division=0)\n    exact = (y_pred_bin == y_true).all(axis=1).mean()\n\n    print(f\"\\n{label} ({task}) [Threshold={threshold:.2f}]\")\n    print(f\"Macro F1: {macro:.3f}\")\n    print(f\"Micro F1: {micro:.3f}\")\n    print(f\"Exact Match: {exact:.3f}\")\n\n    print(\"\\n----------------------------\")\n    print(\"Per-Domain Breakdown\")\n    print(\"----------------------------\")\n    for domain in np.unique(domains):\n        idx = np.where(domains == domain)[0]\n        y_true_d = y_true[idx]\n        y_pred_d = y_pred_bin[idx]\n\n        macro_d = f1_score(y_true_d, y_pred_d, average=\"macro\", zero_division=0)\n        micro_d = f1_score(y_true_d, y_pred_d, average=\"micro\", zero_division=0)\n        exact_d = (y_pred_d == y_true_d).all(axis=1).mean()\n\n        print(f\"\\nDomain: {domain}\")\n        print(f\"Macro F1: {macro_d:.3f}\")\n        print(f\"Micro F1: {micro_d:.3f}\")\n        print(f\"Exact Match: {exact_d:.3f}\")\n\n    return {\n        \"macro\": macro,\n        \"micro\": micro,\n        \"exact\": exact,\n        \"labels_used\": filtered_labels.tolist()\n    }\n",
            "block_group": "6174134d0632475ca674e55c7f1958e1",
            "execution_count": null,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "44b60c46",
                "execution_start": 1743810335456,
                "execution_millis": 10215,
                "execution_context_id": "be327afd-a242-4b93-b203-b8264a33c67d",
                "cell_id": "3a8f5d6e649f4df7acc3e46a56b6048b",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# TEST SET EVALUATION\n# ==========================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"\\n=========================\")\nprint(\"FINAL TEST EVALUATION\")\nprint(\"=========================\")\n\nfor task in [\"narrative_classification\", \"entity_framing\"]:\n    print(f\"\\n--- Task: {task.upper()} ---\")\n\n    # Load the best model \n    task_model_path = f\"{task}_MTL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\"\n    model.load_state_dict(torch.load(task_model_path))\n    model.to(device)\n    model.eval()\n\n    # Task-specific test data\n    test_loader, df_test, y_test, mlb = {\n        \"narrative_classification\": (test_loader_nc, df_test_s2, y_test_s2, mlb_s2),\n        \"entity_framing\": (test_loader_ef, df_test_s1, y_test_s1, mlb_s1)\n    }[task]\n\n    # Evaluate\n    evaluate_mtl(\n        model=model,\n        loader=test_loader,\n        df_source=df_test,\n        y_true=y_test,\n        mlb=mlb,\n        task=task,\n        label=\"TEST\"\n    )\n",
            "block_group": "d1a30da22d94497fabfa6c681d7a2157",
            "execution_count": 180,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\n=========================\nFINAL TEST EVALUATION\n=========================\n\n--- Task: NARRATIVE_CLASSIFICATION ---\nEvaluating TEST [narrative_classification]: 100%|██████████| 23/23 [00:02<00:00,  8.69it/s]\n\nTEST (narrative_classification) [Threshold=0.25]\nMacro F1: 0.116\nMicro F1: 0.229\nExact Match: 0.140\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\nDomain: CC\nMacro F1: 0.187\nMicro F1: 0.570\nExact Match: 0.315\n\nDomain: UA\nMacro F1: 0.016\nMicro F1: 0.025\nExact Match: 0.019\n\n--- Task: ENTITY_FRAMING ---\nEvaluating TEST [entity_framing]: 100%|██████████| 56/56 [00:06<00:00,  8.56it/s]\nTEST (entity_framing) [Threshold=0.25]\nMacro F1: 0.126\nMicro F1: 0.498\nExact Match: 0.145\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\nDomain: CC\nMacro F1: 0.165\nMicro F1: 0.713\nExact Match: 0.526\n\nDomain: UA\nMacro F1: 0.101\nMicro F1: 0.434\nExact Match: 0.040\n\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/e687aa21-a066-48f5-a7ad-6ceca2204177",
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=49d39932-ba1f-4621-a036-ab99ade88496' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
            "metadata": {
                "created_in_deepnote_cell": true,
                "deepnote_cell_type": "markdown"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "deepnote_notebook_id": "1b74d95545144d3db61cbfd11eaaedd2"
    }
}