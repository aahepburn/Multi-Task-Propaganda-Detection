{
    "cells": [
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "b618418e",
                "execution_start": 1744132031692,
                "execution_millis": 0,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "45b39c51560c4df5aef0095d8d79b60a",
                "deepnote_cell_type": "code"
            },
            "source": "import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DebertaV2Tokenizer, AutoModel, RobertaTokenizer\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, classification_report\nimport numpy as np\nimport shap\nfrom captum.attr import IntegratedGradients\nfrom transformers import AutoTokenizer\nimport torch.nn.functional as F\nimport hf_xet",
            "block_group": "05320c4fb99b445dba66cf205049fdf9",
            "execution_count": 79,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "093172d7275a4670884b0b95732e3bf2",
                "deepnote_cell_type": "markdown"
            },
            "source": "# Single-Task Learning\n\nBelow is the current pipeline for single-task learning. The code chunk bellow allows to switch between the two tasks: \"narrative_classification\" and \"entity_framing\".\n\nWe can also specify the training and test domains.",
            "block_group": "b415a08f22c9471c815c4e27d7d8e2be"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "63411438",
                "execution_start": 1744132032625,
                "execution_millis": 2,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "7324c81338a4473f88788141bd0b3060",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# CONTROL PANEL\n# ==========================\n\n# choose a task for the pipeline below: \"narrative_classification\" or \"entity_framing\"\nTASK = \"narrative_classification\"\n\n# select domains for training and testing: \"UA\"; \"CC\"; \"UA\", \"CC\";\nTRAIN_DOMAIN = [\"UA\",\"CC\"]\nTEST_DOMAIN = [\"UA\", \"CC\"] # The test data comes from a separate dataset. \n# The test data is always the same regardless of the domain we choose to train on. This is for consistency.\n\n\"\"\"\nNote that all articles are now in English, but if we wanted to control for e.g. certain cultural variations of a specific language,\nwe could exclude articles that were originally written in that language.\n\nNot to use the functionality, 'ALL' should be selected.\n\n\"\"\"\n# select languages for training and testing: \"ALL\";\"EN\";\"HI\";\"BG\";\"RU\";\"PT\"\nTRAIN_LANGUAGES = [\"ALL\"] \nTEST_LANGUAGES = [\"ALL\"]\n\n# debug mode -- reduced samples\nDEBUG_MODE = False\n\n# change the training hyperparameters here\nMODEL_NAME = \"roberta-base\" # OR \"deberta-v3-base\"\nMAX_LEN = 512\nBATCH_SIZE = 8\nEPOCHS = 3\nLEARNING_RATE = 2e-5\nMODEL_PATH = f\"{TASK}_STL_{'-'.join(TRAIN_DOMAIN)}_to_{'-'.join(TEST_DOMAIN)}.pt\" # -- to save the model later\n",
            "block_group": "dffc3ccb17bc445e96e81bb3c0e11639",
            "execution_count": 81,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "7bb4e15e",
                "execution_start": 1744132033039,
                "execution_millis": 618,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "5670c41a353649f486be16f4968fc6ce",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# LOAD AND MERGE DATA\n# ==========================\n\narticles = pd.read_csv(\"train-all-articles.csv\")\ns1 = pd.read_csv(\"train-S1-labels.csv\")\ns2 = pd.read_csv(\"train-S2-labels.csv\")\n\ntest_s1_articles = pd.read_csv(\"test-S1-articles.csv\")\ntest_s1_labels = pd.read_csv(\"test-S1-labels.csv\")\ntest_s2_articles = pd.read_csv(\"test-S2-articles.csv\")\ntest_s2_labels = pd.read_csv(\"test-S2-labels.csv\")\n\n# ==========================\n# STANDARDISE TEST SET COLUMNS\n# ==========================\n\nif TASK == \"entity_framing\":\n    test_s1_labels.rename(columns={\"Translated_Entity\": \"Entity\"}, inplace=True)\nelif TASK == \"narrative_classification\":\n    test_s2_labels.columns = [\"Filename\", \"Narrative\", \"Subnarrative\"]\n\n# ==========================\n# FILTER + SPLIT TRAIN/VAL\n# ==========================\n\n# filter domains/languages for train/val\nfiltered_articles = articles[articles[\"Domain\"].isin(TRAIN_DOMAIN)]\nif \"ALL\" not in TRAIN_LANGUAGES:\n    filtered_articles = filtered_articles[filtered_articles[\"Language\"].isin(TRAIN_LANGUAGES)]\n\n# 80/20 train/val split\nfiltered_articles = filtered_articles.sample(frac=1, random_state=42).reset_index(drop=True)\nsplit_idx = int(0.8 * len(filtered_articles))\ntrain_articles = filtered_articles.iloc[:split_idx].copy()\nval_articles = filtered_articles.iloc[split_idx:].copy()\n\n# debug subsampling if needed -- off by default\nif DEBUG_MODE:\n    train_articles = train_articles.sample(100)\n    val_articles = val_articles.sample(100)\n    test_s1_articles = test_s1_articles.sample(100)\n    test_s2_articles = test_s2_articles.sample(100)\n",
            "block_group": "f1dd3339e778493fa7f5cc455f638f45",
            "execution_count": 83,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "ed0f8f6c",
                "execution_start": 1744132033723,
                "execution_millis": 0,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "881a3e6ae539492f91e6a0afac0b946f",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# TASK-SPECIFIC MERGE + PROCESSING\n# ==========================\n\nif TASK == \"narrative_classification\":\n    # Merge articles with S2 labels\n    df_train = pd.merge(train_articles, s2, on=\"Filename\")\n    df_val   = pd.merge(val_articles, s2, on=\"Filename\")\n    df_test  = pd.merge(test_s2_articles, test_s2_labels, on=\"Filename\")\n\n    TEXT_COL = \"Translated_Text\"\n    LABEL_COL = \"Narrative\"\n\n    for df in [df_train, df_val, df_test]:\n        df.dropna(subset=[TEXT_COL, LABEL_COL], inplace=True)\n        df[LABEL_COL] = df[LABEL_COL].apply(\n            lambda x: [s.strip() for s in str(x).split(\";\") if s.strip().lower() != \"nan\"]\n        )\n\n    # Create shared label space from all available narrative data (zero-shot setup)\n    full_set = pd.concat([df_train, df_val, df_test])\n    mlb = MultiLabelBinarizer()\n    mlb.fit(full_set[LABEL_COL])\n\n    y_train = mlb.transform(df_train[LABEL_COL])\n    y_val   = mlb.transform(df_val[LABEL_COL])\n    y_test  = mlb.transform(df_test[LABEL_COL])\n    num_classes = len(mlb.classes_)\n\nelif TASK == \"entity_framing\":\n    # Merge entity labels with articles\n    df_train = pd.merge(s1, train_articles, on=\"Filename\")\n    df_val   = pd.merge(s1, val_articles, on=\"Filename\")\n    df_test  = pd.merge(test_s1_labels, test_s1_articles, on=\"Filename\")\n\n    TEXT_COL = \"Translated_Text\"\n    LABEL_COL = \"Label\"\n\n    def insert_entity_marker(text, start, end):\n        try:\n            start, end = int(start), int(end)\n            return text[:start] + \"[ENTITY]\" + text[start:end] + \"[/ENTITY]\" + text[end:]\n        except:\n            return text\n\n    for df in [df_train, df_val, df_test]:\n        df.dropna(subset=[TEXT_COL, \"Entity\", LABEL_COL, \"Start\", \"End\"], inplace=True)\n        df[\"Start\"] = df[\"Start\"].astype(int)\n        df[\"End\"] = df[\"End\"].astype(int)\n        df[\"Input_Text\"] = df.apply(lambda row: insert_entity_marker(row[TEXT_COL], row[\"Start\"], row[\"End\"]), axis=1)\n        df[LABEL_COL] = df[LABEL_COL].apply(lambda x: [s.strip() for s in str(x).split(\",\") if s.strip().lower() != \"nan\"])\n\n    # For entity framing, create a separate label binarizer\n    mlb = MultiLabelBinarizer()\n    mlb.fit(df_train[LABEL_COL] + df_val[LABEL_COL] + df_test[LABEL_COL])  # full entity label space\n\n    y_train = mlb.transform(df_train[LABEL_COL])\n    y_val   = mlb.transform(df_val[LABEL_COL])\n    y_test  = mlb.transform(df_test[LABEL_COL])\n    num_classes = len(mlb.classes_)\n\nelse:\n    raise ValueError(\"Unknown TASK specified.\")\n",
            "block_group": "b35900c3aeb64991a6d1123c456e6404",
            "execution_count": 84,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "65d4f76c",
                "execution_start": 1744132034118,
                "execution_millis": 100,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "e6f1d2f4d7a64f2e95aad2b5d0f8dcbe",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# TOKENISATION and DATASET CLASS\n# ==========================\n\ntokenizer = RobertaTokenizer.from_pretrained(MODEL_NAME)\n#tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n\nclass MultiLabelDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoding = self.tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            return_tensors=\"pt\"\n        )\n\n        return {\n            \"input_ids\": encoding[\"input_ids\"].squeeze(),\n            \"attention_mask\": encoding[\"attention_mask\"].squeeze(),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float)\n        }\n\ntrain_dataset = MultiLabelDataset(df_train[TEXT_COL].tolist(), y_train, tokenizer, MAX_LEN)\nval_dataset   = MultiLabelDataset(df_val[TEXT_COL].tolist(), y_val, tokenizer, MAX_LEN)\ntest_dataset  = MultiLabelDataset(df_test[TEXT_COL].tolist(), y_test, tokenizer, MAX_LEN)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)\ntest_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
            "block_group": "e393f42d1f384c04983bf5ead6b2dcfe",
            "execution_count": 86,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "/root/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "dbtable:cell_outputs/26036d8f-5036-4bd4-aa68-8cb6c526ef02",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "cd251d89",
                "execution_start": 1744131159620,
                "execution_millis": 3,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "0e9553dd909e442eb5b12e047ebb3135",
                "deepnote_cell_type": "code"
            },
            "source": "# Optional oversampling\n\n# Get training texts based on task type\nif TASK == \"narrative_classification\":\n    train_texts_raw = df_train[\"Translated_Text\"].tolist()\nelif TASK == \"entity_framing\":\n    train_texts_raw = df_train[\"Input_Text\"].tolist()\nelse:\n    raise ValueError(\"TASK must be either 'narrative_classification' or 'entity_framing'.\")\n\n# 1. Compute label frequency\nlabel_counts = np.sum(y_train, axis=0)\n\n# 2. Score each sample by rarity of its labels\nsample_weights = (y_train * (1 / (label_counts + 1e-6))).sum(axis=1)\nsample_weights = sample_weights / sample_weights.sum()\n\n# 3. Resample indices with replacement\nindices = np.arange(len(y_train))\nresampled_indices = np.random.choice(indices, size=len(indices), replace=True, p=sample_weights)\n\n# 4. Create oversampled dataset\ntrain_texts_resampled = [train_texts_raw[i] for i in resampled_indices]\ny_train_resampled = y_train[resampled_indices]\n\n# 5. Rebuild Dataset & Dataloader\ntrain_dataset = MultiLabelDataset(train_texts_resampled, y_train_resampled, tokenizer, MAX_LEN)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
            "block_group": "1bf8ba63586c410a81c2e5b0b988fb2f",
            "execution_count": 66,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "23c1e26e",
                "execution_start": 1744131162363,
                "execution_millis": 0,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "229e126177bc4ffc8c8198ff3e1e35bc",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# MODEL CLASS\n# ==========================\n\nclass TransformerClassifier(nn.Module):\n    def __init__(self, model_name, num_classes):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        self.classifier = nn.Linear(self.encoder.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n        pooled_output = self.dropout(pooled_output)\n        return self.classifier(pooled_output)\n",
            "block_group": "6aaa0cfc62de4dca9e058c7a16dfa66a",
            "execution_count": 68,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "cdc23198",
                "execution_start": 1744131163725,
                "execution_millis": 2,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "a5a87c4942b84a8c8b53fa5141a210d9",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# TRAINING UTILS\n# ==========================\n\ndef predict_proba(model, loader, device):\n    model.eval()\n    probs = []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            outputs = model(input_ids, attention_mask)\n            probs.extend(torch.sigmoid(outputs).cpu().numpy())\n    return np.array(probs)\n\ndef evaluate_threshold_sweep(y_true, y_pred, thresholds=np.arange(0.1, 0.9, 0.05)):\n    best_thresh = 0.5\n    best_f1 = 0\n    results = []\n\n    for thresh in thresholds:\n        y_pred_bin = (y_pred > thresh).astype(int)\n        macro = f1_score(y_true, y_pred_bin, average='macro', zero_division=0)\n        micro = f1_score(y_true, y_pred_bin, average='micro', zero_division=0)\n        exact = (y_pred_bin == y_true).all(axis=1).mean()\n\n        results.append((thresh, macro, micro, exact))\n        if macro > best_f1:\n            best_f1 = macro\n            best_thresh = thresh\n\n    print(\"Threshold sweep results:\")\n    for t, macro, micro, exact in results:\n        print(f\"Thresh {t:.2f} | Macro F1: {macro:.3f} | Micro F1: {micro:.3f} | Exact Match: {exact:.3f}\")\n\n    print(f\"\\n Best threshold = {best_thresh:.2f} with Macro F1 = {best_f1:.3f}\")\n    return best_thresh\n",
            "block_group": "2b4954ddc86847acba53c843cb1eeb6c",
            "execution_count": 70,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "b623e53d",
                "execution_start": 1744131165768,
                "execution_millis": 1,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "009ace357e92429f978b7cb11d934d3a",
                "deepnote_cell_type": "code"
            },
            "source": "",
            "block_group": "81c0530c0a24456090264de911d72d3b",
            "execution_count": 72,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "eb4f1d5",
                "execution_start": 1744131167323,
                "execution_millis": 278928,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "e7a491996a1b403eb5f26dd3c967f3e7",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# TRAINING LOOP\n# ==========================\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TransformerClassifier(MODEL_NAME, num_classes).to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.BCEWithLogitsLoss()\nbest_macro_f1 = 0.0 \n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(input_ids, attention_mask)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    print(f\"\\nEpoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n\n    # validation\n    val_probs = predict_proba(model, val_loader, device)\n    threshold = evaluate_threshold_sweep(y_val, val_probs)\n    y_val_pred = (val_probs > threshold).astype(int)\n    macro_f1 = f1_score(y_val, y_val_pred, average=\"macro\", zero_division=0)\n    print(f\"Validation Macro F1 (Epoch {epoch+1}): {macro_f1:.4f}\")\n\n    if macro_f1 > best_macro_f1:\n        best_macro_f1 = macro_f1\n        torch.save(model.state_dict(), MODEL_PATH)\n        print(f\"Saved best model (Epoch {epoch+1}) to {MODEL_PATH}\")\n",
            "block_group": "6088e635ebcb4dd69a28c65254265f5a",
            "execution_count": 73,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "/root/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1: 100%|██████████| 192/192 [01:20<00:00,  2.40it/s]\n\nEpoch 1: Loss = 0.3231\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.296 | Micro F1: 0.304 | Exact Match: 0.000\nThresh 0.15 | Macro F1: 0.320 | Micro F1: 0.349 | Exact Match: 0.010\nThresh 0.20 | Macro F1: 0.349 | Micro F1: 0.407 | Exact Match: 0.045\nThresh 0.25 | Macro F1: 0.342 | Micro F1: 0.437 | Exact Match: 0.068\nThresh 0.30 | Macro F1: 0.348 | Micro F1: 0.451 | Exact Match: 0.084\nThresh 0.35 | Macro F1: 0.351 | Micro F1: 0.469 | Exact Match: 0.108\nThresh 0.40 | Macro F1: 0.340 | Micro F1: 0.478 | Exact Match: 0.113\nThresh 0.45 | Macro F1: 0.306 | Micro F1: 0.479 | Exact Match: 0.113\nThresh 0.50 | Macro F1: 0.272 | Micro F1: 0.479 | Exact Match: 0.152\nThresh 0.55 | Macro F1: 0.237 | Micro F1: 0.453 | Exact Match: 0.139\nThresh 0.60 | Macro F1: 0.199 | Micro F1: 0.415 | Exact Match: 0.139\nThresh 0.65 | Macro F1: 0.163 | Micro F1: 0.328 | Exact Match: 0.121\nThresh 0.70 | Macro F1: 0.120 | Micro F1: 0.226 | Exact Match: 0.100\nThresh 0.75 | Macro F1: 0.078 | Micro F1: 0.135 | Exact Match: 0.081\nThresh 0.80 | Macro F1: 0.050 | Micro F1: 0.093 | Exact Match: 0.066\nThresh 0.85 | Macro F1: 0.033 | Micro F1: 0.053 | Exact Match: 0.037\n\n Best threshold = 0.35 with Macro F1 = 0.351\nValidation Macro F1 (Epoch 1): 0.3505\nSaved best model (Epoch 1) to narrative_classification_STL_UA-CC_to_UA-CC.pt\nEpoch 2: 100%|██████████| 192/192 [01:21<00:00,  2.35it/s]\n\nEpoch 2: Loss = 0.1991\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.355 | Micro F1: 0.388 | Exact Match: 0.008\nThresh 0.15 | Macro F1: 0.390 | Micro F1: 0.454 | Exact Match: 0.052\nThresh 0.20 | Macro F1: 0.393 | Micro F1: 0.495 | Exact Match: 0.076\nThresh 0.25 | Macro F1: 0.405 | Micro F1: 0.523 | Exact Match: 0.108\nThresh 0.30 | Macro F1: 0.407 | Micro F1: 0.533 | Exact Match: 0.134\nThresh 0.35 | Macro F1: 0.398 | Micro F1: 0.529 | Exact Match: 0.152\nThresh 0.40 | Macro F1: 0.389 | Micro F1: 0.516 | Exact Match: 0.178\nThresh 0.45 | Macro F1: 0.372 | Micro F1: 0.505 | Exact Match: 0.165\nThresh 0.50 | Macro F1: 0.351 | Micro F1: 0.481 | Exact Match: 0.160\nThresh 0.55 | Macro F1: 0.326 | Micro F1: 0.448 | Exact Match: 0.160\nThresh 0.60 | Macro F1: 0.284 | Micro F1: 0.411 | Exact Match: 0.155\nThresh 0.65 | Macro F1: 0.233 | Micro F1: 0.370 | Exact Match: 0.134\nThresh 0.70 | Macro F1: 0.209 | Micro F1: 0.326 | Exact Match: 0.113\nThresh 0.75 | Macro F1: 0.170 | Micro F1: 0.267 | Exact Match: 0.092\nThresh 0.80 | Macro F1: 0.130 | Micro F1: 0.198 | Exact Match: 0.058\nThresh 0.85 | Macro F1: 0.085 | Micro F1: 0.115 | Exact Match: 0.037\n\n Best threshold = 0.30 with Macro F1 = 0.407\nValidation Macro F1 (Epoch 2): 0.4072\nSaved best model (Epoch 2) to narrative_classification_STL_UA-CC_to_UA-CC.pt\nEpoch 3: 100%|██████████| 192/192 [01:23<00:00,  2.31it/s]\n\nEpoch 3: Loss = 0.1453\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.404 | Micro F1: 0.478 | Exact Match: 0.039\nThresh 0.15 | Macro F1: 0.423 | Micro F1: 0.518 | Exact Match: 0.071\nThresh 0.20 | Macro F1: 0.435 | Micro F1: 0.539 | Exact Match: 0.087\nThresh 0.25 | Macro F1: 0.450 | Micro F1: 0.557 | Exact Match: 0.115\nThresh 0.30 | Macro F1: 0.446 | Micro F1: 0.556 | Exact Match: 0.136\nThresh 0.35 | Macro F1: 0.423 | Micro F1: 0.549 | Exact Match: 0.165\nThresh 0.40 | Macro F1: 0.417 | Micro F1: 0.550 | Exact Match: 0.186\nThresh 0.45 | Macro F1: 0.398 | Micro F1: 0.535 | Exact Match: 0.192\nThresh 0.50 | Macro F1: 0.385 | Micro F1: 0.521 | Exact Match: 0.207\nThresh 0.55 | Macro F1: 0.373 | Micro F1: 0.517 | Exact Match: 0.205\nThresh 0.60 | Macro F1: 0.339 | Micro F1: 0.496 | Exact Match: 0.192\nThresh 0.65 | Macro F1: 0.291 | Micro F1: 0.457 | Exact Match: 0.178\nThresh 0.70 | Macro F1: 0.268 | Micro F1: 0.412 | Exact Match: 0.160\nThresh 0.75 | Macro F1: 0.241 | Micro F1: 0.384 | Exact Match: 0.144\nThresh 0.80 | Macro F1: 0.217 | Micro F1: 0.329 | Exact Match: 0.115\nThresh 0.85 | Macro F1: 0.181 | Micro F1: 0.281 | Exact Match: 0.097\n\n Best threshold = 0.25 with Macro F1 = 0.450\nValidation Macro F1 (Epoch 3): 0.4502\nSaved best model (Epoch 3) to narrative_classification_STL_UA-CC_to_UA-CC.pt\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/32568e96-ccfb-484c-8a6b-cce426ae3638",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "is_code_hidden": false,
                "deepnote_to_be_reexecuted": true,
                "deepnote_app_is_code_hidden": true,
                "cell_id": "8968163ea1b74925be9da1fdbd8afcdf",
                "deepnote_cell_type": "code"
            },
            "source": "torch.cuda.empty_cache()",
            "block_group": "5c86f24778cd445194873f12829216a4",
            "execution_count": null,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "a8c2963b",
                "execution_start": 1744131451829,
                "execution_millis": 2,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "1fcf5c74c61e49d2ad7c402616547439",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# FIXED THRESHOLD EVALUATION\n# ==========================\n\ndef evaluate(loader, df_source, mlb, label=\"TEST\", threshold=0.25): \n\n    \"\"\"\n    Evaluates a multi-label classification model using a fixed probability threshold.\n\n    Args:\n        loader (DataLoader): A PyTorch DataLoader yielding batches of tokenised input data\n        df_source (pd.DataFrame): Source dataframe containing metadata for each example, including domain info.\n        mlb (MultiLabelBinarizer): The fitted multi-label binarizer used for encoding and decoding labels.\n        label (str, optional): Label for the dataset (e.g., 'TEST', 'VALIDATION'). Used for logging. Defaults to \"TEST\".\n        threshold (float, optional): Probability threshold to convert predicted probabilities into binary labels. Defaults to 0.25.\n\n    Returns:\n        dict: A dictionary containing overall macro F1, micro F1, exact match score, \n              the threshold used, and the list of labels used after filtering.\n              Also prints per-domain breakdowns of these metrics.\n\n    Notes:\n        - Filters out labels that are completely unseen in both predictions and ground truths \n          to avoid skewed metric calculations.\n        - Performs evaluation on the entire dataset as well as broken down by domain.\n    \"\"\"\n    model.eval()\n    y_true, y_pred, domains = [], [], []\n\n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(loader, desc=f\"Evaluating {label}\")):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].cpu().numpy()\n\n            outputs = model(input_ids, attention_mask)\n            probs = torch.sigmoid(outputs).cpu().numpy()\n\n            y_pred.extend(probs)\n            y_true.extend(labels)\n\n            start = i * loader.batch_size\n            end = start + len(labels)\n            domains.extend(df_source[\"Domain\"].iloc[start:end].tolist())\n\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    domains = np.array(domains)\n\n    y_pred_bin = (y_pred > threshold).astype(int)\n\n    # filter columns where y_true or y_pred has no samples (i.e., unseen label)\n    mask = (y_true.sum(axis=0) + y_pred_bin.sum(axis=0)) > 0\n    y_true = y_true[:, mask]\n    y_pred_bin = y_pred_bin[:, mask]\n    filtered_labels = np.array(mlb.classes_)[mask]\n\n    macro = f1_score(y_true, y_pred_bin, average=\"macro\", zero_division=0)\n    micro = f1_score(y_true, y_pred_bin, average=\"micro\", zero_division=0)\n    exact = (y_pred_bin == y_true).all(axis=1).mean()\n\n    print(f\"\\n {label} (Fixed Threshold={threshold:.2f}):\")\n    print(f\"Macro F1: {macro:.3f}\")\n    print(f\"Micro F1: {micro:.3f}\")\n    print(f\"Exact Match: {exact:.3f}\")\n\n    print(\"\\n----------------------------\")\n    print(\"Per-Domain Breakdown\")\n    print(\"----------------------------\")\n    for domain in np.unique(domains):\n        idx = np.where(domains == domain)[0]\n        y_true_d = y_true[idx]\n        y_pred_d = y_pred_bin[idx]\n\n        macro_d = f1_score(y_true_d, y_pred_d, average=\"macro\", zero_division=0)\n        micro_d = f1_score(y_true_d, y_pred_d, average=\"micro\", zero_division=0)\n        exact_d = (y_pred_d == y_true_d).all(axis=1).mean()\n\n        print(f\"\\n Domain: {domain}\")\n        print(f\"Macro F1: {macro_d:.3f}\")\n        print(f\"Micro F1: {micro_d:.3f}\")\n        print(f\"Exact Match: {exact_d:.3f}\")\n\n    return {\n        \"macro\": macro,\n        \"micro\": micro,\n        \"exact\": exact,\n        \"threshold\": threshold,\n        \"labels_used\": filtered_labels.tolist()\n    }\n\n\ndef evaluate_and_compare_fixed_thresh(val_loader, df_val, test_loader, df_test, mlb, threshold=0.25):\n    print(\"\\n=========================\")\n    print(\"Validation (Fixed Threshold)\")\n    print(\"=========================\")\n    val_results = evaluate(val_loader, df_val.reset_index(drop=True), mlb, label=\"VALIDATION\", threshold=threshold)\n\n    print(\"\\n=========================\")\n    print(\"Test (Fixed Threshold)\")\n    print(\"=========================\")\n    test_results = evaluate(test_loader, df_test.reset_index(drop=True), mlb, label=\"TEST\", threshold=threshold)\n\n    print(\"\\n=========================\")\n    print(\"OOD Generalization (Fixed Threshold)\")\n    print(\"=========================\")\n    macro_drop = val_results[\"macro\"] - test_results[\"macro\"]\n    print(f\"Δ Macro F1 (val - test): {macro_drop:.3f}\")\n\n    return {\n        \"val\": val_results,\n        \"test\": test_results,\n        \"ood_gap_macro\": macro_drop\n    }\n\n",
            "block_group": "4534ee0a07354a7b9f2d3059ed80f04c",
            "execution_count": 75,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "cd92cb6",
                "execution_start": 1744131452531,
                "execution_millis": 10431,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "1b851481c1b042be861911bb65ce2451",
                "deepnote_cell_type": "code"
            },
            "source": "results = evaluate_and_compare_fixed_thresh(\n    val_loader, df_val,\n    test_loader, df_test,\n    mlb\n)",
            "block_group": "8da600d15a9a4975941b526e11598804",
            "execution_count": 77,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\n=========================\nValidation (Fixed Threshold)\n=========================\nEvaluating VALIDATION: 100%|██████████| 48/48 [00:07<00:00,  6.82it/s]\n\n VALIDATION (Fixed Threshold=0.25):\nMacro F1: 0.450\nMicro F1: 0.557\nExact Match: 0.115\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\n Domain: CC\nMacro F1: 0.264\nMicro F1: 0.584\nExact Match: 0.239\n\n Domain: UA\nMacro F1: 0.235\nMicro F1: 0.546\nExact Match: 0.063\n\n=========================\nTest (Fixed Threshold)\n=========================\nEvaluating TEST: 100%|██████████| 23/23 [00:03<00:00,  6.84it/s]\n\n TEST (Fixed Threshold=0.25):\nMacro F1: 0.396\nMicro F1: 0.526\nExact Match: 0.129\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\n Domain: CC\nMacro F1: 0.226\nMicro F1: 0.573\nExact Match: 0.260\n\n Domain: UA\nMacro F1: 0.197\nMicro F1: 0.499\nExact Match: 0.038\n\n=========================\nOOD Generalization (Fixed Threshold)\n=========================\nΔ Macro F1 (val - test): 0.054\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/648bd1d9-1d20-4b73-a814-adeac3718d0d",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "cc20b09",
                "execution_start": 1744132460892,
                "execution_millis": 843407,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "e66dbdde87054334b715a3c2ea1e9773",
                "deepnote_cell_type": "code"
            },
            "source": "## Alternative Training Loop: Ensemble\n\n\n# ==========================\n# ENSEMBLE TRAINING LOOP\n# ==========================\n\nfor run_id in range(1, 4):  # Train 3 models for the ensemble\n    print(f\"\\n=== Training Model {run_id}/3 ===\")\n    \n    torch.manual_seed(42 + run_id)\n    np.random.seed(42 + run_id)\n\n    model = TransformerClassifier(MODEL_NAME, num_classes).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.BCEWithLogitsLoss()\n    best_macro_f1 = 0.0 \n    MODEL_PATH_RUN = MODEL_PATH.replace(\".pt\", f\"_{run_id}.pt\")\n\n    for epoch in range(EPOCHS):\n        model.train()\n        total_loss = 0\n        for batch in tqdm(train_loader, desc=f\"[Model {run_id}] Epoch {epoch+1}\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        print(f\"\\n[Model {run_id}] Epoch {epoch+1}: Loss = {total_loss / len(train_loader):.4f}\")\n\n        val_probs = predict_proba(model, val_loader, device)\n        threshold = evaluate_threshold_sweep(y_val, val_probs)\n        y_val_pred = (val_probs > threshold).astype(int)\n        macro_f1 = f1_score(y_val, y_val_pred, average=\"macro\", zero_division=0)\n        print(f\"[Model {run_id}] Validation Macro F1 (Epoch {epoch+1}): {macro_f1:.4f}\")\n\n        if macro_f1 > best_macro_f1:\n            best_macro_f1 = macro_f1\n            torch.save(model.state_dict(), MODEL_PATH_RUN)\n            print(f\" Saved best Model {run_id} (Epoch {epoch+1}) to {MODEL_PATH_RUN}\")\n",
            "block_group": "98242eead7d04bb68c5c3ee5f11522f5",
            "execution_count": 88,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\n=== Training Model 1/3 ===\n/root/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n[Model 1] Epoch 1: 100%|██████████| 192/192 [01:19<00:00,  2.41it/s]\n\n[Model 1] Epoch 1: Loss = 0.2728\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.239 | Micro F1: 0.394 | Exact Match: 0.000\nThresh 0.15 | Macro F1: 0.236 | Micro F1: 0.462 | Exact Match: 0.013\nThresh 0.20 | Macro F1: 0.206 | Micro F1: 0.506 | Exact Match: 0.150\nThresh 0.25 | Macro F1: 0.178 | Micro F1: 0.483 | Exact Match: 0.197\nThresh 0.30 | Macro F1: 0.125 | Micro F1: 0.387 | Exact Match: 0.157\nThresh 0.35 | Macro F1: 0.096 | Micro F1: 0.342 | Exact Match: 0.142\nThresh 0.40 | Macro F1: 0.078 | Micro F1: 0.287 | Exact Match: 0.129\nThresh 0.45 | Macro F1: 0.067 | Micro F1: 0.235 | Exact Match: 0.123\nThresh 0.50 | Macro F1: 0.059 | Micro F1: 0.196 | Exact Match: 0.115\nThresh 0.55 | Macro F1: 0.043 | Micro F1: 0.124 | Exact Match: 0.084\nThresh 0.60 | Macro F1: 0.036 | Micro F1: 0.091 | Exact Match: 0.071\nThresh 0.65 | Macro F1: 0.025 | Micro F1: 0.051 | Exact Match: 0.037\nThresh 0.70 | Macro F1: 0.015 | Micro F1: 0.027 | Exact Match: 0.021\nThresh 0.75 | Macro F1: 0.002 | Micro F1: 0.003 | Exact Match: 0.000\nThresh 0.80 | Macro F1: 0.000 | Micro F1: 0.000 | Exact Match: 0.000\nThresh 0.85 | Macro F1: 0.000 | Micro F1: 0.000 | Exact Match: 0.000\n\n Best threshold = 0.10 with Macro F1 = 0.239\n[Model 1] Validation Macro F1 (Epoch 1): 0.2393\n✅ Saved best Model 1 (Epoch 1) to narrative_classification_STL_UA-CC_to_UA-CC_1.pt\n[Model 1] Epoch 2: 100%|██████████| 192/192 [01:21<00:00,  2.36it/s]\n\n[Model 1] Epoch 2: Loss = 0.1926\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.339 | Micro F1: 0.461 | Exact Match: 0.008\nThresh 0.15 | Macro F1: 0.374 | Micro F1: 0.527 | Exact Match: 0.092\nThresh 0.20 | Macro F1: 0.379 | Micro F1: 0.569 | Exact Match: 0.205\nThresh 0.25 | Macro F1: 0.358 | Micro F1: 0.576 | Exact Match: 0.252\nThresh 0.30 | Macro F1: 0.304 | Micro F1: 0.561 | Exact Match: 0.281\nThresh 0.35 | Macro F1: 0.282 | Micro F1: 0.539 | Exact Match: 0.283\nThresh 0.40 | Macro F1: 0.220 | Micro F1: 0.503 | Exact Match: 0.257\nThresh 0.45 | Macro F1: 0.214 | Micro F1: 0.488 | Exact Match: 0.231\nThresh 0.50 | Macro F1: 0.192 | Micro F1: 0.455 | Exact Match: 0.205\nThresh 0.55 | Macro F1: 0.162 | Micro F1: 0.404 | Exact Match: 0.178\nThresh 0.60 | Macro F1: 0.146 | Micro F1: 0.364 | Exact Match: 0.165\nThresh 0.65 | Macro F1: 0.111 | Micro F1: 0.302 | Exact Match: 0.142\nThresh 0.70 | Macro F1: 0.097 | Micro F1: 0.263 | Exact Match: 0.129\nThresh 0.75 | Macro F1: 0.087 | Micro F1: 0.225 | Exact Match: 0.118\nThresh 0.80 | Macro F1: 0.067 | Micro F1: 0.164 | Exact Match: 0.097\nThresh 0.85 | Macro F1: 0.039 | Micro F1: 0.091 | Exact Match: 0.068\n\n Best threshold = 0.20 with Macro F1 = 0.379\n[Model 1] Validation Macro F1 (Epoch 2): 0.3794\n✅ Saved best Model 1 (Epoch 2) to narrative_classification_STL_UA-CC_to_UA-CC_1.pt\n[Model 1] Epoch 3: 100%|██████████| 192/192 [01:23<00:00,  2.31it/s]\n\n[Model 1] Epoch 3: Loss = 0.1644\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.419 | Micro F1: 0.527 | Exact Match: 0.113\nThresh 0.15 | Macro F1: 0.400 | Micro F1: 0.563 | Exact Match: 0.215\nThresh 0.20 | Macro F1: 0.405 | Micro F1: 0.582 | Exact Match: 0.262\nThresh 0.25 | Macro F1: 0.401 | Micro F1: 0.579 | Exact Match: 0.283\nThresh 0.30 | Macro F1: 0.373 | Micro F1: 0.568 | Exact Match: 0.294\nThresh 0.35 | Macro F1: 0.361 | Micro F1: 0.564 | Exact Match: 0.307\nThresh 0.40 | Macro F1: 0.347 | Micro F1: 0.542 | Exact Match: 0.304\nThresh 0.45 | Macro F1: 0.326 | Micro F1: 0.507 | Exact Match: 0.278\nThresh 0.50 | Macro F1: 0.299 | Micro F1: 0.469 | Exact Match: 0.270\nThresh 0.55 | Macro F1: 0.255 | Micro F1: 0.426 | Exact Match: 0.255\nThresh 0.60 | Macro F1: 0.225 | Micro F1: 0.382 | Exact Match: 0.228\nThresh 0.65 | Macro F1: 0.161 | Micro F1: 0.323 | Exact Match: 0.199\nThresh 0.70 | Macro F1: 0.129 | Micro F1: 0.267 | Exact Match: 0.165\nThresh 0.75 | Macro F1: 0.100 | Micro F1: 0.223 | Exact Match: 0.152\nThresh 0.80 | Macro F1: 0.082 | Micro F1: 0.182 | Exact Match: 0.121\nThresh 0.85 | Macro F1: 0.051 | Micro F1: 0.125 | Exact Match: 0.089\n\n Best threshold = 0.10 with Macro F1 = 0.419\n[Model 1] Validation Macro F1 (Epoch 3): 0.4194\n✅ Saved best Model 1 (Epoch 3) to narrative_classification_STL_UA-CC_to_UA-CC_1.pt\n\n=== Training Model 2/3 ===\n/root/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n[Model 2] Epoch 1: 100%|██████████| 192/192 [01:23<00:00,  2.30it/s]\n\n[Model 2] Epoch 1: Loss = 0.2670\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.226 | Micro F1: 0.379 | Exact Match: 0.003\nThresh 0.15 | Macro F1: 0.243 | Micro F1: 0.434 | Exact Match: 0.008\nThresh 0.20 | Macro F1: 0.211 | Micro F1: 0.430 | Exact Match: 0.050\nThresh 0.25 | Macro F1: 0.135 | Micro F1: 0.390 | Exact Match: 0.105\nThresh 0.30 | Macro F1: 0.100 | Micro F1: 0.385 | Exact Match: 0.131\nThresh 0.35 | Macro F1: 0.087 | Micro F1: 0.378 | Exact Match: 0.139\nThresh 0.40 | Macro F1: 0.085 | Micro F1: 0.382 | Exact Match: 0.142\nThresh 0.45 | Macro F1: 0.089 | Micro F1: 0.384 | Exact Match: 0.139\nThresh 0.50 | Macro F1: 0.088 | Micro F1: 0.356 | Exact Match: 0.142\nThresh 0.55 | Macro F1: 0.073 | Micro F1: 0.280 | Exact Match: 0.123\nThresh 0.60 | Macro F1: 0.058 | Micro F1: 0.206 | Exact Match: 0.097\nThresh 0.65 | Macro F1: 0.035 | Micro F1: 0.088 | Exact Match: 0.060\nThresh 0.70 | Macro F1: 0.008 | Micro F1: 0.014 | Exact Match: 0.010\nThresh 0.75 | Macro F1: 0.000 | Micro F1: 0.000 | Exact Match: 0.000\nThresh 0.80 | Macro F1: 0.000 | Micro F1: 0.000 | Exact Match: 0.000\nThresh 0.85 | Macro F1: 0.000 | Micro F1: 0.000 | Exact Match: 0.000\n\n Best threshold = 0.15 with Macro F1 = 0.243\n[Model 2] Validation Macro F1 (Epoch 1): 0.2432\n✅ Saved best Model 2 (Epoch 1) to narrative_classification_STL_UA-CC_to_UA-CC_2.pt\n[Model 2] Epoch 2: 100%|██████████| 192/192 [01:23<00:00,  2.29it/s]\n\n[Model 2] Epoch 2: Loss = 0.1947\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.350 | Micro F1: 0.466 | Exact Match: 0.034\nThresh 0.15 | Macro F1: 0.332 | Micro F1: 0.519 | Exact Match: 0.108\nThresh 0.20 | Macro F1: 0.332 | Micro F1: 0.558 | Exact Match: 0.181\nThresh 0.25 | Macro F1: 0.302 | Micro F1: 0.562 | Exact Match: 0.244\nThresh 0.30 | Macro F1: 0.274 | Micro F1: 0.556 | Exact Match: 0.268\nThresh 0.35 | Macro F1: 0.244 | Micro F1: 0.532 | Exact Match: 0.268\nThresh 0.40 | Macro F1: 0.202 | Micro F1: 0.515 | Exact Match: 0.278\nThresh 0.45 | Macro F1: 0.192 | Micro F1: 0.487 | Exact Match: 0.252\nThresh 0.50 | Macro F1: 0.177 | Micro F1: 0.445 | Exact Match: 0.215\nThresh 0.55 | Macro F1: 0.162 | Micro F1: 0.406 | Exact Match: 0.194\nThresh 0.60 | Macro F1: 0.137 | Micro F1: 0.353 | Exact Match: 0.171\nThresh 0.65 | Macro F1: 0.105 | Micro F1: 0.288 | Exact Match: 0.150\nThresh 0.70 | Macro F1: 0.078 | Micro F1: 0.226 | Exact Match: 0.115\nThresh 0.75 | Macro F1: 0.059 | Micro F1: 0.160 | Exact Match: 0.089\nThresh 0.80 | Macro F1: 0.042 | Micro F1: 0.104 | Exact Match: 0.071\nThresh 0.85 | Macro F1: 0.028 | Micro F1: 0.061 | Exact Match: 0.052\n\n Best threshold = 0.10 with Macro F1 = 0.350\n[Model 2] Validation Macro F1 (Epoch 2): 0.3500\n✅ Saved best Model 2 (Epoch 2) to narrative_classification_STL_UA-CC_to_UA-CC_2.pt\n[Model 2] Epoch 3: 100%|██████████| 192/192 [01:23<00:00,  2.30it/s]\n\n[Model 2] Epoch 3: Loss = 0.1684\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.381 | Micro F1: 0.491 | Exact Match: 0.073\nThresh 0.15 | Macro F1: 0.383 | Micro F1: 0.542 | Exact Match: 0.144\nThresh 0.20 | Macro F1: 0.369 | Micro F1: 0.567 | Exact Match: 0.192\nThresh 0.25 | Macro F1: 0.336 | Micro F1: 0.578 | Exact Match: 0.252\nThresh 0.30 | Macro F1: 0.315 | Micro F1: 0.577 | Exact Match: 0.270\nThresh 0.35 | Macro F1: 0.292 | Micro F1: 0.571 | Exact Match: 0.307\nThresh 0.40 | Macro F1: 0.272 | Micro F1: 0.558 | Exact Match: 0.307\nThresh 0.45 | Macro F1: 0.241 | Micro F1: 0.526 | Exact Match: 0.315\nThresh 0.50 | Macro F1: 0.221 | Micro F1: 0.490 | Exact Match: 0.320\nThresh 0.55 | Macro F1: 0.191 | Micro F1: 0.437 | Exact Match: 0.299\nThresh 0.60 | Macro F1: 0.159 | Micro F1: 0.386 | Exact Match: 0.268\nThresh 0.65 | Macro F1: 0.139 | Micro F1: 0.342 | Exact Match: 0.234\nThresh 0.70 | Macro F1: 0.113 | Micro F1: 0.277 | Exact Match: 0.205\nThresh 0.75 | Macro F1: 0.101 | Micro F1: 0.242 | Exact Match: 0.189\nThresh 0.80 | Macro F1: 0.085 | Micro F1: 0.195 | Exact Match: 0.163\nThresh 0.85 | Macro F1: 0.061 | Micro F1: 0.136 | Exact Match: 0.115\n\n Best threshold = 0.15 with Macro F1 = 0.383\n[Model 2] Validation Macro F1 (Epoch 3): 0.3833\n✅ Saved best Model 2 (Epoch 3) to narrative_classification_STL_UA-CC_to_UA-CC_2.pt\n\n=== Training Model 3/3 ===\n/root/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n[Model 3] Epoch 1: 100%|██████████| 192/192 [01:23<00:00,  2.30it/s]\n\n[Model 3] Epoch 1: Loss = 0.2734\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.209 | Micro F1: 0.394 | Exact Match: 0.000\nThresh 0.15 | Macro F1: 0.219 | Micro F1: 0.446 | Exact Match: 0.045\nThresh 0.20 | Macro F1: 0.181 | Micro F1: 0.468 | Exact Match: 0.134\nThresh 0.25 | Macro F1: 0.140 | Micro F1: 0.404 | Exact Match: 0.150\nThresh 0.30 | Macro F1: 0.103 | Micro F1: 0.320 | Exact Match: 0.129\nThresh 0.35 | Macro F1: 0.067 | Micro F1: 0.229 | Exact Match: 0.113\nThresh 0.40 | Macro F1: 0.042 | Micro F1: 0.147 | Exact Match: 0.094\nThresh 0.45 | Macro F1: 0.032 | Micro F1: 0.122 | Exact Match: 0.087\nThresh 0.50 | Macro F1: 0.033 | Micro F1: 0.123 | Exact Match: 0.087\nThresh 0.55 | Macro F1: 0.035 | Micro F1: 0.121 | Exact Match: 0.087\nThresh 0.60 | Macro F1: 0.035 | Micro F1: 0.115 | Exact Match: 0.084\nThresh 0.65 | Macro F1: 0.034 | Micro F1: 0.104 | Exact Match: 0.079\nThresh 0.70 | Macro F1: 0.036 | Micro F1: 0.105 | Exact Match: 0.079\nThresh 0.75 | Macro F1: 0.033 | Micro F1: 0.084 | Exact Match: 0.063\nThresh 0.80 | Macro F1: 0.015 | Micro F1: 0.027 | Exact Match: 0.021\nThresh 0.85 | Macro F1: 0.000 | Micro F1: 0.000 | Exact Match: 0.000\n\n Best threshold = 0.15 with Macro F1 = 0.219\n[Model 3] Validation Macro F1 (Epoch 1): 0.2191\n✅ Saved best Model 3 (Epoch 1) to narrative_classification_STL_UA-CC_to_UA-CC_3.pt\n[Model 3] Epoch 2: 100%|██████████| 192/192 [01:22<00:00,  2.33it/s]\n\n[Model 3] Epoch 2: Loss = 0.1938\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.365 | Micro F1: 0.469 | Exact Match: 0.058\nThresh 0.15 | Macro F1: 0.326 | Micro F1: 0.521 | Exact Match: 0.144\nThresh 0.20 | Macro F1: 0.276 | Micro F1: 0.555 | Exact Match: 0.213\nThresh 0.25 | Macro F1: 0.256 | Micro F1: 0.567 | Exact Match: 0.289\nThresh 0.30 | Macro F1: 0.248 | Micro F1: 0.573 | Exact Match: 0.325\nThresh 0.35 | Macro F1: 0.225 | Micro F1: 0.556 | Exact Match: 0.302\nThresh 0.40 | Macro F1: 0.213 | Micro F1: 0.520 | Exact Match: 0.281\nThresh 0.45 | Macro F1: 0.202 | Micro F1: 0.489 | Exact Match: 0.262\nThresh 0.50 | Macro F1: 0.185 | Micro F1: 0.454 | Exact Match: 0.236\nThresh 0.55 | Macro F1: 0.171 | Micro F1: 0.411 | Exact Match: 0.218\nThresh 0.60 | Macro F1: 0.140 | Micro F1: 0.330 | Exact Match: 0.197\nThresh 0.65 | Macro F1: 0.120 | Micro F1: 0.290 | Exact Match: 0.176\nThresh 0.70 | Macro F1: 0.092 | Micro F1: 0.223 | Exact Match: 0.129\nThresh 0.75 | Macro F1: 0.057 | Micro F1: 0.146 | Exact Match: 0.100\nThresh 0.80 | Macro F1: 0.044 | Micro F1: 0.113 | Exact Match: 0.087\nThresh 0.85 | Macro F1: 0.036 | Micro F1: 0.091 | Exact Match: 0.073\n\n Best threshold = 0.10 with Macro F1 = 0.365\n[Model 3] Validation Macro F1 (Epoch 2): 0.3650\n✅ Saved best Model 3 (Epoch 2) to narrative_classification_STL_UA-CC_to_UA-CC_3.pt\n[Model 3] Epoch 3: 100%|██████████| 192/192 [01:23<00:00,  2.31it/s]\n\n[Model 3] Epoch 3: Loss = 0.1627\nThreshold sweep results:\nThresh 0.10 | Macro F1: 0.428 | Micro F1: 0.509 | Exact Match: 0.052\nThresh 0.15 | Macro F1: 0.434 | Micro F1: 0.566 | Exact Match: 0.136\nThresh 0.20 | Macro F1: 0.402 | Micro F1: 0.596 | Exact Match: 0.215\nThresh 0.25 | Macro F1: 0.370 | Micro F1: 0.599 | Exact Match: 0.273\nThresh 0.30 | Macro F1: 0.317 | Micro F1: 0.589 | Exact Match: 0.315\nThresh 0.35 | Macro F1: 0.301 | Micro F1: 0.583 | Exact Match: 0.328\nThresh 0.40 | Macro F1: 0.288 | Micro F1: 0.576 | Exact Match: 0.323\nThresh 0.45 | Macro F1: 0.264 | Micro F1: 0.557 | Exact Match: 0.320\nThresh 0.50 | Macro F1: 0.233 | Micro F1: 0.527 | Exact Match: 0.294\nThresh 0.55 | Macro F1: 0.210 | Micro F1: 0.498 | Exact Match: 0.273\nThresh 0.60 | Macro F1: 0.192 | Micro F1: 0.458 | Exact Match: 0.241\nThresh 0.65 | Macro F1: 0.172 | Micro F1: 0.416 | Exact Match: 0.228\nThresh 0.70 | Macro F1: 0.154 | Micro F1: 0.368 | Exact Match: 0.194\nThresh 0.75 | Macro F1: 0.128 | Micro F1: 0.311 | Exact Match: 0.144\nThresh 0.80 | Macro F1: 0.094 | Micro F1: 0.229 | Exact Match: 0.113\nThresh 0.85 | Macro F1: 0.050 | Micro F1: 0.127 | Exact Match: 0.047\n\n Best threshold = 0.15 with Macro F1 = 0.434\n[Model 3] Validation Macro F1 (Epoch 3): 0.4337\n✅ Saved best Model 3 (Epoch 3) to narrative_classification_STL_UA-CC_to_UA-CC_3.pt\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/d33d8f98-4d53-4dfa-ae33-1735639f07ae",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "d9e294b6",
                "execution_start": 1744133308629,
                "execution_millis": 4,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "b20fc80602a9423ca082540cc1afb39b",
                "deepnote_cell_type": "code"
            },
            "source": "def evaluate(loader, df_source, mlb, label=\"TEST\", threshold=0.25): \n    \"\"\"\n    Ensemble evaluation using 3 trained models with soft voting.\n    \"\"\"\n    model_paths = [\n        MODEL_PATH.replace(\".pt\", f\"_{i}.pt\") for i in range(1, 4)\n    ]\n    \n    models = []\n    for path in model_paths:\n        m = TransformerClassifier(MODEL_NAME, num_classes).to(device)\n        m.load_state_dict(torch.load(path, map_location=device))\n        m.eval()\n        models.append(m)\n\n    y_true, y_pred, domains = [], [], []\n\n    with torch.no_grad():\n        for i, batch in enumerate(tqdm(loader, desc=f\"Ensembling {label}\")):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].cpu().numpy()\n\n            logits_sum = torch.zeros((input_ids.size(0), num_classes)).to(device)\n            for model in models:\n                logits_sum += model(input_ids, attention_mask)\n            probs = torch.sigmoid(logits_sum / len(models)).cpu().numpy()\n\n            y_pred.extend(probs)\n            y_true.extend(labels)\n\n            start = i * loader.batch_size\n            end = start + len(labels)\n            domains.extend(df_source[\"Domain\"].iloc[start:end].tolist())\n\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    domains = np.array(domains)\n\n    y_pred_bin = (y_pred > threshold).astype(int)\n\n    # Filter unused labels\n    mask = (y_true.sum(axis=0) + y_pred_bin.sum(axis=0)) > 0\n    y_true = y_true[:, mask]\n    y_pred_bin = y_pred_bin[:, mask]\n    filtered_labels = np.array(mlb.classes_)[mask]\n\n    macro = f1_score(y_true, y_pred_bin, average=\"macro\", zero_division=0)\n    micro = f1_score(y_true, y_pred_bin, average=\"micro\", zero_division=0)\n    exact = (y_pred_bin == y_true).all(axis=1).mean()\n\n    print(f\"\\n {label} (Fixed Threshold={threshold:.2f}):\")\n    print(f\"Macro F1: {macro:.3f}\")\n    print(f\"Micro F1: {micro:.3f}\")\n    print(f\"Exact Match: {exact:.3f}\")\n\n    print(\"\\n----------------------------\")\n    print(\"Per-Domain Breakdown\")\n    print(\"----------------------------\")\n    for domain in np.unique(domains):\n        idx = np.where(domains == domain)[0]\n        y_true_d = y_true[idx]\n        y_pred_d = y_pred_bin[idx]\n\n        macro_d = f1_score(y_true_d, y_pred_d, average=\"macro\", zero_division=0)\n        micro_d = f1_score(y_true_d, y_pred_d, average=\"micro\", zero_division=0)\n        exact_d = (y_pred_d == y_true_d).all(axis=1).mean()\n\n        print(f\"\\n Domain: {domain}\")\n        print(f\"Macro F1: {macro_d:.3f}\")\n        print(f\"Micro F1: {micro_d:.3f}\")\n        print(f\"Exact Match: {exact_d:.3f}\")\n\n    return {\n        \"macro\": macro,\n        \"micro\": micro,\n        \"exact\": exact,\n        \"threshold\": threshold,\n        \"labels_used\": filtered_labels.tolist()\n    }\n",
            "block_group": "346b8cc33bd64584bc158f79ebe7ec2c",
            "execution_count": 90,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "f1ae8ece",
                "execution_start": 1744133311789,
                "execution_millis": 39250,
                "execution_context_id": "0f665859-5bd7-49c8-b651-a5fa252c40c3",
                "cell_id": "50ea2a1dcce948e9b9df3c8ee9ed5c10",
                "deepnote_cell_type": "code"
            },
            "source": "results = evaluate_and_compare_fixed_thresh(\n    val_loader, df_val,\n    test_loader, df_test,\n    mlb\n)\n",
            "block_group": "733d4a10135e400aa97a63272ba59148",
            "execution_count": 92,
            "outputs": [
                {
                    "name": "stdout",
                    "text": "\n=========================\nValidation (Fixed Threshold)\n=========================\n/root/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEnsembling VALIDATION: 100%|██████████| 48/48 [00:20<00:00,  2.29it/s]\n/root/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n\n VALIDATION (Fixed Threshold=0.25):\nMacro F1: 0.381\nMicro F1: 0.604\nExact Match: 0.294\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\n Domain: CC\nMacro F1: 0.279\nMicro F1: 0.677\nExact Match: 0.460\n\n Domain: UA\nMacro F1: 0.178\nMicro F1: 0.578\nExact Match: 0.224\n\n=========================\nTest (Fixed Threshold)\n=========================\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEnsembling TEST: 100%|██████████| 23/23 [00:09<00:00,  2.36it/s]\n TEST (Fixed Threshold=0.25):\nMacro F1: 0.330\nMicro F1: 0.567\nExact Match: 0.236\n\n----------------------------\nPer-Domain Breakdown\n----------------------------\n\n Domain: CC\nMacro F1: 0.279\nMicro F1: 0.644\nExact Match: 0.397\n\n Domain: UA\nMacro F1: 0.166\nMicro F1: 0.524\nExact Match: 0.124\n\n=========================\nOOD Generalization (Fixed Threshold)\n=========================\nΔ Macro F1 (val - test): 0.051\n\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/76aca08a-db1a-4551-b3e9-e5eaeb8451a1",
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "cell_id": "b021856af2d042089ce8f6b51cf37df4",
                "deepnote_cell_type": "markdown"
            },
            "source": "# Post Hoc Interpretation -- Not Working -- Never mind for now",
            "block_group": "390ce735aab046978b9e054c87930e2a"
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "af889093",
                "execution_start": 1743778243462,
                "execution_millis": 1056,
                "execution_context_id": "0584160d-43be-413a-acf4-fe6858cdad7d",
                "cell_id": "ab4f14d492694ca28564e5e718d72368",
                "deepnote_cell_type": "code"
            },
            "source": "import shap\nfrom captum.attr import IntegratedGradients\nfrom transformers import AutoTokenizer\nimport torch.nn.functional as F\n\n",
            "block_group": "4ca955de68ce46fd9e86c0f15f64d299",
            "execution_count": 22,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "a8ecc548",
                "execution_start": 1743778246873,
                "execution_millis": 1987,
                "execution_context_id": "0584160d-43be-413a-acf4-fe6858cdad7d",
                "cell_id": "5dd8cc85d112431e942a05c38efb88ce",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# LOAD BEST MODEL\n# ==========================\n\nmodel = TransformerClassifier(MODEL_NAME, num_classes)\nmodel.load_state_dict(torch.load(MODEL_PATH))\nmodel.to(device)\nmodel.eval()\n",
            "block_group": "41262b58401b40be8ffa779d5beea6fc",
            "execution_count": 24,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 24,
                    "data": {
                        "text/plain": "TransformerClassifier(\n  (encoder): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (dropout): Dropout(p=0.3, inplace=False)\n  (classifier): Linear(in_features=768, out_features=25, bias=True)\n)"
                    },
                    "metadata": {}
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/bf2e1be2-c90e-47a7-9037-26d092f48ae8",
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "4c9b4da9",
                "execution_start": 1743778255694,
                "execution_millis": 3,
                "execution_context_id": "0584160d-43be-413a-acf4-fe6858cdad7d",
                "cell_id": "60cfe961294e4cec907f41287fe25a39",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# SHAP WRAPPER + EXPLAINER\n# ==========================\n\nimport shap\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nclass TextClassifierWrapper:\n    def __init__(self, model, tokenizer, device):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.device = device\n\n    def __call__(self, texts):\n        texts = [str(t) for t in texts]\n        encodings = self.tokenizer(\n            texts,\n            return_tensors=\"pt\",\n            padding=True,\n            truncation=True,\n            max_length=MAX_LEN\n        )\n        input_ids = encodings[\"input_ids\"].to(self.device)\n        attention_mask = encodings[\"attention_mask\"].to(self.device)\n        with torch.no_grad():\n            logits = self.model(input_ids=input_ids, attention_mask=attention_mask)\n            probs = torch.sigmoid(logits)\n        return probs.cpu().numpy()\n\nwrapped_model = TextClassifierWrapper(model, tokenizer, device)\nmasker = shap.maskers.Text(tokenizer)\nexplainer = shap.Explainer(wrapped_model, masker)\n",
            "block_group": "e93807d0ee714b57a436764e010ce57d",
            "execution_count": 28,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "98c26a3d",
                "execution_start": 1743778258578,
                "execution_millis": 2,
                "execution_context_id": "0584160d-43be-413a-acf4-fe6858cdad7d",
                "cell_id": "96b05f847a754edf935139abaa8fbb33",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# GLOBAL SHAP SUMMARY PLOT\n# ==========================\n\ndef shap_global_summary(texts, filename=\"shap_global_summary.png\", top_n=20):\n    shap_values = explainer(texts)\n\n    all_scores = np.abs(shap_values.values)  # (samples, tokens, outputs)\n    all_tokens = shap_values.data\n\n    if all_scores.ndim == 3:\n        all_scores = all_scores[:, :, 0]  # collapse output label dim\n\n    token_contributions = {}\n    for doc_tokens, doc_scores in zip(all_tokens, all_scores):\n        for token, score in zip(doc_tokens, doc_scores):\n            token = str(token)\n            token_contributions[token] = token_contributions.get(token, []) + [abs(score)]\n\n    token_avg_scores = {tok: np.mean(vals) for tok, vals in token_contributions.items()}\n    top_items = sorted(token_avg_scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n    top_tokens, top_scores = zip(*top_items)\n\n    plt.figure(figsize=(10, 6))\n    y_pos = np.arange(len(top_tokens))\n    plt.barh(y_pos, top_scores, align='center')\n    plt.yticks(y_pos, top_tokens)\n    plt.xlabel('Mean |SHAP Value|')\n    plt.title(f'Top {top_n} Most Influential Tokens Globally')\n    plt.gca().invert_yaxis()\n    plt.tight_layout()\n    plt.savefig(filename)\n    plt.close()\n",
            "block_group": "adb86556b9f94adab723c7264bcbab97",
            "execution_count": 30,
            "outputs": [],
            "outputs_reference": null,
            "content_dependencies": null
        },
        {
            "cell_type": "code",
            "metadata": {
                "source_hash": "a71a2263",
                "execution_start": 1743778262268,
                "execution_millis": 218215,
                "execution_context_id": "0584160d-43be-413a-acf4-fe6858cdad7d",
                "cell_id": "c10213618d5242b1ae207baa2ad421e2",
                "deepnote_cell_type": "code"
            },
            "source": "# ==========================\n# RUN GLOBAL ANALYSIS\n# ==========================\n\nsample_texts = df_test[TEXT_COL].tolist()[:10]\nshap_global_summary(sample_texts, filename=\"shap_global_summary.png\", top_n=25)\n",
            "block_group": "a7edf35e522f4432a3acde04c987b32c",
            "execution_count": 32,
            "outputs": [
                {
                    "name": "stderr",
                    "text": "PartitionExplainer explainer:  10%|█         | 1/10 [00:00<?, ?it/s]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:00<00:00, 2946.00it/s]\u001b[A\nPartitionExplainer explainer:  30%|███       | 3/10 [00:23<00:30,  4.34s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 433.03it/s]\u001b[A\n 34%|███▍      | 170/498 [00:02<00:06, 54.17it/s] \u001b[A\n 39%|███▉      | 194/498 [00:03<00:07, 41.11it/s]\u001b[A\n 41%|████▏     | 206/498 [00:04<00:07, 36.69it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:08, 32.98it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:08, 31.21it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 29.49it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:09, 27.85it/s]\u001b[A\n 49%|████▊     | 242/498 [00:05<00:09, 26.32it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:09, 25.10it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 24.07it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 23.31it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 22.74it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 22.29it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 21.96it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:07<00:09, 21.73it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 21.54it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 21.50it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 21.43it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:08, 21.32it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 21.26it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 21.27it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:09<00:08, 21.26it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:07, 21.22it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 21.19it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 21.27it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:06, 21.24it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 21.19it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 21.22it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:11<00:06, 21.19it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 21.20it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 21.22it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:12<00:05, 21.19it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:04, 21.21it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 21.19it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 21.16it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:13<00:04, 21.19it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 21.20it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 21.21it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:14<00:03, 21.21it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 21.19it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 21.22it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 21.25it/s]\u001b[A\n 91%|█████████ | 452/498 [00:15<00:02, 20.96it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 20.95it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 20.89it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:16<00:01, 21.03it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 21.06it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 21.12it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 21.14it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:17<00:00, 21.10it/s]\u001b[A\n500it [00:18, 21.16it/s]                         \u001b[A\n504it [00:18, 21.07it/s]\u001b[A\nPartitionExplainer explainer:  40%|████      | 4/10 [00:47<01:15, 12.55s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 434.04it/s]\u001b[A\n 34%|███▍      | 170/498 [00:02<00:06, 54.20it/s] \u001b[A\n 39%|███▉      | 194/498 [00:03<00:07, 41.10it/s]\u001b[A\n 41%|████▏     | 206/498 [00:04<00:07, 36.72it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:08, 32.96it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:08, 31.24it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 29.53it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:09, 27.87it/s]\u001b[A\n 49%|████▊     | 242/498 [00:05<00:09, 26.44it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:09, 25.12it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 24.11it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 23.36it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 22.75it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 22.30it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 22.00it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:07<00:09, 21.77it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 21.60it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 21.52it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 21.34it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:08, 21.26it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 21.10it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 21.03it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:09<00:08, 21.02it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:07, 21.02it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 21.09it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 21.10it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:07, 21.11it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 21.16it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 21.18it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:11<00:06, 21.20it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 21.17it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 21.22it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:12<00:05, 21.19it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:05, 21.16it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 21.15it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 21.15it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:13<00:04, 21.07it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 21.09it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 20.96it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:14<00:03, 20.98it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 20.96it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 21.01it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 21.02it/s]\u001b[A\n 91%|█████████ | 452/498 [00:15<00:02, 21.06it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 21.15it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 21.18it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:16<00:01, 21.13it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 21.13it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 21.18it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 21.22it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:17<00:00, 21.18it/s]\u001b[A\n500it [00:18, 21.14it/s]                         \u001b[A\n504it [00:18, 21.05it/s]\u001b[A\nPartitionExplainer explainer:  50%|█████     | 5/10 [01:11<01:24, 16.85s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 430.68it/s]\u001b[A\n 34%|███▍      | 170/498 [00:02<00:06, 54.15it/s] \u001b[A\n 39%|███▉      | 194/498 [00:03<00:07, 41.07it/s]\u001b[A\n 41%|████▏     | 206/498 [00:04<00:07, 36.66it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:08, 32.88it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:08, 31.16it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 29.42it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:09, 27.78it/s]\u001b[A\n 49%|████▊     | 242/498 [00:05<00:09, 26.21it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:10, 24.94it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 23.93it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 23.13it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 22.59it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 22.17it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 21.89it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:07<00:09, 21.73it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 21.51it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 21.34it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 21.20it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:08, 21.13it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 21.06it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 21.13it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:09<00:08, 21.08it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:07, 21.09it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 21.10it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 21.13it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:07, 21.12it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 21.05it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 21.03it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:11<00:06, 21.00it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 21.01it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 20.96it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:12<00:05, 21.02it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:05, 21.05it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 21.03it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 21.01it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:13<00:04, 20.96it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 20.95it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 20.98it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:14<00:03, 20.99it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 20.98it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 20.95it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 20.92it/s]\u001b[A\n 91%|█████████ | 452/498 [00:15<00:02, 20.96it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 20.99it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 21.05it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:16<00:01, 21.08it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 21.11it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 21.00it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 20.94it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:17<00:00, 20.94it/s]\u001b[A\n500it [00:18, 20.88it/s]                         \u001b[A\n504it [00:18, 20.83it/s]\u001b[A\nPartitionExplainer explainer:  60%|██████    | 6/10 [01:35<01:17, 19.39s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 433.45it/s]\u001b[A\n 34%|███▍      | 170/498 [00:02<00:06, 54.24it/s] \u001b[A\n 39%|███▉      | 194/498 [00:03<00:07, 41.12it/s]\u001b[A\n 41%|████▏     | 206/498 [00:04<00:07, 36.73it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:08, 32.98it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:08, 31.24it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 29.30it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:09, 27.62it/s]\u001b[A\n 49%|████▊     | 242/498 [00:05<00:09, 26.14it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:10, 24.88it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 23.76it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 22.98it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 22.44it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 21.97it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 21.63it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:07<00:09, 21.42it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 21.29it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 21.15it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 21.06it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:09, 21.02it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 21.05it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 21.04it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:09<00:08, 21.04it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:07, 21.05it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 21.05it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 20.99it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:07, 20.95it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 21.00it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 20.97it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:11<00:06, 21.03it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 21.10it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 21.09it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:12<00:05, 21.08it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:05, 21.15it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 21.17it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 21.12it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:13<00:04, 21.09it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 21.04it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 21.01it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:14<00:03, 20.98it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 20.99it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 21.02it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 20.94it/s]\u001b[A\n 91%|█████████ | 452/498 [00:15<00:02, 20.93it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 20.91it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 20.93it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:16<00:01, 20.96it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 21.03it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 21.06it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 21.04it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:17<00:00, 21.03it/s]\u001b[A\n500it [00:18, 21.06it/s]                         \u001b[A\n504it [00:18, 21.01it/s]\u001b[A\nPartitionExplainer explainer:  70%|███████   | 7/10 [01:59<01:02, 20.98s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 431.31it/s]\u001b[A\n 34%|███▍      | 170/498 [00:02<00:06, 54.23it/s] \u001b[A\n 39%|███▉      | 194/498 [00:03<00:07, 40.94it/s]\u001b[A\n 41%|████▏     | 206/498 [00:04<00:07, 36.54it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:08, 32.82it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:08, 31.12it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 29.41it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:09, 27.76it/s]\u001b[A\n 49%|████▊     | 242/498 [00:05<00:09, 26.26it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:10, 24.96it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 23.91it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 23.12it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 22.50it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 22.14it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 21.91it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:07<00:09, 21.61it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 21.51it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 21.37it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 21.27it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:08, 21.17it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 21.11it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 21.00it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:09<00:08, 20.87it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:07, 20.95it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 20.94it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 20.93it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:07, 20.93it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 20.94it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 20.97it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:11<00:06, 20.99it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 21.05it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 21.05it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:12<00:05, 21.07it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:05, 21.00it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 20.97it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 20.97it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:13<00:04, 21.00it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 21.03it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 21.03it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:14<00:03, 21.09it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 21.15it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 21.14it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 21.15it/s]\u001b[A\n 91%|█████████ | 452/498 [00:15<00:02, 21.17it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 21.12it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 21.11it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:16<00:01, 21.15it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 21.13it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 21.14it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 21.09it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:17<00:00, 21.12it/s]\u001b[A\n500it [00:18, 21.10it/s]                         \u001b[A\n504it [00:18, 21.03it/s]\u001b[A\nPartitionExplainer explainer:  80%|████████  | 8/10 [02:23<00:43, 21.99s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 427.26it/s]\u001b[A\n 34%|███▍      | 170/498 [00:02<00:06, 53.32it/s] \u001b[A\n 39%|███▉      | 194/498 [00:03<00:07, 40.50it/s]\u001b[A\n 41%|████▏     | 206/498 [00:04<00:08, 36.21it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:08, 32.58it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:08, 30.79it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 29.05it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:09, 27.36it/s]\u001b[A\n 49%|████▊     | 242/498 [00:06<00:09, 25.86it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:10, 24.53it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 23.53it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 22.86it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 22.29it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 21.78it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 21.53it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:08<00:10, 21.18it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 21.02it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 20.99it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 20.90it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:09, 20.82it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 20.85it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 20.62it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:10<00:08, 20.68it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:08, 20.66it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 20.66it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 20.75it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:07, 20.70it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 20.66it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 20.76it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:12<00:06, 20.75it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 20.67it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 20.75it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:13<00:05, 20.76it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:05, 20.68it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 20.72it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 20.74it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:14<00:04, 20.67it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 20.70it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 20.67it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:15<00:03, 20.68it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 20.78it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 20.64it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 20.68it/s]\u001b[A\n 91%|█████████ | 452/498 [00:16<00:02, 20.68it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 20.69it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 20.72it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:17<00:01, 20.76it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 20.75it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 20.69it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 20.76it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:18<00:00, 20.84it/s]\u001b[A\n500it [00:18, 20.85it/s]                         \u001b[A\n504it [00:18, 20.79it/s]\u001b[A\nPartitionExplainer explainer:  90%|█████████ | 9/10 [02:48<00:22, 22.81s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 410.10it/s]\u001b[A\n 33%|███▎      | 164/498 [00:02<00:05, 57.62it/s] \u001b[A\n 38%|███▊      | 188/498 [00:03<00:07, 42.00it/s]\u001b[A\n 40%|████      | 200/498 [00:04<00:08, 37.07it/s]\u001b[A\n 43%|████▎     | 212/498 [00:04<00:08, 32.98it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:09, 31.11it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:09, 29.26it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 27.53it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:10, 26.00it/s]\u001b[A\n 49%|████▊     | 242/498 [00:06<00:10, 24.80it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:10, 23.72it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 22.87it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 22.33it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 21.97it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 21.46it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 21.31it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:08<00:10, 21.12it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 20.99it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 20.92it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 20.84it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:09, 20.81it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 20.76it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 20.72it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:10<00:08, 20.74it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:07, 20.80it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 20.73it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 20.68it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:07, 20.63it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 20.59it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 20.66it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:12<00:06, 20.69it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 20.67it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 20.71it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:13<00:05, 20.62it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:05, 20.68it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 20.69it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 20.67it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:14<00:04, 20.70it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 20.79it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 20.75it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:15<00:03, 20.70it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 20.77it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 20.71it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 20.71it/s]\u001b[A\n 91%|█████████ | 452/498 [00:16<00:02, 20.79it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 20.83it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 20.69it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:17<00:01, 20.75it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 20.79it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 20.74it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 20.68it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:18<00:00, 20.72it/s]\u001b[A\n500it [00:18, 20.75it/s]                         \u001b[A\n504it [00:18, 20.67it/s]\u001b[A\nPartitionExplainer explainer: 100%|██████████| 10/10 [03:12<00:00, 23.35s/it]\n  0%|          | 0/498 [00:00<?, ?it/s]\u001b[A\n 24%|██▍       | 122/498 [00:00<00:00, 421.56it/s]\u001b[A\n 34%|███▍      | 170/498 [00:02<00:06, 53.38it/s] \u001b[A\n 39%|███▉      | 194/498 [00:03<00:07, 40.36it/s]\u001b[A\n 41%|████▏     | 206/498 [00:04<00:08, 36.08it/s]\u001b[A\n 44%|████▍     | 218/498 [00:04<00:08, 32.51it/s]\u001b[A\n 45%|████▍     | 224/498 [00:05<00:08, 30.75it/s]\u001b[A\n 46%|████▌     | 230/498 [00:05<00:09, 28.99it/s]\u001b[A\n 47%|████▋     | 236/498 [00:05<00:09, 27.37it/s]\u001b[A\n 49%|████▊     | 242/498 [00:06<00:09, 25.88it/s]\u001b[A\n 50%|████▉     | 248/498 [00:06<00:10, 24.62it/s]\u001b[A\n 51%|█████     | 254/498 [00:06<00:10, 23.61it/s]\u001b[A\n 52%|█████▏    | 260/498 [00:06<00:10, 22.65it/s]\u001b[A\n 53%|█████▎    | 266/498 [00:07<00:10, 22.15it/s]\u001b[A\n 55%|█████▍    | 272/498 [00:07<00:10, 21.67it/s]\u001b[A\n 56%|█████▌    | 278/498 [00:07<00:10, 21.40it/s]\u001b[A\n 57%|█████▋    | 284/498 [00:08<00:10, 21.16it/s]\u001b[A\n 58%|█████▊    | 290/498 [00:08<00:09, 20.96it/s]\u001b[A\n 59%|█████▉    | 296/498 [00:08<00:09, 20.95it/s]\u001b[A\n 61%|██████    | 302/498 [00:08<00:09, 20.79it/s]\u001b[A\n 62%|██████▏   | 308/498 [00:09<00:09, 20.76it/s]\u001b[A\n 63%|██████▎   | 314/498 [00:09<00:08, 20.77it/s]\u001b[A\n 64%|██████▍   | 320/498 [00:09<00:08, 20.72it/s]\u001b[A\n 65%|██████▌   | 326/498 [00:10<00:08, 20.71it/s]\u001b[A\n 67%|██████▋   | 332/498 [00:10<00:07, 20.76it/s]\u001b[A\n 68%|██████▊   | 338/498 [00:10<00:07, 20.72it/s]\u001b[A\n 69%|██████▉   | 344/498 [00:10<00:07, 20.69it/s]\u001b[A\n 70%|███████   | 350/498 [00:11<00:07, 20.69it/s]\u001b[A\n 71%|███████▏  | 356/498 [00:11<00:06, 20.68it/s]\u001b[A\n 73%|███████▎  | 362/498 [00:11<00:06, 20.65it/s]\u001b[A\n 74%|███████▍  | 368/498 [00:12<00:06, 20.67it/s]\u001b[A\n 75%|███████▌  | 374/498 [00:12<00:05, 20.67it/s]\u001b[A\n 76%|███████▋  | 380/498 [00:12<00:05, 20.63it/s]\u001b[A\n 78%|███████▊  | 386/498 [00:13<00:05, 20.70it/s]\u001b[A\n 79%|███████▊  | 392/498 [00:13<00:05, 20.67it/s]\u001b[A\n 80%|███████▉  | 398/498 [00:13<00:04, 20.71it/s]\u001b[A\n 81%|████████  | 404/498 [00:13<00:04, 20.76it/s]\u001b[A\n 82%|████████▏ | 410/498 [00:14<00:04, 20.83it/s]\u001b[A\n 84%|████████▎ | 416/498 [00:14<00:03, 20.83it/s]\u001b[A\n 85%|████████▍ | 422/498 [00:14<00:03, 20.74it/s]\u001b[A\n 86%|████████▌ | 428/498 [00:15<00:03, 20.70it/s]\u001b[A\n 87%|████████▋ | 434/498 [00:15<00:03, 20.70it/s]\u001b[A\n 88%|████████▊ | 440/498 [00:15<00:02, 20.67it/s]\u001b[A\n 90%|████████▉ | 446/498 [00:15<00:02, 20.70it/s]\u001b[A\n 91%|█████████ | 452/498 [00:16<00:02, 20.66it/s]\u001b[A\n 92%|█████████▏| 458/498 [00:16<00:01, 20.62it/s]\u001b[A\n 93%|█████████▎| 464/498 [00:16<00:01, 20.72it/s]\u001b[A\n 94%|█████████▍| 470/498 [00:17<00:01, 20.70it/s]\u001b[A\n 96%|█████████▌| 476/498 [00:17<00:01, 20.70it/s]\u001b[A\n 97%|█████████▋| 482/498 [00:17<00:00, 20.76it/s]\u001b[A\n 98%|█████████▊| 488/498 [00:17<00:00, 20.78it/s]\u001b[A\n 99%|█████████▉| 494/498 [00:18<00:00, 20.76it/s]\u001b[A\n500it [00:18, 20.74it/s]                         \u001b[A\n504it [00:18, 20.72it/s]\u001b[A\nPartitionExplainer explainer: 11it [03:37, 21.76s/it]\n",
                    "output_type": "stream"
                }
            ],
            "outputs_reference": "s3:deepnote-cell-outputs-production/8b18b10e-e00c-4728-a2bf-1b2c9457b68a",
            "content_dependencies": null
        },
        {
            "cell_type": "markdown",
            "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=49d39932-ba1f-4621-a036-ab99ade88496' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
            "metadata": {
                "created_in_deepnote_cell": true,
                "deepnote_cell_type": "markdown"
            }
        }
    ],
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "deepnote_notebook_id": "8ccec4a61d4a48a9970e32794a5a560d"
    }
}